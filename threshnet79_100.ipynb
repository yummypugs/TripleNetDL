{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\alexa\\mambaforge\\envs\\triplenet\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:131: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n",
      "c:\\Users\\alexa\\mambaforge\\envs\\triplenet\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===> epoch: 1/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 66ms | Tot: 33s521ms | Loss: 1.3707 | Acc: 49.566% (24783/50000)..........................................................................]  Step: 68ms | Tot: 1s35ms | Loss: 2.0770 | Acc: 24.438% (391/1600) [====>...........................................................................]  Step: 68ms | Tot: 1s790ms | Loss: 1.9828 | Acc: 26.889% (726/2700) [=======>........................................................................]  Step: 68ms | Tot: 3s156ms | Loss: 1.8733 | Acc: 30.255% (1422/4700) [===========================>....................................................]  Step: 69ms | Tot: 11s823ms | Loss: 1.6183 | Acc: 39.489% (6871/17400) [============================>...................................................]  Step: 69ms | Tot: 12s307ms | Loss: 1.6090 | Acc: 39.867% (7216/18100)\n",
      "(685.3286415934563, 0.49566)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 20ms | Tot: 1s996ms | Loss: 1.0662 | Acc: 62.180% (6218/10000)\n",
      "\n",
      "===> epoch: 2/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 65ms | Tot: 32s829ms | Loss: 0.9439 | Acc: 66.700% (33350/50000)==================>............................................................]  Step: 66ms | Tot: 8s102ms | Loss: 1.0086 | Acc: 64.528% (7937/12300) [============================================================>...................]  Step: 66ms | Tot: 24s646ms | Loss: 0.9664 | Acc: 65.736% (24651/37500)\n",
      "(471.93769389390945, 0.667)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 20ms | Tot: 1s983ms | Loss: 1.0043 | Acc: 66.040% (6604/10000)\n",
      "\n",
      "===> epoch: 3/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 65ms | Tot: 32s811ms | Loss: 0.7552 | Acc: 73.810% (36905/50000)\n",
      "(377.590396463871, 0.7381)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 21ms | Tot: 1s979ms | Loss: 0.7631 | Acc: 73.910% (7391/10000)\n",
      "\n",
      "===> epoch: 4/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 66ms | Tot: 32s898ms | Loss: 0.6546 | Acc: 77.432% (38716/50000)\n",
      "(327.3023433685303, 0.77432)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 21ms | Tot: 1s997ms | Loss: 0.7098 | Acc: 75.840% (7584/10000)\n",
      "\n",
      "===> epoch: 5/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 66ms | Tot: 32s955ms | Loss: 0.5748 | Acc: 80.486% (40243/50000)=================>.............................................................]  Step: 66ms | Tot: 7s672ms | Loss: 0.5759 | Acc: 80.658% (9437/11700)\n",
      "(287.380901992321, 0.80486)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 19ms | Tot: 1s987ms | Loss: 0.6111 | Acc: 79.460% (7946/10000)\n",
      "\n",
      "===> epoch: 6/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 67ms | Tot: 32s950ms | Loss: 0.5201 | Acc: 82.310% (41155/50000)===========>.................................................................]  Step: 67ms | Tot: 5s952ms | Loss: 0.5128 | Acc: 82.516% (7509/9100) [==================>.............................................................]  Step: 66ms | Tot: 7s534ms | Loss: 0.5107 | Acc: 82.739% (9515/11500) [========================>.......................................................]  Step: 66ms | Tot: 10s170ms | Loss: 0.5124 | Acc: 82.587% (12801/15500) [======================================>.........................................]  Step: 66ms | Tot: 15s717ms | Loss: 0.5119 | Acc: 82.607% (19743/23900) [============================================>...................................]  Step: 67ms | Tot: 18s159ms | Loss: 0.5149 | Acc: 82.424% (22749/27600) [====================================================>...........................]  Step: 66ms | Tot: 21s466ms | Loss: 0.5145 | Acc: 82.534% (26906/32600)\n",
      "(260.04603213071823, 0.8231)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 20ms | Tot: 1s991ms | Loss: 0.6113 | Acc: 79.460% (7946/10000)\n",
      "\n",
      "===> epoch: 7/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 65ms | Tot: 32s963ms | Loss: 0.4632 | Acc: 84.102% (42051/50000)[==========================================================================>.....]  Step: 67ms | Tot: 30s848ms | Loss: 0.4646 | Acc: 84.036% (39329/46800)\n",
      "(231.57575652003288, 0.84102)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 19ms | Tot: 1s989ms | Loss: 0.6378 | Acc: 79.010% (7901/10000)\n",
      "\n",
      "===> epoch: 8/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 65ms | Tot: 32s990ms | Loss: 0.4234 | Acc: 85.400% (42700/50000)[=====================================================================>..........]  Step: 66ms | Tot: 28s624ms | Loss: 0.4207 | Acc: 85.539% (37124/43400) [=========================================================================>......]  Step: 66ms | Tot: 30s485ms | Loss: 0.4203 | Acc: 85.504% (39503/46200)\n",
      "(211.6827235519886, 0.854)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 19ms | Tot: 1s996ms | Loss: 0.6031 | Acc: 80.010% (8001/10000)\n",
      "\n",
      "===> epoch: 9/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 68ms | Tot: 33s518ms | Loss: 0.3842 | Acc: 86.744% (43372/50000)================>..............................................................]  Step: 67ms | Tot: 7s342ms | Loss: 0.3718 | Acc: 87.136% (9585/11000) [============================>...................................................]  Step: 66ms | Tot: 11s973ms | Loss: 0.3736 | Acc: 87.168% (15603/17900)\n",
      "(192.11787874996662, 0.86744)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 20ms | Tot: 1s995ms | Loss: 0.5969 | Acc: 80.710% (8071/10000)\n",
      "\n",
      "===> epoch: 10/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 68ms | Tot: 33s528ms | Loss: 0.3544 | Acc: 87.908% (43954/50000)====================>...........................................................]  Step: 67ms | Tot: 8s588ms | Loss: 0.3300 | Acc: 88.659% (11437/12900) [========================================================>.......................]  Step: 68ms | Tot: 23s730ms | Loss: 0.3484 | Acc: 88.037% (31253/35500)\n",
      "(177.176276370883, 0.87908)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 20ms | Tot: 2s35ms | Loss: 0.5625 | Acc: 81.790% (8179/10000)\n",
      "\n",
      "===> epoch: 11/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 67ms | Tot: 33s579ms | Loss: 0.3228 | Acc: 89.040% (44520/50000)[=============================>..................................................]  Step: 68ms | Tot: 12s391ms | Loss: 0.3059 | Acc: 89.616% (16579/18500) [===========================================================>....................]  Step: 68ms | Tot: 24s980ms | Loss: 0.3182 | Acc: 89.183% (33176/37200) [===========================================================================>....]  Step: 68ms | Tot: 31s496ms | Loss: 0.3234 | Acc: 89.055% (41767/46900)\n",
      "(161.39783602952957, 0.8904)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 21ms | Tot: 2s10ms | Loss: 0.5344 | Acc: 82.230% (8223/10000)\n",
      "\n",
      "===> epoch: 12/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 67ms | Tot: 33s527ms | Loss: 0.2945 | Acc: 89.988% (44994/50000)[========================================================================>.......]  Step: 68ms | Tot: 30s435ms | Loss: 0.2917 | Acc: 90.081% (40897/45400) [==========================================================================>.....]  Step: 67ms | Tot: 31s39ms | Loss: 0.2938 | Acc: 90.011% (41675/46300) [===============================================================================>]  Step: 68ms | Tot: 33s125ms | Loss: 0.2948 | Acc: 89.966% (44443/49400)\n",
      "(147.2531966716051, 0.89988)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 20ms | Tot: 1s992ms | Loss: 0.5521 | Acc: 82.140% (8214/10000)\n",
      "\n",
      "===> epoch: 13/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 67ms | Tot: 33s609ms | Loss: 0.2914 | Acc: 90.198% (45099/50000)=====>.......................................................................]  Step: 67ms | Tot: 3s313ms | Loss: 0.3163 | Acc: 89.940% (4497/5000) [==================>.............................................................]  Step: 67ms | Tot: 7s547ms | Loss: 0.3078 | Acc: 89.637% (10129/11300) [============================================================>...................]  Step: 68ms | Tot: 25s389ms | Loss: 0.2928 | Acc: 90.135% (34071/37800) [====================================================================>...........]  Step: 67ms | Tot: 28s766ms | Loss: 0.2924 | Acc: 90.147% (38583/42800)\n",
      "(145.6767717897892, 0.90198)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 21ms | Tot: 2s12ms | Loss: 0.5659 | Acc: 82.820% (8282/10000)\n",
      "\n",
      "===> epoch: 14/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 67ms | Tot: 33s633ms | Loss: 0.2561 | Acc: 91.344% (45672/50000)====>........................................................................]  Step: 68ms | Tot: 2s904ms | Loss: 0.2354 | Acc: 92.159% (4055/4400)\n",
      "(128.02948474138975, 0.91344)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 20ms | Tot: 2s3ms | Loss: 0.5503 | Acc: 83.010% (8301/10000)\n",
      "\n",
      "===> epoch: 15/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 67ms | Tot: 33s666ms | Loss: 0.2842 | Acc: 90.416% (45208/50000)[==============================>.................................................]  Step: 68ms | Tot: 12s804ms | Loss: 0.3193 | Acc: 89.335% (17063/19100)\n",
      "(142.07693115621805, 0.90416)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 21ms | Tot: 2s40ms | Loss: 0.5638 | Acc: 82.400% (8240/10000)\n",
      "\n",
      "===> epoch: 16/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 68ms | Tot: 33s917ms | Loss: 0.2111 | Acc: 92.840% (46420/50000)\n",
      "(105.52696802467108, 0.9284)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 20ms | Tot: 2s2ms | Loss: 0.5558 | Acc: 83.330% (8333/10000)\n",
      "\n",
      "===> epoch: 17/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 69ms | Tot: 33s842ms | Loss: 0.1958 | Acc: 93.276% (46638/50000)[============================================>...................................]  Step: 68ms | Tot: 18s573ms | Loss: 0.1834 | Acc: 93.746% (25874/27600) [========================================================================>.......]  Step: 69ms | Tot: 30s557ms | Loss: 0.1917 | Acc: 93.394% (42214/45200)\n",
      "(97.91414362564683, 0.93276)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 20ms | Tot: 2s6ms | Loss: 0.5374 | Acc: 83.270% (8327/10000)[========================================================>.......................]  Step: 20ms | Tot: 1s407ms | Loss: 0.5432 | Acc: 82.957% (5807/7000)\n",
      "\n",
      "===> epoch: 18/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 67ms | Tot: 33s838ms | Loss: 0.1802 | Acc: 93.872% (46936/50000)[=================================>..............................................]  Step: 69ms | Tot: 14s317ms | Loss: 0.1730 | Acc: 94.090% (19947/21200) [=================================================>..............................]  Step: 70ms | Tot: 21s114ms | Loss: 0.1751 | Acc: 94.042% (29341/31200)\n",
      "(90.08440110087395, 0.93872)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 20ms | Tot: 2s10ms | Loss: 0.5999 | Acc: 82.920% (8292/10000)\n",
      "\n",
      "===> epoch: 19/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 68ms | Tot: 33s770ms | Loss: 0.1704 | Acc: 94.164% (47082/50000)[=============================================>..................................]  Step: 68ms | Tot: 19s229ms | Loss: 0.1625 | Acc: 94.509% (26935/28500)\n",
      "(85.22026590630412, 0.94164)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 20ms | Tot: 2s12ms | Loss: 0.6074 | Acc: 82.650% (8265/10000)\n",
      "\n",
      "===> epoch: 20/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 68ms | Tot: 33s775ms | Loss: 0.1578 | Acc: 94.682% (47341/50000)======>......................................................................]  Step: 68ms | Tot: 4s72ms | Loss: 0.1373 | Acc: 95.443% (5822/6100) [============>...................................................................]  Step: 68ms | Tot: 5s88ms | Loss: 0.1416 | Acc: 95.329% (7245/7600) [=======================================================>........................]  Step: 68ms | Tot: 23s483ms | Loss: 0.1525 | Acc: 94.839% (33004/34800)\n",
      "(78.9027640465647, 0.94682)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 20ms | Tot: 2s42ms | Loss: 0.6428 | Acc: 82.920% (8292/10000)\n",
      "\n",
      "===> epoch: 21/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 68ms | Tot: 33s889ms | Loss: 0.1647 | Acc: 94.300% (47150/50000)\n",
      "(82.3576153498143, 0.943)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 20ms | Tot: 2s11ms | Loss: 0.5651 | Acc: 83.440% (8344/10000)\n",
      "\n",
      "===> epoch: 22/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 67ms | Tot: 33s748ms | Loss: 0.1482 | Acc: 95.082% (47541/50000)...........................................................................]  Step: 68ms | Tot: 892ms | Loss: 0.1188 | Acc: 96.000% (1344/1400) [===>............................................................................]  Step: 67ms | Tot: 1s499ms | Loss: 0.1157 | Acc: 96.043% (2209/2300) [====================================>...........................................]  Step: 68ms | Tot: 15s153ms | Loss: 0.1490 | Acc: 95.093% (21396/22500) [============================================================>...................]  Step: 68ms | Tot: 25s626ms | Loss: 0.1492 | Acc: 95.063% (36124/38000) [==========================================================================>.....]  Step: 68ms | Tot: 31s378ms | Loss: 0.1484 | Acc: 95.069% (44207/46500)\n",
      "(74.08511098846793, 0.95082)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 20ms | Tot: 1s996ms | Loss: 0.6325 | Acc: 83.210% (8321/10000)\n",
      "\n",
      "===> epoch: 23/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 71ms | Tot: 33s819ms | Loss: 0.1269 | Acc: 95.696% (47848/50000)[=======================================================================>........]  Step: 68ms | Tot: 30s159ms | Loss: 0.1240 | Acc: 95.839% (42744/44600)\n",
      "(63.4743672311306, 0.95696)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 19ms | Tot: 2s9ms | Loss: 0.6192 | Acc: 82.990% (8299/10000)\n",
      "\n",
      "===> epoch: 24/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 67ms | Tot: 33s899ms | Loss: 0.1156 | Acc: 96.074% (48037/50000)====>........................................................................]  Step: 67ms | Tot: 3s58ms | Loss: 0.0921 | Acc: 96.826% (4454/4600) [=========================================>......................................]  Step: 68ms | Tot: 17s573ms | Loss: 0.1024 | Acc: 96.488% (25087/26000)\n",
      "(57.81447792053223, 0.96074)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 20ms | Tot: 1s996ms | Loss: 0.6490 | Acc: 82.820% (8282/10000)\n",
      "\n",
      "===> epoch: 25/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 67ms | Tot: 33s918ms | Loss: 0.1111 | Acc: 96.158% (48079/50000)=======>.....................................................................]  Step: 68ms | Tot: 4s219ms | Loss: 0.0956 | Acc: 96.762% (6096/6300) [============================================================================>...]  Step: 68ms | Tot: 32s630ms | Loss: 0.1106 | Acc: 96.164% (46255/48100) [==============================================================================>.]  Step: 68ms | Tot: 33s172ms | Loss: 0.1106 | Acc: 96.170% (47027/48900)\n",
      "(55.52588428836316, 0.96158)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 21ms | Tot: 2s19ms | Loss: 0.6302 | Acc: 83.510% (8351/10000)\n",
      "\n",
      "===> epoch: 26/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 67ms | Tot: 33s925ms | Loss: 0.1083 | Acc: 96.258% (48129/50000)[==============================================>.................................]  Step: 68ms | Tot: 19s767ms | Loss: 0.1027 | Acc: 96.409% (28055/29100) [======================================================================>.........]  Step: 67ms | Tot: 29s725ms | Loss: 0.1074 | Acc: 96.297% (42178/43800)\n",
      "(54.14682664722204, 0.96258)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 21ms | Tot: 2s10ms | Loss: 0.6297 | Acc: 83.790% (8379/10000)\n",
      "\n",
      "===> epoch: 27/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 68ms | Tot: 33s869ms | Loss: 0.1025 | Acc: 96.396% (48198/50000)...........................................................................]  Step: 68ms | Tot: 895ms | Loss: 0.0796 | Acc: 97.571% (1366/1400) [================>...............................................................]  Step: 68ms | Tot: 6s928ms | Loss: 0.0862 | Acc: 97.097% (10001/10300) [=====================================>..........................................]  Step: 68ms | Tot: 15s795ms | Loss: 0.0888 | Acc: 96.871% (22571/23300) [=========================================================>......................]  Step: 68ms | Tot: 24s466ms | Loss: 0.0976 | Acc: 96.554% (34856/36100) [==========================================================>.....................]  Step: 67ms | Tot: 24s736ms | Loss: 0.0974 | Acc: 96.562% (35245/36500) [=============================================================>..................]  Step: 70ms | Tot: 26s228ms | Loss: 0.0983 | Acc: 96.532% (37358/38700) [====================================================================>...........]  Step: 69ms | Tot: 29s202ms | Loss: 0.1004 | Acc: 96.480% (41583/43100)\n",
      "(51.27454307116568, 0.96396)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 20ms | Tot: 2s13ms | Loss: 0.6566 | Acc: 83.370% (8337/10000)\n",
      "\n",
      "===> epoch: 28/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 68ms | Tot: 33s805ms | Loss: 0.1021 | Acc: 96.542% (48271/50000)======>......................................................................]  Step: 68ms | Tot: 3s878ms | Loss: 0.0837 | Acc: 97.034% (5628/5800) [=================>..............................................................]  Step: 68ms | Tot: 7s534ms | Loss: 0.0919 | Acc: 96.804% (10842/11200) [========================================================>.......................]  Step: 69ms | Tot: 24s59ms | Loss: 0.0989 | Acc: 96.621% (34397/35600)\n",
      "(51.03623663634062, 0.96542)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 20ms | Tot: 2s10ms | Loss: 0.6320 | Acc: 83.810% (8381/10000)\n",
      "\n",
      "===> epoch: 29/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 68ms | Tot: 33s796ms | Loss: 0.0930 | Acc: 96.854% (48427/50000)[============================================================>...................]  Step: 69ms | Tot: 25s662ms | Loss: 0.0930 | Acc: 96.805% (36786/38000)\n",
      "(46.507907120510936, 0.96854)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 22ms | Tot: 2s20ms | Loss: 0.6813 | Acc: 83.580% (8358/10000)\n",
      "\n",
      "===> epoch: 30/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 68ms | Tot: 33s907ms | Loss: 0.0903 | Acc: 96.958% (48479/50000)[===========================>....................................................]  Step: 68ms | Tot: 11s641ms | Loss: 0.0781 | Acc: 97.312% (16835/17300) [===============================================================>................]  Step: 68ms | Tot: 26s714ms | Loss: 0.0877 | Acc: 97.038% (38233/39400)\n",
      "(45.1320871040225, 0.96958)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 25ms | Tot: 2s7ms | Loss: 0.6913 | Acc: 83.390% (8339/10000)\n",
      "\n",
      "===> epoch: 31/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 67ms | Tot: 34s42ms | Loss: 0.0859 | Acc: 96.966% (48483/50000)======>.......................................................................]  Step: 69ms | Tot: 3s645ms | Loss: 0.0814 | Acc: 96.963% (5236/5400) [==========================================>.....................................]  Step: 68ms | Tot: 18s42ms | Loss: 0.0768 | Acc: 97.279% (25779/26500)\n",
      "(42.95200438797474, 0.96966)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 20ms | Tot: 2s22ms | Loss: 0.6519 | Acc: 84.120% (8412/10000)\n",
      "\n",
      "===> epoch: 32/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 68ms | Tot: 33s832ms | Loss: 0.0798 | Acc: 97.320% (48660/50000)\n",
      "(39.89799448195845, 0.9732)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 21ms | Tot: 2s4ms | Loss: 0.7246 | Acc: 82.600% (8260/10000)\n",
      "\n",
      "===> epoch: 33/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 69ms | Tot: 33s953ms | Loss: 0.0799 | Acc: 97.352% (48676/50000)=====>.......................................................................]  Step: 69ms | Tot: 3s745ms | Loss: 0.0743 | Acc: 97.571% (5464/5600) [=======================================>........................................]  Step: 68ms | Tot: 16s696ms | Loss: 0.0702 | Acc: 97.667% (24026/24600) [===========================================>....................................]  Step: 68ms | Tot: 18s398ms | Loss: 0.0708 | Acc: 97.649% (26463/27100) [================================================================>...............]  Step: 68ms | Tot: 27s225ms | Loss: 0.0780 | Acc: 97.431% (39070/40100)\n",
      "(39.95920004695654, 0.97352)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 20ms | Tot: 2s30ms | Loss: 0.6797 | Acc: 83.580% (8358/10000)\n",
      "\n",
      "===> epoch: 34/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 105ms | Tot: 39s856ms | Loss: 0.0737 | Acc: 97.390% (48695/50000)\n",
      "(36.842295945156366, 0.9739)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 24ms | Tot: 2s466ms | Loss: 0.6786 | Acc: 84.480% (8448/10000)\n",
      "\n",
      "===> epoch: 35/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 83ms | Tot: 45s517ms | Loss: 0.0743 | Acc: 97.450% (48725/50000) [=================================================>..............................]  Step: 104ms | Tot: 27s764ms | Loss: 0.0728 | Acc: 97.452% (30210/31000) [=======================================================================>........]  Step: 102ms | Tot: 40s326ms | Loss: 0.0731 | Acc: 97.471% (43667/44800)\n",
      "(37.154132349416614, 0.9745)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 22ms | Tot: 2s204ms | Loss: 0.7109 | Acc: 83.700% (8370/10000)\n",
      "\n",
      "===> epoch: 36/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 79ms | Tot: 45s102ms | Loss: 0.0699 | Acc: 97.610% (48805/50000) [=================================================================>..............]  Step: 101ms | Tot: 36s892ms | Loss: 0.0677 | Acc: 97.664% (40140/41100)\n",
      "(34.96652127755806, 0.9761)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 22ms | Tot: 2s201ms | Loss: 0.6984 | Acc: 83.890% (8389/10000)\n",
      "\n",
      "===> epoch: 37/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 78ms | Tot: 45s20ms | Loss: 0.0703 | Acc: 97.562% (48781/50000))========>.....................................................................]  Step: 98ms | Tot: 6s131ms | Loss: 0.0582 | Acc: 97.954% (6367/6500) [===============================================================>................]  Step: 104ms | Tot: 35s885ms | Loss: 0.0690 | Acc: 97.622% (38463/39400) [===================================================================>............]  Step: 101ms | Tot: 38s932ms | Loss: 0.0692 | Acc: 97.627% (41394/42400)\n",
      "(35.158535588067025, 0.97562)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 23ms | Tot: 2s367ms | Loss: 0.7099 | Acc: 83.870% (8387/10000)\n",
      "\n",
      "===> epoch: 38/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 97ms | Tot: 44s977ms | Loss: 0.0603 | Acc: 97.940% (48970/50000)\n",
      "(30.147106590215117, 0.9794)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 24ms | Tot: 2s390ms | Loss: 0.7090 | Acc: 84.030% (8403/10000)\n",
      "\n",
      "===> epoch: 39/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 99ms | Tot: 44s994ms | Loss: 0.1005 | Acc: 96.752% (48376/50000) [========================================================>.......................]  Step: 101ms | Tot: 31s908ms | Loss: 0.0597 | Acc: 97.826% (34337/35100)\n",
      "(50.26943121664226, 0.96752)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 22ms | Tot: 2s332ms | Loss: 0.6544 | Acc: 82.720% (8272/10000)\n",
      "\n",
      "===> epoch: 40/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 78ms | Tot: 45s16ms | Loss: 0.0810 | Acc: 97.240% (48620/50000))\n",
      "(40.51110848598182, 0.9724)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 23ms | Tot: 2s214ms | Loss: 0.6754 | Acc: 84.860% (8486/10000)\n",
      "\n",
      "===> epoch: 41/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 79ms | Tot: 44s971ms | Loss: 0.0567 | Acc: 98.090% (49045/50000) [================================>...............................................]  Step: 101ms | Tot: 18s454ms | Loss: 0.0498 | Acc: 98.351% (20162/20500)\n",
      "(28.326649744762108, 0.9809)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 24ms | Tot: 2s259ms | Loss: 0.6941 | Acc: 84.510% (8451/10000)\n",
      "\n",
      "===> epoch: 42/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 104ms | Tot: 45s35ms | Loss: 0.0504 | Acc: 98.304% (49152/50000) [==================================>.............................................]  Step: 101ms | Tot: 20s223ms | Loss: 0.0406 | Acc: 98.693% (21219/21500)\n",
      "(25.219835065770894, 0.98304)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 24ms | Tot: 2s375ms | Loss: 0.6988 | Acc: 83.920% (8392/10000)\n",
      "\n",
      "===> epoch: 43/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 101ms | Tot: 45s78ms | Loss: 0.0539 | Acc: 98.174% (49087/50000)\n",
      "(26.931483790744096, 0.98174)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 24ms | Tot: 2s379ms | Loss: 0.7202 | Acc: 84.110% (8411/10000)\n",
      "\n",
      "===> epoch: 44/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 102ms | Tot: 45s91ms | Loss: 0.0533 | Acc: 98.178% (49089/50000)\n",
      "(26.626661682967097, 0.98178)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 22ms | Tot: 2s224ms | Loss: 0.7457 | Acc: 83.190% (8319/10000)\n",
      "\n",
      "===> epoch: 45/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 84ms | Tot: 45s122ms | Loss: 0.0550 | Acc: 98.098% (49049/50000) [=======================================>........................................]  Step: 98ms | Tot: 22s102ms | Loss: 0.0512 | Acc: 98.272% (24175/24600) [=========================================================================>......]  Step: 103ms | Tot: 41s420ms | Loss: 0.0538 | Acc: 98.144% (44950/45800)\n",
      "(27.49081721471157, 0.98098)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 24ms | Tot: 2s201ms | Loss: 0.7407 | Acc: 83.960% (8396/10000)\n",
      "\n",
      "===> epoch: 46/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 83ms | Tot: 45s133ms | Loss: 0.0499 | Acc: 98.350% (49175/50000)=>............................................................................]  Step: 104ms | Tot: 1s688ms | Loss: 0.0522 | Acc: 98.400% (1968/2000) [=========>......................................................................]  Step: 101ms | Tot: 5s662ms | Loss: 0.0544 | Acc: 98.051% (5785/5900)\n",
      "(24.9520119484514, 0.9835)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 25ms | Tot: 2s306ms | Loss: 0.7671 | Acc: 84.130% (8413/10000)\n",
      "\n",
      "===> epoch: 47/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 99ms | Tot: 45s15ms | Loss: 0.0554 | Acc: 98.160% (49080/50000)) [======================================================>.........................]  Step: 102ms | Tot: 30s604ms | Loss: 0.0548 | Acc: 98.187% (33678/34300) [==============================================================>.................]  Step: 101ms | Tot: 35s554ms | Loss: 0.0555 | Acc: 98.130% (38467/39200)\n",
      "(27.723631975939497, 0.9816)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 24ms | Tot: 2s386ms | Loss: 0.7094 | Acc: 84.480% (8448/10000)\n",
      "\n",
      "===> epoch: 48/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 104ms | Tot: 45s77ms | Loss: 0.0904 | Acc: 97.048% (48524/50000)\n",
      "(45.2217736588791, 0.97048)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 23ms | Tot: 2s371ms | Loss: 0.7252 | Acc: 84.210% (8421/10000)\n",
      "\n",
      "===> epoch: 49/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 78ms | Tot: 45s102ms | Loss: 0.0475 | Acc: 98.432% (49216/50000)\n",
      "(23.752660836093128, 0.98432)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 22ms | Tot: 2s206ms | Loss: 0.7336 | Acc: 84.040% (8404/10000)\n",
      "\n",
      "===> epoch: 50/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 78ms | Tot: 44s921ms | Loss: 0.0406 | Acc: 98.634% (49317/50000)\n",
      "(20.278879674035124, 0.98634)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 22ms | Tot: 2s202ms | Loss: 0.7829 | Acc: 83.720% (8372/10000)\n",
      "\n",
      "===> epoch: 51/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 78ms | Tot: 44s968ms | Loss: 0.0432 | Acc: 98.514% (49257/50000)==========>...................................................................]  Step: 98ms | Tot: 7s718ms | Loss: 0.0412 | Acc: 98.667% (7992/8100)\n",
      "(21.61442049755715, 0.98514)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 24ms | Tot: 2s377ms | Loss: 0.7905 | Acc: 83.920% (8392/10000)\n",
      "\n",
      "===> epoch: 52/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 97ms | Tot: 44s875ms | Loss: 0.0414 | Acc: 98.576% (49288/50000)[=======================>........................................................]  Step: 100ms | Tot: 12s517ms | Loss: 0.0336 | Acc: 98.863% (14434/14600) [============================>...................................................]  Step: 101ms | Tot: 15s835ms | Loss: 0.0336 | Acc: 98.855% (17695/17900)\n",
      "(20.679876686190255, 0.98576)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 24ms | Tot: 2s386ms | Loss: 0.7784 | Acc: 84.160% (8416/10000)\n",
      "\n",
      "===> epoch: 53/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 97ms | Tot: 45s44ms | Loss: 0.0715 | Acc: 97.564% (48782/50000))\n",
      "(35.76487187994644, 0.97564)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 23ms | Tot: 2s287ms | Loss: 0.7356 | Acc: 84.150% (8415/10000)\n",
      "\n",
      "===> epoch: 54/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 77ms | Tot: 45s76ms | Loss: 0.0407 | Acc: 98.602% (49301/50000)) [================================================>...............................]  Step: 100ms | Tot: 27s697ms | Loss: 0.0405 | Acc: 98.597% (29875/30300)\n",
      "(20.35022796667181, 0.98602)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 23ms | Tot: 2s209ms | Loss: 0.8218 | Acc: 83.560% (8356/10000)\n",
      "\n",
      "===> epoch: 55/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 77ms | Tot: 44s969ms | Loss: 0.0403 | Acc: 98.588% (49294/50000)\n",
      "(20.164086045115255, 0.98588)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 24ms | Tot: 2s264ms | Loss: 0.7637 | Acc: 84.560% (8456/10000)\n",
      "\n",
      "===> epoch: 56/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 104ms | Tot: 44s972ms | Loss: 0.0401 | Acc: 98.642% (49321/50000)\n",
      "(20.03168864408508, 0.98642)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 25ms | Tot: 2s378ms | Loss: 0.8018 | Acc: 83.870% (8387/10000)\n",
      "\n",
      "===> epoch: 57/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 100ms | Tot: 45s32ms | Loss: 0.0410 | Acc: 98.560% (49280/50000) [==============================================================================>.]  Step: 101ms | Tot: 44s20ms | Loss: 0.0411 | Acc: 98.555% (48292/49000)\n",
      "(20.50856832996942, 0.9856)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 24ms | Tot: 2s393ms | Loss: 0.7672 | Acc: 83.790% (8379/10000)\n",
      "\n",
      "===> epoch: 58/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 101ms | Tot: 45s26ms | Loss: 0.0365 | Acc: 98.776% (49388/50000) [===============================================>................................]  Step: 94ms | Tot: 26s544ms | Loss: 0.0344 | Acc: 98.896% (29372/29700) [========================================================================>.......]  Step: 100ms | Tot: 40s583ms | Loss: 0.0362 | Acc: 98.794% (45050/45600)\n",
      "(18.249559988093097, 0.98776)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 22ms | Tot: 2s231ms | Loss: 0.7680 | Acc: 84.510% (8451/10000)\n",
      "\n",
      "===> epoch: 59/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 84ms | Tot: 45s61ms | Loss: 0.0391 | Acc: 98.668% (49334/50000))======>.......................................................................]  Step: 104ms | Tot: 4s381ms | Loss: 0.0342 | Acc: 98.849% (5239/5300) [===================>............................................................]  Step: 101ms | Tot: 11s373ms | Loss: 0.0327 | Acc: 98.820% (12056/12200)\n",
      "(19.560750689939596, 0.98668)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 22ms | Tot: 2s202ms | Loss: 0.7667 | Acc: 84.390% (8439/10000)\n",
      "\n",
      "===> epoch: 60/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 85ms | Tot: 45s19ms | Loss: 0.0372 | Acc: 98.756% (49378/50000))\n",
      "(18.580786079983227, 0.98756)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 25ms | Tot: 2s292ms | Loss: 0.8444 | Acc: 83.170% (8317/10000)\n",
      "\n",
      "===> epoch: 61/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 104ms | Tot: 45s73ms | Loss: 0.0395 | Acc: 98.654% (49327/50000)\n",
      "(19.74825154116843, 0.98654)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 25ms | Tot: 2s382ms | Loss: 0.7356 | Acc: 84.480% (8448/10000)\n",
      "\n",
      "===> epoch: 62/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 101ms | Tot: 45s66ms | Loss: 0.0400 | Acc: 98.622% (49311/50000)\n",
      "(20.012222786899656, 0.98622)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 22ms | Tot: 2s367ms | Loss: 0.7692 | Acc: 84.190% (8419/10000)\n",
      "\n",
      "===> epoch: 63/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 78ms | Tot: 45s23ms | Loss: 0.0378 | Acc: 98.714% (49357/50000))\n",
      "(18.882046963553876, 0.98714)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 22ms | Tot: 2s217ms | Loss: 0.7556 | Acc: 83.870% (8387/10000)\n",
      "\n",
      "===> epoch: 64/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 78ms | Tot: 44s993ms | Loss: 0.0359 | Acc: 98.824% (49412/50000)\n",
      "(17.964292359305546, 0.98824)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 22ms | Tot: 2s212ms | Loss: 0.7976 | Acc: 84.190% (8419/10000)\n",
      "\n",
      "===> epoch: 65/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 78ms | Tot: 44s915ms | Loss: 0.0317 | Acc: 98.932% (49466/50000)\n",
      "(15.862312177254353, 0.98932)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 24ms | Tot: 2s349ms | Loss: 0.7885 | Acc: 84.420% (8442/10000)\n",
      "\n",
      "===> epoch: 66/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 97ms | Tot: 44s925ms | Loss: 0.0389 | Acc: 98.710% (49355/50000) [=====================================================>..........................]  Step: 101ms | Tot: 30s384ms | Loss: 0.0355 | Acc: 98.825% (33304/33700)\n",
      "(19.45010361482855, 0.9871)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 24ms | Tot: 2s401ms | Loss: 0.7571 | Acc: 84.550% (8455/10000)\n",
      "\n",
      "===> epoch: 67/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 96ms | Tot: 44s891ms | Loss: 0.0324 | Acc: 98.852% (49426/50000) [=============================>..................................................]  Step: 103ms | Tot: 16s829ms | Loss: 0.0291 | Acc: 98.957% (18505/18700) [========================================================================>.......]  Step: 97ms | Tot: 40s557ms | Loss: 0.0311 | Acc: 98.899% (44999/45500) [===========================================================================>....]  Step: 96ms | Tot: 42s96ms | Loss: 0.0319 | Acc: 98.877% (46571/47100)\n",
      "(16.210390598862432, 0.98852)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 23ms | Tot: 2s297ms | Loss: 0.8332 | Acc: 83.980% (8398/10000)\n",
      "\n",
      "===> epoch: 68/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 79ms | Tot: 44s921ms | Loss: 0.0388 | Acc: 98.674% (49337/50000)\n",
      "(19.399382261326537, 0.98674)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 22ms | Tot: 2s207ms | Loss: 0.7962 | Acc: 84.270% (8427/10000)\n",
      "\n",
      "===> epoch: 69/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 79ms | Tot: 44s935ms | Loss: 0.0300 | Acc: 99.018% (49509/50000)\n",
      "(14.991569782374427, 0.99018)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 25ms | Tot: 2s250ms | Loss: 0.8063 | Acc: 84.450% (8445/10000)\n",
      "\n",
      "===> epoch: 70/200\n",
      "train:\n",
      " 500/500 [===============================================================================>]  Step: 104ms | Tot: 44s773ms | Loss: 0.0297 | Acc: 98.994% (49398/49900) [================================================================================>]  Step: 102ms | Tot: 44s875ms | Loss: 0.0296 | Acc: 98.996% (49498/50000)\n",
      "(14.814916245406494, 0.98996)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 25ms | Tot: 2s379ms | Loss: 0.8223 | Acc: 84.110% (8411/10000)\n",
      "\n",
      "===> epoch: 71/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 101ms | Tot: 45s69ms | Loss: 0.0332 | Acc: 98.898% (49449/50000)\n",
      "(16.613373917585704, 0.98898)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 24ms | Tot: 2s386ms | Loss: 0.7679 | Acc: 84.570% (8457/10000)\n",
      "\n",
      "===> epoch: 72/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 101ms | Tot: 45s58ms | Loss: 0.0332 | Acc: 98.844% (49422/50000)\n",
      "(16.61620573385153, 0.98844)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 21ms | Tot: 2s256ms | Loss: 0.7714 | Acc: 84.290% (8429/10000)\n",
      "\n",
      "===> epoch: 73/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 84ms | Tot: 45s173ms | Loss: 0.0311 | Acc: 98.956% (49478/50000)\n",
      "(15.526471266814042, 0.98956)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 22ms | Tot: 2s206ms | Loss: 0.8172 | Acc: 84.250% (8425/10000)\n",
      "\n",
      "===> epoch: 74/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 82ms | Tot: 45s116ms | Loss: 0.0340 | Acc: 98.892% (49446/50000)===========>..................................................................]  Step: 102ms | Tot: 8s279ms | Loss: 0.0282 | Acc: 99.081% (8521/8600)\n",
      "(17.00456136581488, 0.98892)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 24ms | Tot: 2s287ms | Loss: 0.8300 | Acc: 84.110% (8411/10000)\n",
      "\n",
      "===> epoch: 75/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 104ms | Tot: 45s52ms | Loss: 0.0153 | Acc: 99.526% (49763/50000)[========================>.......................................................]  Step: 99ms | Tot: 13s672ms | Loss: 0.0196 | Acc: 99.448% (15315/15400)\n",
      "(7.62728960858658, 0.99526)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 23ms | Tot: 2s402ms | Loss: 0.8350 | Acc: 85.400% (8540/10000)\n",
      "\n",
      "===> epoch: 76/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 101ms | Tot: 45s126ms | Loss: 0.0085 | Acc: 99.726% (49863/50000)[====================>...........................................................]  Step: 98ms | Tot: 11s311ms | Loss: 0.0083 | Acc: 99.710% (13062/13100) [===================================================>............................]  Step: 103ms | Tot: 28s555ms | Loss: 0.0083 | Acc: 99.705% (32105/32200)\n",
      "(4.2613287181739, 0.99726)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 23ms | Tot: 2s390ms | Loss: 0.8908 | Acc: 85.670% (8567/10000)\n",
      "\n",
      "===> epoch: 77/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 95ms | Tot: 44s985ms | Loss: 0.0075 | Acc: 99.752% (49876/50000) [============================================================================>...]  Step: 96ms | Tot: 43s145ms | Loss: 0.0074 | Acc: 99.763% (47986/48100)\n",
      "(3.7724079593317583, 0.99752)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 22ms | Tot: 2s213ms | Loss: 0.9120 | Acc: 85.100% (8510/10000)\n",
      "\n",
      "===> epoch: 78/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 77ms | Tot: 44s954ms | Loss: 0.0074 | Acc: 99.760% (49880/50000) [===================================>............................................]  Step: 103ms | Tot: 18s972ms | Loss: 0.0068 | Acc: 99.759% (21947/22000)\n",
      "(3.678257160790963, 0.9976)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 22ms | Tot: 2s208ms | Loss: 0.9562 | Acc: 85.040% (8504/10000)\n",
      "\n",
      "===> epoch: 79/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 79ms | Tot: 44s955ms | Loss: 0.0260 | Acc: 99.192% (49596/50000)=========>....................................................................]  Step: 96ms | Tot: 6s868ms | Loss: 0.0061 | Acc: 99.767% (7283/7300) [====================================================================>...........]  Step: 96ms | Tot: 39s9ms | Loss: 0.0268 | Acc: 99.184% (42153/42500)\n",
      "(13.00355064614996, 0.99192)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 24ms | Tot: 2s345ms | Loss: 0.7909 | Acc: 84.750% (8475/10000)\n",
      "\n",
      "===> epoch: 80/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 94ms | Tot: 44s873ms | Loss: 0.0099 | Acc: 99.680% (49840/50000)\n",
      "(4.9732119330292335, 0.9968)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 24ms | Tot: 2s396ms | Loss: 0.8912 | Acc: 85.450% (8545/10000)\n",
      "\n",
      "===> epoch: 81/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 96ms | Tot: 44s891ms | Loss: 0.0059 | Acc: 99.804% (49902/50000) [============================>...................................................]  Step: 102ms | Tot: 15s646ms | Loss: 0.0047 | Acc: 99.846% (17473/17500) [==============================================================================>.]  Step: 98ms | Tot: 43s922ms | Loss: 0.0059 | Acc: 99.808% (48906/49000)\n",
      "(2.9683679591944383, 0.99804)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 23ms | Tot: 2s323ms | Loss: 0.9687 | Acc: 84.970% (8497/10000)\n",
      "\n",
      "===> epoch: 82/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 78ms | Tot: 45s1ms | Loss: 0.0055 | Acc: 99.820% (49910/50000)))\n",
      "(2.762374560788885, 0.9982)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 22ms | Tot: 2s209ms | Loss: 0.9541 | Acc: 85.460% (8546/10000)\n",
      "\n",
      "===> epoch: 83/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 78ms | Tot: 44s964ms | Loss: 0.0048 | Acc: 99.850% (49925/50000) [===========================================================>....................]  Step: 98ms | Tot: 33s541ms | Loss: 0.0044 | Acc: 99.869% (37251/37300)\n",
      "(2.4114262075254373, 0.9985)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 23ms | Tot: 2s243ms | Loss: 0.9930 | Acc: 85.140% (8514/10000)\n",
      "\n",
      "===> epoch: 84/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 103ms | Tot: 45s122ms | Loss: 0.0043 | Acc: 99.874% (49937/50000)=>...........................................................................]  Step: 102ms | Tot: 2s725ms | Loss: 0.0045 | Acc: 99.857% (2796/2800) [========>.......................................................................]  Step: 102ms | Tot: 5s273ms | Loss: 0.0043 | Acc: 99.887% (5294/5300) [=================================>..............................................]  Step: 102ms | Tot: 19s507ms | Loss: 0.0037 | Acc: 99.894% (20778/20800) [======================================================>.........................]  Step: 99ms | Tot: 31s226ms | Loss: 0.0041 | Acc: 99.880% (34259/34300) [=======================================================>........................]  Step: 97ms | Tot: 31s719ms | Loss: 0.0043 | Acc: 99.876% (34757/34800)\n",
      "(2.1565718370111426, 0.99874)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 24ms | Tot: 2s387ms | Loss: 1.0585 | Acc: 85.280% (8528/10000)\n",
      "\n",
      "===> epoch: 85/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 101ms | Tot: 45s83ms | Loss: 0.0090 | Acc: 99.706% (49853/50000)\n",
      "(4.503615677907874, 0.99706)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 25ms | Tot: 2s398ms | Loss: 0.9827 | Acc: 85.130% (8513/10000)\n",
      "\n",
      "===> epoch: 86/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 104ms | Tot: 45s169ms | Loss: 0.0076 | Acc: 99.756% (49878/50000)\n",
      "(3.7987631012729253, 0.99756)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 22ms | Tot: 2s253ms | Loss: 0.9763 | Acc: 85.620% (8562/10000)\n",
      "\n",
      "===> epoch: 87/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 83ms | Tot: 45s125ms | Loss: 0.0081 | Acc: 99.750% (49875/50000)\n",
      "(4.0621658578384086, 0.9975)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 22ms | Tot: 2s209ms | Loss: 0.9850 | Acc: 85.410% (8541/10000)\n",
      "\n",
      "===> epoch: 88/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 82ms | Tot: 45s137ms | Loss: 0.0091 | Acc: 99.708% (49854/50000)=============>................................................................]  Step: 102ms | Tot: 9s108ms | Loss: 0.0061 | Acc: 99.798% (9381/9400)\n",
      "(4.569652901012887, 0.99708)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 25ms | Tot: 2s307ms | Loss: 0.9147 | Acc: 85.460% (8546/10000)\n",
      "\n",
      "===> epoch: 89/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 100ms | Tot: 45s145ms | Loss: 0.0064 | Acc: 99.758% (49879/50000)\n",
      "(3.2181783133983117, 0.99758)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 24ms | Tot: 2s400ms | Loss: 0.9856 | Acc: 85.590% (8559/10000)\n",
      "\n",
      "===> epoch: 90/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 97ms | Tot: 45s37ms | Loss: 0.0088 | Acc: 99.696% (49848/50000))\n",
      "(4.404890974587033, 0.99696)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 22ms | Tot: 2s355ms | Loss: 0.9823 | Acc: 84.970% (8497/10000)\n",
      "\n",
      "===> epoch: 91/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 79ms | Tot: 44s978ms | Loss: 0.0092 | Acc: 99.666% (49833/50000)\n",
      "(4.599101508199965, 0.99666)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 23ms | Tot: 2s230ms | Loss: 0.9608 | Acc: 85.350% (8535/10000)\n",
      "\n",
      "===> epoch: 92/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 78ms | Tot: 44s966ms | Loss: 0.0096 | Acc: 99.680% (49840/50000)\n",
      "(4.794565335094376, 0.9968)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 22ms | Tot: 2s228ms | Loss: 0.9487 | Acc: 85.320% (8532/10000)\n",
      "\n",
      "===> epoch: 93/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 79ms | Tot: 44s980ms | Loss: 0.0086 | Acc: 99.694% (49847/50000)\n",
      "(4.31989484004589, 0.99694)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 24ms | Tot: 2s380ms | Loss: 0.9608 | Acc: 85.270% (8527/10000)\n",
      "\n",
      "===> epoch: 94/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 100ms | Tot: 44s927ms | Loss: 0.0070 | Acc: 99.764% (49882/50000)[==============================>.................................................]  Step: 103ms | Tot: 17s292ms | Loss: 0.0063 | Acc: 99.818% (19165/19200)\n",
      "(3.497280113027955, 0.99764)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 24ms | Tot: 2s402ms | Loss: 0.9830 | Acc: 85.280% (8528/10000)\n",
      "\n",
      "===> epoch: 95/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 97ms | Tot: 44s868ms | Loss: 0.0077 | Acc: 99.724% (49862/50000)\n",
      "(3.8324045148510777, 0.99724)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 22ms | Tot: 2s291ms | Loss: 0.9720 | Acc: 85.210% (8521/10000)\n",
      "\n",
      "===> epoch: 96/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 79ms | Tot: 44s963ms | Loss: 0.0081 | Acc: 99.738% (49869/50000) [========================================>.......................................]  Step: 104ms | Tot: 23s29ms | Loss: 0.0070 | Acc: 99.797% (25548/25600)\n",
      "(4.033208660652235, 0.99738)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 23ms | Tot: 2s208ms | Loss: 0.9703 | Acc: 85.260% (8526/10000)\n",
      "\n",
      "===> epoch: 97/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 83ms | Tot: 45s13ms | Loss: 0.0094 | Acc: 99.694% (49847/50000))======>.......................................................................]  Step: 102ms | Tot: 4s537ms | Loss: 0.0076 | Acc: 99.804% (5090/5100) [===============>................................................................]  Step: 101ms | Tot: 9s300ms | Loss: 0.0068 | Acc: 99.765% (9777/9800)\n",
      "(4.676807513831591, 0.99694)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 24ms | Tot: 2s267ms | Loss: 0.9293 | Acc: 85.440% (8544/10000)\n",
      "\n",
      "===> epoch: 98/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 103ms | Tot: 45s142ms | Loss: 0.0078 | Acc: 99.738% (49869/50000)[===========================================================>....................]  Step: 98ms | Tot: 33s813ms | Loss: 0.0077 | Acc: 99.738% (36903/37000)\n",
      "(3.921006624819711, 0.99738)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 24ms | Tot: 2s397ms | Loss: 0.9555 | Acc: 85.390% (8539/10000)\n",
      "\n",
      "===> epoch: 99/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 101ms | Tot: 45s122ms | Loss: 0.0081 | Acc: 99.726% (49863/50000)\n",
      "(4.074744832443685, 0.99726)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 25ms | Tot: 2s391ms | Loss: 0.9477 | Acc: 85.090% (8509/10000)\n",
      "\n",
      "===> epoch: 100/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 102ms | Tot: 45s19ms | Loss: 0.0081 | Acc: 99.734% (49867/50000)\n",
      "(4.066220209457242, 0.99734)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 23ms | Tot: 2s224ms | Loss: 0.9545 | Acc: 85.080% (8508/10000)\n",
      "\n",
      "===> epoch: 101/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 84ms | Tot: 45s194ms | Loss: 0.0066 | Acc: 99.768% (49884/50000) [==============================================================>.................]  Step: 104ms | Tot: 34s550ms | Loss: 0.0066 | Acc: 99.759% (38906/39000) [=======================================================================>........]  Step: 102ms | Tot: 40s248ms | Loss: 0.0069 | Acc: 99.758% (44492/44600)\n",
      "(3.2860650326001632, 0.99768)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 23ms | Tot: 2s222ms | Loss: 0.9903 | Acc: 85.270% (8527/10000)\n",
      "\n",
      "===> epoch: 102/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 85ms | Tot: 45s134ms | Loss: 0.0075 | Acc: 99.746% (49873/50000)\n",
      "(3.764587465677323, 0.99746)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 25ms | Tot: 2s335ms | Loss: 0.9670 | Acc: 85.250% (8525/10000)\n",
      "\n",
      "===> epoch: 103/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 104ms | Tot: 45s94ms | Loss: 0.0087 | Acc: 99.708% (49854/50000)[===================================>............................................]  Step: 98ms | Tot: 20s223ms | Loss: 0.0085 | Acc: 99.749% (22244/22300)\n",
      "(4.361725738750465, 0.99708)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 25ms | Tot: 2s414ms | Loss: 0.9674 | Acc: 84.970% (8497/10000)\n",
      "\n",
      "===> epoch: 104/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 97ms | Tot: 44s969ms | Loss: 0.0069 | Acc: 99.764% (49882/50000) [===============================================================================>]  Step: 99ms | Tot: 44s386ms | Loss: 0.0069 | Acc: 99.761% (49282/49400)\n",
      "(3.450126243122213, 0.99764)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 22ms | Tot: 2s336ms | Loss: 0.9801 | Acc: 84.970% (8497/10000)\n",
      "\n",
      "===> epoch: 105/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 78ms | Tot: 44s987ms | Loss: 0.0060 | Acc: 99.818% (49909/50000)\n",
      "(2.975810180463668, 0.99818)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 23ms | Tot: 2s214ms | Loss: 1.0818 | Acc: 84.790% (8479/10000)\n",
      "\n",
      "===> epoch: 106/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 79ms | Tot: 44s982ms | Loss: 0.0086 | Acc: 99.722% (49861/50000)=================>..............................................................]  Step: 95ms | Tot: 10s88ms | Loss: 0.0123 | Acc: 99.616% (11157/11200)\n",
      "(4.277608039690676, 0.99722)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 22ms | Tot: 2s213ms | Loss: 0.9835 | Acc: 84.940% (8494/10000)\n",
      "\n",
      "===> epoch: 107/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 78ms | Tot: 44s915ms | Loss: 0.0103 | Acc: 99.656% (49828/50000)\n",
      "(5.1733837715109985, 0.99656)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 24ms | Tot: 2s391ms | Loss: 0.9143 | Acc: 85.000% (8500/10000)\n",
      "\n",
      "===> epoch: 108/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 98ms | Tot: 44s998ms | Loss: 0.0061 | Acc: 99.786% (49893/50000)\n",
      "(3.060973212515819, 0.99786)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 25ms | Tot: 2s399ms | Loss: 0.9675 | Acc: 85.620% (8562/10000)\n",
      "\n",
      "===> epoch: 109/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 94ms | Tot: 44s907ms | Loss: 0.0266 | Acc: 99.168% (49584/50000) [=====================>..........................................................]  Step: 102ms | Tot: 11s760ms | Loss: 0.0522 | Acc: 98.607% (13312/13500) [==========================================================================>.....]  Step: 98ms | Tot: 41s524ms | Loss: 0.0279 | Acc: 99.127% (46094/46500)\n",
      "(13.299927740521525, 0.99168)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 22ms | Tot: 2s293ms | Loss: 0.8923 | Acc: 85.220% (8522/10000)\n",
      "\n",
      "===> epoch: 110/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 80ms | Tot: 44s984ms | Loss: 0.0055 | Acc: 99.818% (49909/50000) [=================================================>..............................]  Step: 96ms | Tot: 28s393ms | Loss: 0.0065 | Acc: 99.796% (30837/30900)\n",
      "(2.7573574612215452, 0.99818)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 22ms | Tot: 2s225ms | Loss: 0.9853 | Acc: 85.510% (8551/10000)\n",
      "\n",
      "===> epoch: 111/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 83ms | Tot: 45s116ms | Loss: 0.0045 | Acc: 99.864% (49932/50000)\n",
      "(2.2543663094775184, 0.99864)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 25ms | Tot: 2s271ms | Loss: 0.9725 | Acc: 85.560% (8556/10000)====================>........................................................]  Step: 23ms | Tot: 629ms | Loss: 1.0043 | Acc: 85.379% (2476/2900)\n",
      "\n",
      "===> epoch: 112/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 102ms | Tot: 45s42ms | Loss: 0.0033 | Acc: 99.896% (49948/50000) [=============================>..................................................]  Step: 102ms | Tot: 16s850ms | Loss: 0.0024 | Acc: 99.945% (18190/18200) [================================>...............................................]  Step: 102ms | Tot: 18s663ms | Loss: 0.0027 | Acc: 99.935% (19987/20000) [===================================>............................................]  Step: 96ms | Tot: 20s635ms | Loss: 0.0030 | Acc: 99.927% (21984/22000)\n",
      "(1.6550564877561555, 0.99896)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 25ms | Tot: 2s381ms | Loss: 1.0146 | Acc: 85.270% (8527/10000)\n",
      "\n",
      "===> epoch: 113/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 102ms | Tot: 45s24ms | Loss: 0.0030 | Acc: 99.896% (49948/50000)\n",
      "(1.5237708092945468, 0.99896)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 24ms | Tot: 2s392ms | Loss: 1.0732 | Acc: 84.940% (8494/10000)\n",
      "\n",
      "===> epoch: 114/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 102ms | Tot: 45s34ms | Loss: 0.0053 | Acc: 99.832% (49916/50000)\n",
      "(2.632161337881371, 0.99832)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 23ms | Tot: 2s237ms | Loss: 1.1325 | Acc: 84.980% (8498/10000)\n",
      "\n",
      "===> epoch: 115/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 84ms | Tot: 45s150ms | Loss: 0.0062 | Acc: 99.792% (49896/50000)\n",
      "(3.0838458643538615, 0.99792)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 22ms | Tot: 2s206ms | Loss: 0.9949 | Acc: 85.130% (8513/10000)\n",
      "\n",
      "===> epoch: 116/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 83ms | Tot: 45s168ms | Loss: 0.0078 | Acc: 99.728% (49864/50000)\n",
      "(3.8823542195023037, 0.99728)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 24ms | Tot: 2s319ms | Loss: 1.0062 | Acc: 85.060% (8506/10000)\n",
      "\n",
      "===> epoch: 117/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 101ms | Tot: 45s69ms | Loss: 0.0067 | Acc: 99.788% (49894/50000)\n",
      "(3.340558013971531, 0.99788)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 24ms | Tot: 2s407ms | Loss: 1.0130 | Acc: 85.190% (8519/10000)\n",
      "\n",
      "===> epoch: 118/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 98ms | Tot: 44s960ms | Loss: 0.0058 | Acc: 99.800% (49900/50000) [=========================>......................................................]  Step: 98ms | Tot: 13s693ms | Loss: 0.0049 | Acc: 99.835% (15774/15800)\n",
      "(2.9112829879595665, 0.998)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 22ms | Tot: 2s361ms | Loss: 0.9958 | Acc: 85.160% (8516/10000)\n",
      "\n",
      "===> epoch: 119/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 79ms | Tot: 45s68ms | Loss: 0.0069 | Acc: 99.776% (49888/50000)) [=========================================================================>......]  Step: 96ms | Tot: 41s136ms | Loss: 0.0069 | Acc: 99.771% (45695/45800)\n",
      "(3.4344208102684206, 0.99776)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 23ms | Tot: 2s211ms | Loss: 0.9945 | Acc: 85.350% (8535/10000)\n",
      "\n",
      "===> epoch: 120/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 78ms | Tot: 44s990ms | Loss: 0.0065 | Acc: 99.774% (49887/50000) [==================================================================>.............]  Step: 97ms | Tot: 37s570ms | Loss: 0.0068 | Acc: 99.759% (41400/41500)\n",
      "(3.242792029730481, 0.99774)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 21ms | Tot: 2s210ms | Loss: 1.0243 | Acc: 85.020% (8502/10000)\n",
      "\n",
      "===> epoch: 121/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 78ms | Tot: 44s942ms | Loss: 0.0062 | Acc: 99.804% (49902/50000)\n",
      "(3.101009030078785, 0.99804)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 24ms | Tot: 2s383ms | Loss: 1.0015 | Acc: 85.200% (8520/10000)\n",
      "\n",
      "===> epoch: 122/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 98ms | Tot: 44s941ms | Loss: 0.0052 | Acc: 99.818% (49909/50000)\n",
      "(2.601751192001757, 0.99818)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 24ms | Tot: 2s397ms | Loss: 1.0592 | Acc: 84.810% (8481/10000)\n",
      "\n",
      "===> epoch: 123/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 96ms | Tot: 44s852ms | Loss: 0.0098 | Acc: 99.694% (49847/50000)\n",
      "(4.906618838031136, 0.99694)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 23ms | Tot: 2s303ms | Loss: 0.9731 | Acc: 85.440% (8544/10000)\n",
      "\n",
      "===> epoch: 124/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 83ms | Tot: 45s31ms | Loss: 0.0070 | Acc: 99.768% (49884/50000))\n",
      "(3.5205201261615002, 0.99768)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 22ms | Tot: 2s225ms | Loss: 1.0272 | Acc: 85.270% (8527/10000)\n",
      "\n",
      "===> epoch: 125/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 83ms | Tot: 45s147ms | Loss: 0.0075 | Acc: 99.748% (49874/50000) [==========================================>.....................................]  Step: 97ms | Tot: 24s661ms | Loss: 0.0065 | Acc: 99.789% (26444/26500) [==========================================================>.....................]  Step: 98ms | Tot: 32s725ms | Loss: 0.0073 | Acc: 99.750% (36309/36400)\n",
      "(3.736918375001551, 0.99748)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 24ms | Tot: 2s268ms | Loss: 1.0218 | Acc: 85.150% (8515/10000)\n",
      "\n",
      "===> epoch: 126/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 104ms | Tot: 45s76ms | Loss: 0.0068 | Acc: 99.764% (49882/50000) [=================================================================>..............]  Step: 98ms | Tot: 37s501ms | Loss: 0.0059 | Acc: 99.800% (40918/41000)\n",
      "(3.4116676264784473, 0.99764)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 23ms | Tot: 2s404ms | Loss: 1.0318 | Acc: 85.340% (8534/10000)\n",
      "\n",
      "===> epoch: 127/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 102ms | Tot: 45s37ms | Loss: 0.0075 | Acc: 99.788% (49894/50000)\n",
      "(3.7348563206724066, 0.99788)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 24ms | Tot: 2s388ms | Loss: 0.9541 | Acc: 85.210% (8521/10000)\n",
      "\n",
      "===> epoch: 128/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 100ms | Tot: 45s77ms | Loss: 0.0057 | Acc: 99.812% (49906/50000) [==========================================>.....................................]  Step: 99ms | Tot: 23s407ms | Loss: 0.0043 | Acc: 99.851% (26760/26800)\n",
      "(2.829600193626902, 0.99812)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 22ms | Tot: 2s246ms | Loss: 1.0095 | Acc: 85.140% (8514/10000)========>....................................................................]  Step: 25ms | Tot: 305ms | Loss: 0.8795 | Acc: 86.571% (1212/1400)\n",
      "\n",
      "===> epoch: 129/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 83ms | Tot: 45s155ms | Loss: 0.0079 | Acc: 99.704% (49852/50000)\n",
      "(3.9515944064914947, 0.99704)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 22ms | Tot: 2s214ms | Loss: 0.9989 | Acc: 85.010% (8501/10000)\n",
      "\n",
      "===> epoch: 130/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 83ms | Tot: 45s104ms | Loss: 0.0072 | Acc: 99.762% (49881/50000)\n",
      "(3.5991858564520953, 0.99762)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 24ms | Tot: 2s308ms | Loss: 0.9871 | Acc: 84.880% (8488/10000)\n",
      "\n",
      "===> epoch: 131/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 95ms | Tot: 45s8ms | Loss: 0.0051 | Acc: 99.834% (49917/50000)))\n",
      "(2.5584343681930477, 0.99834)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 24ms | Tot: 2s394ms | Loss: 1.0199 | Acc: 85.260% (8526/10000)\n",
      "\n",
      "===> epoch: 132/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 97ms | Tot: 44s907ms | Loss: 0.0055 | Acc: 99.816% (49908/50000)\n",
      "(2.7716569365202304, 0.99816)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 22ms | Tot: 2s370ms | Loss: 1.0370 | Acc: 85.010% (8501/10000)\n",
      "\n",
      "===> epoch: 133/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 77ms | Tot: 44s967ms | Loss: 0.0082 | Acc: 99.698% (49849/50000) [===================================================>............................]  Step: 101ms | Tot: 28s698ms | Loss: 0.0076 | Acc: 99.692% (32001/32100)\n",
      "(4.113430552624777, 0.99698)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 23ms | Tot: 2s214ms | Loss: 1.0381 | Acc: 85.020% (8502/10000)\n",
      "\n",
      "===> epoch: 134/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 79ms | Tot: 44s976ms | Loss: 0.0077 | Acc: 99.754% (49877/50000)\n",
      "(3.868894315468424, 0.99754)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 23ms | Tot: 2s205ms | Loss: 0.9952 | Acc: 85.610% (8561/10000)\n",
      "\n",
      "===> epoch: 135/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 78ms | Tot: 45s13ms | Loss: 0.0061 | Acc: 99.788% (49894/50000)) [=============================>..................................................]  Step: 101ms | Tot: 16s776ms | Loss: 0.0075 | Acc: 99.738% (18651/18700)\n",
      "(3.0424553211450984, 0.99788)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 24ms | Tot: 2s375ms | Loss: 1.0011 | Acc: 85.160% (8516/10000)\n",
      "\n",
      "===> epoch: 136/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 97ms | Tot: 44s863ms | Loss: 0.0074 | Acc: 99.778% (49889/50000) [=========================================================>......................]  Step: 97ms | Tot: 32s718ms | Loss: 0.0073 | Acc: 99.783% (35822/35900)\n",
      "(3.6769058088793827, 0.99778)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 24ms | Tot: 2s398ms | Loss: 1.0076 | Acc: 85.040% (8504/10000)\n",
      "\n",
      "===> epoch: 137/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 98ms | Tot: 44s898ms | Loss: 0.0060 | Acc: 99.812% (49906/50000)\n",
      "(2.993065453520103, 0.99812)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 22ms | Tot: 2s313ms | Loss: 1.0058 | Acc: 85.100% (8510/10000)\n",
      "\n",
      "===> epoch: 138/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 83ms | Tot: 45s133ms | Loss: 0.0066 | Acc: 99.792% (49896/50000)\n",
      "(3.287389522639387, 0.99792)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 23ms | Tot: 2s214ms | Loss: 1.0100 | Acc: 85.010% (8501/10000)\n",
      "\n",
      "===> epoch: 139/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 83ms | Tot: 45s151ms | Loss: 0.0060 | Acc: 99.810% (49905/50000)===>..........................................................................]  Step: 102ms | Tot: 3s88ms | Loss: 0.0095 | Acc: 99.622% (3686/3700)\n",
      "(2.994746935833973, 0.9981)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 24ms | Tot: 2s235ms | Loss: 1.0306 | Acc: 85.250% (8525/10000)\n",
      "\n",
      "===> epoch: 140/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 100ms | Tot: 45s125ms | Loss: 0.0144 | Acc: 99.550% (49775/50000)===>.........................................................................]  Step: 101ms | Tot: 3s857ms | Loss: 0.0075 | Acc: 99.718% (3889/3900)\n",
      "(7.205833549223826, 0.9955)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 24ms | Tot: 2s400ms | Loss: 1.0294 | Acc: 84.890% (8489/10000)\n",
      "\n",
      "===> epoch: 141/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 101ms | Tot: 45s157ms | Loss: 0.0075 | Acc: 99.742% (49871/50000)\n",
      "(3.7540715106151765, 0.99742)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 25ms | Tot: 2s401ms | Loss: 1.0547 | Acc: 85.250% (8525/10000)\n",
      "\n",
      "===> epoch: 142/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 100ms | Tot: 45s149ms | Loss: 0.0064 | Acc: 99.802% (49901/50000)=================>..............................................................]  Step: 97ms | Tot: 9s741ms | Loss: 0.0056 | Acc: 99.804% (11178/11200)\n",
      "(3.1801883139414713, 0.99802)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 22ms | Tot: 2s263ms | Loss: 1.0690 | Acc: 85.420% (8542/10000)\n",
      "\n",
      "===> epoch: 143/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 84ms | Tot: 45s204ms | Loss: 0.0045 | Acc: 99.878% (49939/50000)\n",
      "(2.2380230679664237, 0.99878)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 21ms | Tot: 2s220ms | Loss: 1.0651 | Acc: 85.130% (8513/10000)\n",
      "\n",
      "===> epoch: 144/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 79ms | Tot: 45s206ms | Loss: 0.0052 | Acc: 99.824% (49912/50000)\n",
      "(2.586566732546089, 0.99824)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 24ms | Tot: 2s288ms | Loss: 1.0788 | Acc: 85.310% (8531/10000)\n",
      "\n",
      "===> epoch: 145/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 99ms | Tot: 44s980ms | Loss: 0.0078 | Acc: 99.714% (49857/50000)==>...........................................................................]  Step: 99ms | Tot: 2s528ms | Loss: 0.0113 | Acc: 99.667% (2691/2700) [==================================>.............................................]  Step: 98ms | Tot: 19s229ms | Loss: 0.0065 | Acc: 99.772% (21451/21500)\n",
      "(3.9247458952568195, 0.99714)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 24ms | Tot: 2s386ms | Loss: 1.0007 | Acc: 85.060% (8506/10000)\n",
      "\n",
      "===> epoch: 146/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 98ms | Tot: 44s937ms | Loss: 0.0065 | Acc: 99.778% (49889/50000) [====================>...........................................................]  Step: 99ms | Tot: 10s678ms | Loss: 0.0065 | Acc: 99.748% (12668/12700)\n",
      "(3.262598990673723, 0.99778)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 22ms | Tot: 2s373ms | Loss: 1.0121 | Acc: 85.440% (8544/10000)\n",
      "\n",
      "===> epoch: 147/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 96ms | Tot: 45s14ms | Loss: 0.0064 | Acc: 99.784% (49892/50000)) [=============================================>..................................]  Step: 102ms | Tot: 25s314ms | Loss: 0.0056 | Acc: 99.801% (28543/28600)\n",
      "(3.2060321151548123, 0.99784)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 22ms | Tot: 2s209ms | Loss: 1.0749 | Acc: 85.350% (8535/10000)\n",
      "\n",
      "===> epoch: 148/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 78ms | Tot: 44s987ms | Loss: 0.0071 | Acc: 99.770% (49885/50000)\n",
      "(3.537943929515677, 0.9977)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 22ms | Tot: 2s214ms | Loss: 1.0429 | Acc: 84.920% (8492/10000)\n",
      "\n",
      "===> epoch: 149/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 79ms | Tot: 44s973ms | Loss: 0.0070 | Acc: 99.776% (49888/50000)\n",
      "(3.509238465481758, 0.99776)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 24ms | Tot: 2s359ms | Loss: 1.0214 | Acc: 84.980% (8498/10000)\n",
      "\n",
      "===> epoch: 150/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 98ms | Tot: 44s937ms | Loss: 0.0038 | Acc: 99.882% (49941/50000)\n",
      "(1.8866825773629898, 0.99882)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 24ms | Tot: 2s398ms | Loss: 1.0088 | Acc: 85.260% (8526/10000)\n",
      "\n",
      "===> epoch: 151/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 102ms | Tot: 45s58ms | Loss: 0.0020 | Acc: 99.924% (49962/50000)\n",
      "(0.9934568320441031, 0.99924)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 22ms | Tot: 2s327ms | Loss: 1.0454 | Acc: 85.470% (8547/10000)\n",
      "\n",
      "===> epoch: 152/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 83ms | Tot: 45s117ms | Loss: 0.0011 | Acc: 99.962% (49981/50000)\n",
      "(0.5671518243671017, 0.99962)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 22ms | Tot: 2s214ms | Loss: 1.0522 | Acc: 85.580% (8558/10000)\n",
      "\n",
      "===> epoch: 153/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 84ms | Tot: 45s198ms | Loss: 0.0010 | Acc: 99.964% (49982/50000)\n",
      "(0.5120132425670363, 0.99964)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 24ms | Tot: 2s224ms | Loss: 1.1397 | Acc: 85.510% (8551/10000)\n",
      "\n",
      "===> epoch: 154/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 100ms | Tot: 45s48ms | Loss: 0.0009 | Acc: 99.966% (49983/50000)>.............................................................................]  Step: 101ms | Tot: 1s506ms | Loss: 0.0009 | Acc: 99.938% (1599/1600)\n",
      "(0.4589128059221821, 0.99966)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 24ms | Tot: 2s386ms | Loss: 1.1641 | Acc: 85.620% (8562/10000)\n",
      "\n",
      "===> epoch: 155/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 100ms | Tot: 45s135ms | Loss: 0.0018 | Acc: 99.938% (49969/50000)\n",
      "(0.8784030759488815, 0.99938)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 25ms | Tot: 2s403ms | Loss: 1.2052 | Acc: 85.320% (8532/10000)\n",
      "\n",
      "===> epoch: 156/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 102ms | Tot: 45s77ms | Loss: 0.0023 | Acc: 99.932% (49966/50000).......................................................................]  Step: 73ms | Tot: 74ms | Loss: 0.0038 | Acc: 100.000% (200/200) [==============================================================================>.]  Step: 103ms | Tot: 44s167ms | Loss: 0.0023 | Acc: 99.931% (49066/49100)\n",
      "(1.138494374946049, 0.99932)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 23ms | Tot: 2s286ms | Loss: 1.1766 | Acc: 85.460% (8546/10000)\n",
      "\n",
      "===> epoch: 157/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 83ms | Tot: 45s94ms | Loss: 0.0023 | Acc: 99.920% (49960/50000))\n",
      "(1.1550268336925456, 0.9992)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 22ms | Tot: 2s211ms | Loss: 1.1594 | Acc: 85.180% (8518/10000)\n",
      "\n",
      "===> epoch: 158/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 79ms | Tot: 44s978ms | Loss: 0.0012 | Acc: 99.960% (49980/50000)[===============================>................................................]  Step: 99ms | Tot: 17s223ms | Loss: 0.0014 | Acc: 99.944% (19789/19800)\n",
      "(0.6202990194935865, 0.9996)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 24ms | Tot: 2s285ms | Loss: 1.1732 | Acc: 85.560% (8556/10000)================================================>..............................]  Step: 24ms | Tot: 1s370ms | Loss: 1.1931 | Acc: 85.597% (5307/6200)\n",
      "\n",
      "===> epoch: 159/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 98ms | Tot: 44s848ms | Loss: 0.0016 | Acc: 99.940% (49970/50000)\n",
      "(0.8035685078498318, 0.9994)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 24ms | Tot: 2s387ms | Loss: 1.1831 | Acc: 85.630% (8563/10000)\n",
      "\n",
      "===> epoch: 160/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 97ms | Tot: 44s880ms | Loss: 0.0017 | Acc: 99.950% (49975/50000) [==============================>.................................................]  Step: 103ms | Tot: 16s803ms | Loss: 0.0016 | Acc: 99.952% (18891/18900)\n",
      "(0.8591762629463915, 0.9995)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 23ms | Tot: 2s387ms | Loss: 1.2503 | Acc: 85.300% (8530/10000)\n",
      "\n",
      "===> epoch: 161/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 97ms | Tot: 45s5ms | Loss: 0.0025 | Acc: 99.930% (49965/50000)))\n",
      "(1.2688677095187586, 0.9993)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 23ms | Tot: 2s249ms | Loss: 1.1895 | Acc: 85.430% (8543/10000)\n",
      "\n",
      "===> epoch: 162/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 77ms | Tot: 44s921ms | Loss: 0.0016 | Acc: 99.958% (49979/50000) [==================================>.............................................]  Step: 105ms | Tot: 19s332ms | Loss: 0.0020 | Acc: 99.945% (21788/21800)\n",
      "(0.7919348270672799, 0.99958)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 22ms | Tot: 2s211ms | Loss: 1.1719 | Acc: 85.590% (8559/10000)\n",
      "\n",
      "===> epoch: 163/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 79ms | Tot: 44s979ms | Loss: 0.0013 | Acc: 99.954% (49977/50000)=========>.....................................................................]  Step: 103ms | Tot: 6s152ms | Loss: 0.0011 | Acc: 99.938% (6496/6500)\n",
      "(0.6354930045347373, 0.99954)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 25ms | Tot: 2s356ms | Loss: 1.2069 | Acc: 85.330% (8533/10000)\n",
      "\n",
      "===> epoch: 164/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 99ms | Tot: 44s945ms | Loss: 0.0016 | Acc: 99.942% (49971/50000)\n",
      "(0.8153209604431595, 0.99942)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 24ms | Tot: 2s401ms | Loss: 1.2212 | Acc: 85.580% (8558/10000)============================>................................................]  Step: 25ms | Tot: 920ms | Loss: 1.2392 | Acc: 85.718% (3343/3900)\n",
      "\n",
      "===> epoch: 165/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 101ms | Tot: 44s982ms | Loss: 0.0015 | Acc: 99.944% (49972/50000)\n",
      "(0.7291368625458858, 0.99944)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 22ms | Tot: 2s314ms | Loss: 1.2383 | Acc: 85.460% (8546/10000)\n",
      "\n",
      "===> epoch: 166/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 83ms | Tot: 45s63ms | Loss: 0.0007 | Acc: 99.972% (49986/50000))\n",
      "(0.37402801891641957, 0.99972)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 23ms | Tot: 2s205ms | Loss: 1.2714 | Acc: 85.570% (8557/10000)\n",
      "\n",
      "===> epoch: 167/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 82ms | Tot: 45s97ms | Loss: 0.0024 | Acc: 99.914% (49957/50000))=====>.........................................................................]  Step: 102ms | Tot: 3s259ms | Loss: 0.0004 | Acc: 100.000% (3900/3900)\n",
      "(1.2073511052041113, 0.99914)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 25ms | Tot: 2s231ms | Loss: 1.2911 | Acc: 85.330% (8533/10000)\n",
      "\n",
      "===> epoch: 168/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 83ms | Tot: 44s963ms | Loss: 0.0015 | Acc: 99.954% (49977/50000)=====>.........................................................................]  Step: 101ms | Tot: 3s749ms | Loss: 0.0004 | Acc: 100.000% (3800/3800)\n",
      "(0.7432503616687995, 0.99954)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 24ms | Tot: 2s385ms | Loss: 1.2715 | Acc: 85.590% (8559/10000)\n",
      "\n",
      "===> epoch: 169/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 100ms | Tot: 44s993ms | Loss: 0.0022 | Acc: 99.940% (49970/50000)\n",
      "(1.0859480946379563, 0.9994)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 24ms | Tot: 2s420ms | Loss: 1.2454 | Acc: 85.480% (8548/10000)\n",
      "\n",
      "===> epoch: 170/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 100ms | Tot: 45s3ms | Loss: 0.0020 | Acc: 99.924% (49962/50000))[=========================>......................................................]  Step: 97ms | Tot: 14s191ms | Loss: 0.0019 | Acc: 99.932% (16089/16100)\n",
      "(1.0082151331652653, 0.99924)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 22ms | Tot: 2s282ms | Loss: 1.2618 | Acc: 85.520% (8552/10000)\n",
      "\n",
      "===> epoch: 171/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 78ms | Tot: 45s33ms | Loss: 0.0028 | Acc: 99.908% (49954/50000)) [==========================================>.....................................]  Step: 102ms | Tot: 22s959ms | Loss: 0.0023 | Acc: 99.916% (26278/26300) [=========================================================================>......]  Step: 101ms | Tot: 41s678ms | Loss: 0.0029 | Acc: 99.900% (46154/46200)\n",
      "(1.38503909614019, 0.99908)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 23ms | Tot: 2s211ms | Loss: 1.1933 | Acc: 85.670% (8567/10000)\n",
      "\n",
      "===> epoch: 172/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 78ms | Tot: 44s970ms | Loss: 0.0012 | Acc: 99.956% (49978/50000)\n",
      "(0.5858111200143412, 0.99956)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 24ms | Tot: 2s260ms | Loss: 1.2315 | Acc: 85.670% (8567/10000)\n",
      "\n",
      "===> epoch: 173/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 97ms | Tot: 44s922ms | Loss: 0.0012 | Acc: 99.964% (49982/50000)\n",
      "(0.6146115600486155, 0.99964)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 25ms | Tot: 2s381ms | Loss: 1.2556 | Acc: 85.410% (8541/10000)\n",
      "\n",
      "===> epoch: 174/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 95ms | Tot: 44s887ms | Loss: 0.0015 | Acc: 99.954% (49977/50000)\n",
      "(0.7512786908062026, 0.99954)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 24ms | Tot: 2s402ms | Loss: 1.2279 | Acc: 85.610% (8561/10000)\n",
      "\n",
      "===> epoch: 175/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 98ms | Tot: 44s834ms | Loss: 0.0019 | Acc: 99.936% (49968/50000)\n",
      "(0.9649018169498049, 0.99936)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 23ms | Tot: 2s217ms | Loss: 1.2738 | Acc: 85.750% (8575/10000)\n",
      "\n",
      "===> epoch: 176/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 79ms | Tot: 45s27ms | Loss: 0.0020 | Acc: 99.940% (49970/50000)) [====================================>...........................................]  Step: 104ms | Tot: 20s339ms | Loss: 0.0010 | Acc: 99.965% (22692/22700)\n",
      "(1.011862431609643, 0.9994)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 23ms | Tot: 2s212ms | Loss: 1.1891 | Acc: 85.690% (8569/10000)\n",
      "\n",
      "===> epoch: 177/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 84ms | Tot: 44s975ms | Loss: 0.0019 | Acc: 99.932% (49966/50000)\n",
      "(0.9593036723413206, 0.99932)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 25ms | Tot: 2s350ms | Loss: 1.2339 | Acc: 85.360% (8536/10000)\n",
      "\n",
      "===> epoch: 178/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 99ms | Tot: 44s969ms | Loss: 0.0016 | Acc: 99.942% (49971/50000) [===================================>............................................]  Step: 99ms | Tot: 20s576ms | Loss: 0.0014 | Acc: 99.954% (21890/21900)\n",
      "(0.7996788344146353, 0.99942)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 24ms | Tot: 2s396ms | Loss: 1.2447 | Acc: 85.490% (8549/10000)\n",
      "\n",
      "===> epoch: 179/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 101ms | Tot: 45s126ms | Loss: 0.0016 | Acc: 99.946% (49973/50000)[=========================>......................................................]  Step: 102ms | Tot: 14s864ms | Loss: 0.0020 | Acc: 99.938% (16190/16200)\n",
      "(0.8154120008759946, 0.99946)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 23ms | Tot: 2s346ms | Loss: 1.2340 | Acc: 85.800% (8580/10000)\n",
      "\n",
      "===> epoch: 180/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 82ms | Tot: 45s160ms | Loss: 0.0017 | Acc: 99.938% (49969/50000)\n",
      "(0.8306691120294545, 0.99938)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 23ms | Tot: 2s218ms | Loss: 1.2352 | Acc: 85.540% (8554/10000)\n",
      "\n",
      "===> epoch: 181/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 83ms | Tot: 45s67ms | Loss: 0.0018 | Acc: 99.940% (49970/50000))\n",
      "(0.9243359732433873, 0.9994)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 27ms | Tot: 2s219ms | Loss: 1.2245 | Acc: 85.760% (8576/10000)\n",
      "\n",
      "===> epoch: 182/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 83ms | Tot: 45s74ms | Loss: 0.0009 | Acc: 99.972% (49986/50000))\n",
      "(0.4317863298838347, 0.99972)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 25ms | Tot: 2s398ms | Loss: 1.2894 | Acc: 85.960% (8596/10000)\n",
      "\n",
      "===> epoch: 183/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 101ms | Tot: 45s111ms | Loss: 0.0013 | Acc: 99.960% (49980/50000)[============================================================================>...]  Step: 101ms | Tot: 42s784ms | Loss: 0.0014 | Acc: 99.960% (47681/47700)\n",
      "(0.6723115873002143, 0.9996)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 24ms | Tot: 2s388ms | Loss: 1.2721 | Acc: 85.890% (8589/10000)\n",
      "\n",
      "===> epoch: 184/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 99ms | Tot: 44s982ms | Loss: 0.0011 | Acc: 99.964% (49982/50000) [=============================================>..................................]  Step: 101ms | Tot: 24s438ms | Loss: 0.0007 | Acc: 99.979% (28194/28200)\n",
      "(0.5446175558786024, 0.99964)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 22ms | Tot: 2s276ms | Loss: 1.3353 | Acc: 85.220% (8522/10000)\n",
      "\n",
      "===> epoch: 185/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 80ms | Tot: 44s961ms | Loss: 0.0023 | Acc: 99.926% (49963/50000) [========================================>.......................................]  Step: 102ms | Tot: 22s300ms | Loss: 0.0021 | Acc: 99.938% (25584/25600) [==================================================================>.............]  Step: 103ms | Tot: 37s140ms | Loss: 0.0023 | Acc: 99.926% (41669/41700)\n",
      "(1.1687182766716546, 0.99926)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 22ms | Tot: 2s233ms | Loss: 1.2716 | Acc: 85.300% (8530/10000)\n",
      "\n",
      "===> epoch: 186/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 78ms | Tot: 45s100ms | Loss: 0.0008 | Acc: 99.978% (49989/50000) [===============================>................................................]  Step: 105ms | Tot: 17s82ms | Loss: 0.0005 | Acc: 99.990% (19598/19600)\n",
      "(0.39464051530922006, 0.99978)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 25ms | Tot: 2s321ms | Loss: 1.3137 | Acc: 85.710% (8571/10000)\n",
      "\n",
      "===> epoch: 187/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 97ms | Tot: 45s1ms | Loss: 0.0019 | Acc: 99.930% (49965/50000))) [======================================================>.........................]  Step: 102ms | Tot: 30s976ms | Loss: 0.0016 | Acc: 99.939% (34179/34200)\n",
      "(0.9583103646303925, 0.9993)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 24ms | Tot: 2s384ms | Loss: 1.3212 | Acc: 85.380% (8538/10000)\n",
      "\n",
      "===> epoch: 188/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 96ms | Tot: 44s832ms | Loss: 0.0022 | Acc: 99.930% (49965/50000)\n",
      "(1.1213971169236174, 0.9993)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 22ms | Tot: 2s368ms | Loss: 1.2814 | Acc: 85.430% (8543/10000)\n",
      "\n",
      "===> epoch: 189/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 77ms | Tot: 45s27ms | Loss: 0.0015 | Acc: 99.946% (49973/50000)) [==================================================>.............................]  Step: 102ms | Tot: 28s488ms | Loss: 0.0016 | Acc: 99.939% (31381/31400)\n",
      "(0.7436400070736227, 0.99946)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 23ms | Tot: 2s225ms | Loss: 1.2347 | Acc: 85.610% (8561/10000)\n",
      "\n",
      "===> epoch: 190/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 78ms | Tot: 45s33ms | Loss: 0.0014 | Acc: 99.966% (49983/50000)) [===================================>............................................]  Step: 104ms | Tot: 20s2ms | Loss: 0.0023 | Acc: 99.937% (22186/22200)\n",
      "(0.6806077878756014, 0.99966)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 23ms | Tot: 2s213ms | Loss: 1.2265 | Acc: 85.640% (8564/10000)\n",
      "\n",
      "===> epoch: 191/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 83ms | Tot: 45s99ms | Loss: 0.0018 | Acc: 99.944% (49972/50000)) [============================>...................................................]  Step: 103ms | Tot: 16s315ms | Loss: 0.0024 | Acc: 99.938% (17789/17800) [==================================================================>.............]  Step: 97ms | Tot: 38s197ms | Loss: 0.0020 | Acc: 99.940% (41575/41600)\n",
      "(0.9236311524115308, 0.99944)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 24ms | Tot: 2s369ms | Loss: 1.2294 | Acc: 85.560% (8556/10000)\n",
      "\n",
      "===> epoch: 192/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 99ms | Tot: 45s38ms | Loss: 0.0017 | Acc: 99.954% (49977/50000))\n",
      "(0.8442459138437926, 0.99954)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 24ms | Tot: 2s397ms | Loss: 1.2511 | Acc: 85.450% (8545/10000)\n",
      "\n",
      "===> epoch: 193/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 101ms | Tot: 45s27ms | Loss: 0.0020 | Acc: 99.950% (49975/50000)\n",
      "(0.977151724738178, 0.9995)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 22ms | Tot: 2s323ms | Loss: 1.2403 | Acc: 85.670% (8567/10000)\n",
      "\n",
      "===> epoch: 194/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 85ms | Tot: 45s158ms | Loss: 0.0010 | Acc: 99.966% (49983/50000)\n",
      "(0.49515526668506027, 0.99966)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 23ms | Tot: 2s215ms | Loss: 1.2815 | Acc: 85.640% (8564/10000)\n",
      "\n",
      "===> epoch: 195/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 83ms | Tot: 45s129ms | Loss: 0.0012 | Acc: 99.954% (49977/50000)=============>................................................................]  Step: 101ms | Tot: 8s885ms | Loss: 0.0010 | Acc: 99.957% (9396/9400) [==============================================================>.................]  Step: 103ms | Tot: 34s870ms | Loss: 0.0013 | Acc: 99.951% (38981/39000)\n",
      "(0.6117498459204285, 0.99954)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 24ms | Tot: 2s233ms | Loss: 1.3141 | Acc: 85.570% (8557/10000)\n",
      "\n",
      "===> epoch: 196/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 104ms | Tot: 45s50ms | Loss: 0.0021 | Acc: 99.932% (49966/50000) [================================>...............................................]  Step: 95ms | Tot: 18s586ms | Loss: 0.0021 | Acc: 99.932% (20486/20500)\n",
      "(1.061202582603073, 0.99932)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 23ms | Tot: 2s393ms | Loss: 1.2748 | Acc: 85.410% (8541/10000)\n",
      "\n",
      "===> epoch: 197/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 102ms | Tot: 45s87ms | Loss: 0.0013 | Acc: 99.960% (49980/50000)\n",
      "(0.6440529761034668, 0.9996)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 24ms | Tot: 2s403ms | Loss: 1.2848 | Acc: 85.860% (8586/10000)\n",
      "\n",
      "===> epoch: 198/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 98ms | Tot: 44s893ms | Loss: 0.0037 | Acc: 99.906% (49953/50000)=================>..............................................................]  Step: 98ms | Tot: 8s736ms | Loss: 0.0011 | Acc: 99.963% (10696/10700) [========================================================================>.......]  Step: 102ms | Tot: 40s491ms | Loss: 0.0039 | Acc: 99.905% (45457/45500)\n",
      "(1.8453719424241513, 0.99906)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 22ms | Tot: 2s258ms | Loss: 1.2444 | Acc: 85.390% (8539/10000)\n",
      "\n",
      "===> epoch: 199/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 78ms | Tot: 45s18ms | Loss: 0.0026 | Acc: 99.908% (49954/50000)) [====================================================================>...........]  Step: 96ms | Tot: 38s815ms | Loss: 0.0028 | Acc: 99.907% (43060/43100)\n",
      "(1.2938325348602575, 0.99908)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 22ms | Tot: 2s233ms | Loss: 1.2072 | Acc: 85.550% (8555/10000)\n",
      "\n",
      "===> epoch: 200/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 78ms | Tot: 44s976ms | Loss: 0.0008 | Acc: 99.978% (49989/50000)\n",
      "(0.3841238634356614, 0.99978)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 25ms | Tot: 2s309ms | Loss: 1.2543 | Acc: 85.530% (8553/10000)\n",
      "===> BEST ACC. PERFORMANCE: 85.960%\n",
      "Checkpoint saved to model.pth\n"
     ]
    }
   ],
   "source": [
    "%run cifar10threshnet\\main.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "The model has 14371858 trainable parameters.\n",
      "\n",
      "===> epoch: 1/200\n",
      "train:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\alexa\\mambaforge\\envs\\triplenet\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:131: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n",
      "c:\\Users\\alexa\\mambaforge\\envs\\triplenet\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[1;32m~\\OneDrive\\01 Frankfurt School\\Semester 3\\Deep Learning\\TripleNetDL\\cifar10threshnet\\main.py:149\u001b[0m\n\u001b[0;32m    146\u001b[0m                 \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msave()\n\u001b[0;32m    148\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m__name__\u001b[39m \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39m__main__\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m--> 149\u001b[0m     main()\n",
      "File \u001b[1;32m~\\OneDrive\\01 Frankfurt School\\Semester 3\\Deep Learning\\TripleNetDL\\cifar10threshnet\\main.py:33\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     30\u001b[0m args \u001b[39m=\u001b[39m parser\u001b[39m.\u001b[39mparse_args()\n\u001b[0;32m     32\u001b[0m solver \u001b[39m=\u001b[39m Solver(args)\n\u001b[1;32m---> 33\u001b[0m solver\u001b[39m.\u001b[39;49mrun()\n",
      "File \u001b[1;32m~\\OneDrive\\01 Frankfurt School\\Semester 3\\Deep Learning\\TripleNetDL\\cifar10threshnet\\main.py:140\u001b[0m, in \u001b[0;36mSolver.run\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mscheduler\u001b[39m.\u001b[39mstep(epoch)\n\u001b[0;32m    139\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m===> epoch: \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m/200\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m epoch)\n\u001b[1;32m--> 140\u001b[0m train_result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain()\n\u001b[0;32m    141\u001b[0m \u001b[39mprint\u001b[39m(train_result)\n\u001b[0;32m    142\u001b[0m test_result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtest()\n",
      "File \u001b[1;32m~\\OneDrive\\01 Frankfurt School\\Semester 3\\Deep Learning\\TripleNetDL\\cifar10threshnet\\main.py:86\u001b[0m, in \u001b[0;36mSolver.train\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     84\u001b[0m data, target \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39mto(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice), target\u001b[39m.\u001b[39mto(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice)\n\u001b[0;32m     85\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m---> 86\u001b[0m output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel(data)\n\u001b[0;32m     87\u001b[0m loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcriterion(output, target)\n\u001b[0;32m     88\u001b[0m loss\u001b[39m.\u001b[39mbackward()\n",
      "File \u001b[1;32mc:\\Users\\alexa\\mambaforge\\envs\\triplenet\\lib\\site-packages\\torch\\nn\\modules\\module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1106\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1107\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1108\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1109\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1110\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1111\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\OneDrive\\01 Frankfurt School\\Semester 3\\Deep Learning\\TripleNetDL\\cifar10threshnet\\models\\ThreshNet79.py:175\u001b[0m, in \u001b[0;36mThreshNet.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    173\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[0;32m    174\u001b[0m     \u001b[39mfor\u001b[39;00m layer \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbase:\n\u001b[1;32m--> 175\u001b[0m       x \u001b[39m=\u001b[39m layer(x)\n\u001b[0;32m    176\u001b[0m     \u001b[39mreturn\u001b[39;00m x\n",
      "File \u001b[1;32mc:\\Users\\alexa\\mambaforge\\envs\\triplenet\\lib\\site-packages\\torch\\nn\\modules\\module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1106\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1107\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1108\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1109\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1110\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1111\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\OneDrive\\01 Frankfurt School\\Semester 3\\Deep Learning\\TripleNetDL\\cifar10threshnet\\models\\ThreshNet79.py:22\u001b[0m, in \u001b[0;36mConvLayer.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[1;32m---> 22\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mforward(x)\n",
      "File \u001b[1;32mc:\\Users\\alexa\\mambaforge\\envs\\triplenet\\lib\\site-packages\\torch\\nn\\modules\\container.py:141\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    139\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[0;32m    140\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[1;32m--> 141\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[0;32m    142\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\alexa\\mambaforge\\envs\\triplenet\\lib\\site-packages\\torch\\nn\\modules\\module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1106\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1107\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1108\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1109\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1110\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1111\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\alexa\\mambaforge\\envs\\triplenet\\lib\\site-packages\\torch\\nn\\modules\\batchnorm.py:148\u001b[0m, in \u001b[0;36m_BatchNorm.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    145\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrack_running_stats:\n\u001b[0;32m    146\u001b[0m     \u001b[39m# TODO: if statement only here to tell the jit to skip emitting this when it is None\u001b[39;00m\n\u001b[0;32m    147\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_batches_tracked \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:  \u001b[39m# type: ignore[has-type]\u001b[39;00m\n\u001b[1;32m--> 148\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnum_batches_tracked\u001b[39m.\u001b[39;49madd_(\u001b[39m1\u001b[39;49m)  \u001b[39m# type: ignore[has-type]\u001b[39;00m\n\u001b[0;32m    149\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmomentum \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:  \u001b[39m# use cumulative moving average\u001b[39;00m\n\u001b[0;32m    150\u001b[0m             exponential_average_factor \u001b[39m=\u001b[39m \u001b[39m1.0\u001b[39m \u001b[39m/\u001b[39m \u001b[39mfloat\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_batches_tracked)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%run cifar10threshnet\\main.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "triplenet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
