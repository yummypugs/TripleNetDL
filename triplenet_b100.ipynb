{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "The model has 14142526 trainable parameters.\n",
      "\n",
      "===> epoch: 1/200\n",
      "train:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\alexa\\mambaforge\\envs\\triplenet\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:131: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n",
      "c:\\Users\\alexa\\mambaforge\\envs\\triplenet\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 500/500 [================================================================================>]  Step: 77ms | Tot: 38s566ms | Loss: 1.5813 | Acc: 40.496% (20248/50000)\n",
      "(790.6542510390282, 0.40496)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 21ms | Tot: 2s189ms | Loss: 1.1885 | Acc: 56.120% (5612/10000)\n",
      "\n",
      "===> epoch: 2/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 79ms | Tot: 38s659ms | Loss: 1.0669 | Acc: 61.824% (30912/50000)\n",
      "(533.4640101194382, 0.61824)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 21ms | Tot: 2s193ms | Loss: 1.0955 | Acc: 61.860% (6186/10000)\n",
      "\n",
      "===> epoch: 3/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 77ms | Tot: 38s576ms | Loss: 0.8668 | Acc: 69.898% (34949/50000)\n",
      "(433.40187960863113, 0.69898)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 22ms | Tot: 2s181ms | Loss: 0.9671 | Acc: 66.650% (6665/10000)\n",
      "\n",
      "===> epoch: 4/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 81ms | Tot: 38s595ms | Loss: 0.7465 | Acc: 74.434% (37217/50000)\n",
      "(373.2543658018112, 0.74434)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 25ms | Tot: 2s350ms | Loss: 0.8342 | Acc: 72.000% (7200/10000)\n",
      "\n",
      "===> epoch: 5/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 76ms | Tot: 38s647ms | Loss: 0.6604 | Acc: 77.700% (38850/50000)\n",
      "(330.18219578266144, 0.777)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 23ms | Tot: 2s188ms | Loss: 0.7974 | Acc: 74.040% (7404/10000)=================================>...........................................]  Step: 23ms | Tot: 1s | Loss: 0.8006 | Acc: 74.174% (3412/4600)\n",
      "\n",
      "===> epoch: 6/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 77ms | Tot: 38s775ms | Loss: 0.5936 | Acc: 79.942% (39971/50000)\n",
      "(296.8194600343704, 0.79942)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 22ms | Tot: 2s199ms | Loss: 0.8045 | Acc: 74.350% (7435/10000)\n",
      "\n",
      "===> epoch: 7/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 76ms | Tot: 38s624ms | Loss: 0.5427 | Acc: 81.770% (40885/50000)\n",
      "(271.33593758940697, 0.8177)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 22ms | Tot: 2s190ms | Loss: 0.6780 | Acc: 77.360% (7736/10000)\n",
      "\n",
      "===> epoch: 8/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 76ms | Tot: 38s313ms | Loss: 0.4839 | Acc: 83.732% (41866/50000)\n",
      "(241.93565398454666, 0.83732)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 22ms | Tot: 2s188ms | Loss: 0.7488 | Acc: 76.310% (7631/10000)\n",
      "\n",
      "===> epoch: 9/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 77ms | Tot: 38s196ms | Loss: 0.4532 | Acc: 84.728% (42364/50000)\n",
      "(226.61387413740158, 0.84728)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 21ms | Tot: 2s185ms | Loss: 0.7504 | Acc: 76.470% (7647/10000)\n",
      "\n",
      "===> epoch: 10/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 76ms | Tot: 38s200ms | Loss: 0.4154 | Acc: 86.032% (43016/50000)\n",
      "(207.72129882872105, 0.86032)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 21ms | Tot: 2s189ms | Loss: 0.6291 | Acc: 79.950% (7995/10000)\n",
      "\n",
      "===> epoch: 11/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 76ms | Tot: 38s311ms | Loss: 0.3834 | Acc: 87.226% (43613/50000)\n",
      "(191.71786975860596, 0.87226)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 21ms | Tot: 2s191ms | Loss: 0.6716 | Acc: 78.980% (7898/10000)\n",
      "\n",
      "===> epoch: 12/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 76ms | Tot: 38s198ms | Loss: 0.3456 | Acc: 88.358% (44179/50000)\n",
      "(172.82144212722778, 0.88358)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 21ms | Tot: 2s187ms | Loss: 0.5896 | Acc: 81.580% (8158/10000)\n",
      "\n",
      "===> epoch: 13/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 76ms | Tot: 38s212ms | Loss: 0.3253 | Acc: 89.152% (44576/50000)\n",
      "(162.66551919281483, 0.89152)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 21ms | Tot: 2s193ms | Loss: 0.6785 | Acc: 79.560% (7956/10000)\n",
      "\n",
      "===> epoch: 14/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 76ms | Tot: 38s264ms | Loss: 0.2924 | Acc: 90.090% (45045/50000)\n",
      "(146.18430864065886, 0.9009)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 21ms | Tot: 2s188ms | Loss: 0.6751 | Acc: 80.140% (8014/10000)\n",
      "\n",
      "===> epoch: 15/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 77ms | Tot: 38s402ms | Loss: 0.2733 | Acc: 90.818% (45409/50000)\n",
      "(136.63503423333168, 0.90818)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 22ms | Tot: 2s179ms | Loss: 0.7012 | Acc: 79.720% (7972/10000)\n",
      "\n",
      "===> epoch: 16/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 77ms | Tot: 38s261ms | Loss: 0.2498 | Acc: 91.684% (45842/50000)\n",
      "(124.92089399695396, 0.91684)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 21ms | Tot: 2s189ms | Loss: 0.5786 | Acc: 83.000% (8300/10000)\n",
      "\n",
      "===> epoch: 17/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 76ms | Tot: 38s261ms | Loss: 0.2350 | Acc: 92.306% (46153/50000)\n",
      "(117.48272519558668, 0.92306)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 22ms | Tot: 2s194ms | Loss: 0.6551 | Acc: 82.020% (8202/10000)\n",
      "\n",
      "===> epoch: 18/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 77ms | Tot: 38s286ms | Loss: 0.2221 | Acc: 92.668% (46334/50000)\n",
      "(111.03544523194432, 0.92668)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 22ms | Tot: 2s188ms | Loss: 0.6428 | Acc: 82.270% (8227/10000)\n",
      "\n",
      "===> epoch: 19/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 76ms | Tot: 38s306ms | Loss: 0.1905 | Acc: 93.682% (46841/50000)\n",
      "(95.24936679750681, 0.93682)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 22ms | Tot: 2s196ms | Loss: 0.6275 | Acc: 82.660% (8266/10000)\n",
      "\n",
      "===> epoch: 20/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 76ms | Tot: 38s339ms | Loss: 0.1758 | Acc: 94.042% (47021/50000)\n",
      "(87.8765546567738, 0.94042)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 21ms | Tot: 2s187ms | Loss: 0.6107 | Acc: 82.720% (8272/10000)\n",
      "\n",
      "===> epoch: 21/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 77ms | Tot: 38s307ms | Loss: 0.1673 | Acc: 94.382% (47191/50000)\n",
      "(83.66359731182456, 0.94382)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 22ms | Tot: 2s187ms | Loss: 0.7746 | Acc: 80.270% (8027/10000)\n",
      "\n",
      "===> epoch: 22/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 78ms | Tot: 39s594ms | Loss: 0.1539 | Acc: 94.866% (47433/50000)\n",
      "(76.92947067134082, 0.94866)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 22ms | Tot: 2s243ms | Loss: 0.6056 | Acc: 83.340% (8334/10000)\n",
      "\n",
      "===> epoch: 23/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 76ms | Tot: 39s185ms | Loss: 0.1421 | Acc: 95.140% (47570/50000)\n",
      "(71.0360669568181, 0.9514)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 22ms | Tot: 2s252ms | Loss: 0.6120 | Acc: 83.340% (8334/10000)\n",
      "\n",
      "===> epoch: 24/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 80ms | Tot: 38s707ms | Loss: 0.1336 | Acc: 95.498% (47749/50000)\n",
      "(66.81181875616312, 0.95498)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 23ms | Tot: 2s306ms | Loss: 0.6283 | Acc: 83.620% (8362/10000)\n",
      "\n",
      "===> epoch: 25/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 104ms | Tot: 47s407ms | Loss: 0.1170 | Acc: 95.926% (47963/50000)\n",
      "(58.51103614270687, 0.95926)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 28ms | Tot: 2s721ms | Loss: 0.7109 | Acc: 83.560% (8356/10000)\n",
      "\n",
      "===> epoch: 26/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 96ms | Tot: 49s679ms | Loss: 0.1170 | Acc: 96.156% (48078/50000)\n",
      "(58.47937383688986, 0.96156)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 27ms | Tot: 2s487ms | Loss: 0.6869 | Acc: 82.580% (8258/10000)\n",
      "\n",
      "===> epoch: 27/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 112ms | Tot: 51s91ms | Loss: 0.1091 | Acc: 96.314% (48157/50000)\n",
      "(54.5343017950654, 0.96314)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 23ms | Tot: 2s589ms | Loss: 0.6759 | Acc: 83.490% (8349/10000)\n",
      "\n",
      "===> epoch: 28/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 88ms | Tot: 49s327ms | Loss: 0.1028 | Acc: 96.564% (48282/50000)===========>..................................................................]  Step: 106ms | Tot: 7s926ms | Loss: 0.0829 | Acc: 97.024% (8247/8500) [==================================>.............................................]  Step: 110ms | Tot: 20s683ms | Loss: 0.0917 | Acc: 96.894% (21123/21800)\n",
      "(51.411356029100716, 0.96564)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 27ms | Tot: 2s524ms | Loss: 0.6461 | Acc: 84.260% (8426/10000)\n",
      "\n",
      "===> epoch: 29/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 109ms | Tot: 49s968ms | Loss: 0.1179 | Acc: 96.236% (48118/50000)\n",
      "(58.97137790173292, 0.96236)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 24ms | Tot: 2s507ms | Loss: 0.8429 | Acc: 79.770% (7977/10000)\n",
      "\n",
      "===> epoch: 30/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 76ms | Tot: 47s253ms | Loss: 0.0991 | Acc: 96.688% (48344/50000)\n",
      "(49.559048297815025, 0.96688)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 22ms | Tot: 2s190ms | Loss: 0.6823 | Acc: 84.030% (8403/10000)\n",
      "\n",
      "===> epoch: 31/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 76ms | Tot: 38s238ms | Loss: 0.0866 | Acc: 97.176% (48588/50000)\n",
      "(43.30418777372688, 0.97176)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 22ms | Tot: 2s184ms | Loss: 0.6593 | Acc: 84.230% (8423/10000)\n",
      "\n",
      "===> epoch: 32/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 76ms | Tot: 38s225ms | Loss: 0.0785 | Acc: 97.456% (48728/50000)\n",
      "(39.25146375969052, 0.97456)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 22ms | Tot: 2s186ms | Loss: 0.6549 | Acc: 84.670% (8467/10000)\n",
      "\n",
      "===> epoch: 33/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 77ms | Tot: 38s252ms | Loss: 0.0768 | Acc: 97.468% (48734/50000)\n",
      "(38.39177107671276, 0.97468)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 22ms | Tot: 2s186ms | Loss: 0.6912 | Acc: 84.360% (8436/10000)\n",
      "\n",
      "===> epoch: 34/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 79ms | Tot: 38s268ms | Loss: 0.0767 | Acc: 97.398% (48699/50000)\n",
      "(38.34977667685598, 0.97398)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 22ms | Tot: 2s183ms | Loss: 0.6755 | Acc: 84.620% (8462/10000)\n",
      "\n",
      "===> epoch: 35/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 78ms | Tot: 38s379ms | Loss: 0.0734 | Acc: 97.556% (48778/50000)\n",
      "(36.69217919372022, 0.97556)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 22ms | Tot: 2s190ms | Loss: 0.7486 | Acc: 83.490% (8349/10000)\n",
      "\n",
      "===> epoch: 36/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 76ms | Tot: 38s256ms | Loss: 0.0681 | Acc: 97.738% (48869/50000)\n",
      "(34.04429769795388, 0.97738)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 21ms | Tot: 2s191ms | Loss: 0.7360 | Acc: 84.090% (8409/10000)\n",
      "\n",
      "===> epoch: 37/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 76ms | Tot: 38s298ms | Loss: 0.0690 | Acc: 97.686% (48843/50000)\n",
      "(34.49116084724665, 0.97686)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 22ms | Tot: 2s191ms | Loss: 0.6872 | Acc: 84.950% (8495/10000)\n",
      "\n",
      "===> epoch: 38/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 76ms | Tot: 38s262ms | Loss: 0.0654 | Acc: 97.832% (48916/50000)\n",
      "(32.70545448269695, 0.97832)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 21ms | Tot: 2s199ms | Loss: 0.7350 | Acc: 83.640% (8364/10000)\n",
      "\n",
      "===> epoch: 39/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 75ms | Tot: 38s446ms | Loss: 0.0631 | Acc: 97.866% (48933/50000)\n",
      "(31.531496400479227, 0.97866)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 23ms | Tot: 2s187ms | Loss: 0.7585 | Acc: 83.780% (8378/10000)\n",
      "\n",
      "===> epoch: 40/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 77ms | Tot: 38s246ms | Loss: 0.0645 | Acc: 97.836% (48918/50000)[===============================================================>................]  Step: 76ms | Tot: 30s279ms | Loss: 0.0620 | Acc: 97.944% (38786/39600)\n",
      "(32.27127059036866, 0.97836)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 24ms | Tot: 2s184ms | Loss: 0.7058 | Acc: 84.010% (8401/10000)\n",
      "\n",
      "===> epoch: 41/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 76ms | Tot: 38s208ms | Loss: 0.0577 | Acc: 98.108% (49054/50000)\n",
      "(28.85702835675329, 0.98108)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 22ms | Tot: 2s191ms | Loss: 0.7045 | Acc: 84.360% (8436/10000)\n",
      "\n",
      "===> epoch: 42/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 77ms | Tot: 38s211ms | Loss: 0.0765 | Acc: 97.530% (48765/50000)\n",
      "(38.23043314949609, 0.9753)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 22ms | Tot: 2s184ms | Loss: 0.7017 | Acc: 84.460% (8446/10000)\n",
      "\n",
      "===> epoch: 43/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 77ms | Tot: 38s188ms | Loss: 0.0533 | Acc: 98.238% (49119/50000)\n",
      "(26.630312969209626, 0.98238)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 22ms | Tot: 2s177ms | Loss: 0.7036 | Acc: 84.790% (8479/10000)\n",
      "\n",
      "===> epoch: 44/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 77ms | Tot: 38s352ms | Loss: 0.0563 | Acc: 98.070% (49035/50000)\n",
      "(28.137746575288475, 0.9807)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 22ms | Tot: 2s177ms | Loss: 0.7312 | Acc: 84.510% (8451/10000)\n",
      "\n",
      "===> epoch: 45/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 77ms | Tot: 38s246ms | Loss: 0.0473 | Acc: 98.446% (49223/50000)\n",
      "(23.637473421404138, 0.98446)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 22ms | Tot: 2s164ms | Loss: 0.8220 | Acc: 83.740% (8374/10000)\n",
      "\n",
      "===> epoch: 46/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 76ms | Tot: 38s27ms | Loss: 0.0517 | Acc: 98.240% (49120/50000)\n",
      "(25.868441197555512, 0.9824)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 22ms | Tot: 2s160ms | Loss: 0.7128 | Acc: 84.640% (8464/10000)\n",
      "\n",
      "===> epoch: 47/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 76ms | Tot: 38s36ms | Loss: 0.0428 | Acc: 98.604% (49302/50000)\n",
      "(21.407044638996013, 0.98604)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 22ms | Tot: 2s161ms | Loss: 0.8592 | Acc: 83.740% (8374/10000)\n",
      "\n",
      "===> epoch: 48/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 76ms | Tot: 38s129ms | Loss: 0.0485 | Acc: 98.362% (49181/50000)\n",
      "(24.236360726878047, 0.98362)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 21ms | Tot: 2s159ms | Loss: 0.8323 | Acc: 83.410% (8341/10000)\n",
      "\n",
      "===> epoch: 49/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 76ms | Tot: 38s10ms | Loss: 0.0488 | Acc: 98.314% (49157/50000)\n",
      "(24.402795979985967, 0.98314)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 22ms | Tot: 2s164ms | Loss: 0.7547 | Acc: 84.430% (8443/10000)\n",
      "\n",
      "===> epoch: 50/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 76ms | Tot: 38s31ms | Loss: 0.0452 | Acc: 98.494% (49247/50000)\n",
      "(22.614604254020378, 0.98494)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 22ms | Tot: 2s167ms | Loss: 0.7430 | Acc: 85.060% (8506/10000)\n",
      "\n",
      "===> epoch: 51/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 77ms | Tot: 38s38ms | Loss: 0.0431 | Acc: 98.550% (49275/50000)\n",
      "(21.54843480559066, 0.9855)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 22ms | Tot: 2s165ms | Loss: 0.7289 | Acc: 85.160% (8516/10000)\n",
      "\n",
      "===> epoch: 52/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 76ms | Tot: 38s20ms | Loss: 0.0438 | Acc: 98.504% (49252/50000)\n",
      "(21.90925901848823, 0.98504)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 21ms | Tot: 2s164ms | Loss: 0.7382 | Acc: 85.020% (8502/10000)\n",
      "\n",
      "===> epoch: 53/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 76ms | Tot: 38s138ms | Loss: 0.0408 | Acc: 98.632% (49316/50000)\n",
      "(20.409368623804767, 0.98632)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 22ms | Tot: 2s167ms | Loss: 0.8039 | Acc: 84.180% (8418/10000)\n",
      "\n",
      "===> epoch: 54/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 76ms | Tot: 38s35ms | Loss: 0.0426 | Acc: 98.536% (49268/50000) [===================================================>............................]  Step: 76ms | Tot: 24s614ms | Loss: 0.0397 | Acc: 98.642% (31960/32400)\n",
      "(21.3172372689005, 0.98536)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 22ms | Tot: 2s167ms | Loss: 0.7620 | Acc: 84.340% (8434/10000)\n",
      "\n",
      "===> epoch: 55/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 76ms | Tot: 38s44ms | Loss: 0.0412 | Acc: 98.666% (49333/50000)\n",
      "(20.612346289446577, 0.98666)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 22ms | Tot: 2s165ms | Loss: 0.7579 | Acc: 85.070% (8507/10000)\n",
      "\n",
      "===> epoch: 56/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 77ms | Tot: 38s72ms | Loss: 0.0402 | Acc: 98.684% (49342/50000)\n",
      "(20.095656135235913, 0.98684)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 21ms | Tot: 2s177ms | Loss: 0.7422 | Acc: 85.110% (8511/10000)\n",
      "\n",
      "===> epoch: 57/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 76ms | Tot: 38s176ms | Loss: 0.0379 | Acc: 98.758% (49379/50000)\n",
      "(18.972565414500423, 0.98758)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 22ms | Tot: 2s159ms | Loss: 0.7674 | Acc: 84.960% (8496/10000)\n",
      "\n",
      "===> epoch: 58/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 76ms | Tot: 38s54ms | Loss: 0.0370 | Acc: 98.814% (49407/50000)\n",
      "(18.51056760409847, 0.98814)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 21ms | Tot: 2s165ms | Loss: 0.7820 | Acc: 85.580% (8558/10000)\n",
      "\n",
      "===> epoch: 59/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 75ms | Tot: 38s56ms | Loss: 0.0367 | Acc: 98.782% (49391/50000)\n",
      "(18.35860949428752, 0.98782)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 21ms | Tot: 2s158ms | Loss: 0.7827 | Acc: 84.520% (8452/10000)\n",
      "\n",
      "===> epoch: 60/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 76ms | Tot: 38s252ms | Loss: 0.0383 | Acc: 98.722% (49361/50000)\n",
      "(19.12666382966563, 0.98722)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 22ms | Tot: 2s156ms | Loss: 0.7596 | Acc: 85.310% (8531/10000)\n",
      "\n",
      "===> epoch: 61/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 76ms | Tot: 38s99ms | Loss: 0.0381 | Acc: 98.738% (49369/50000)\n",
      "(19.026045918348245, 0.98738)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 22ms | Tot: 2s167ms | Loss: 0.7654 | Acc: 85.640% (8564/10000)\n",
      "\n",
      "===> epoch: 62/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 77ms | Tot: 38s196ms | Loss: 0.0815 | Acc: 97.460% (48730/50000)\n",
      "(40.74083478853572, 0.9746)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 22ms | Tot: 2s175ms | Loss: 0.7207 | Acc: 85.120% (8512/10000)\n",
      "\n",
      "===> epoch: 63/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 76ms | Tot: 38s81ms | Loss: 0.0321 | Acc: 98.936% (49468/50000)\n",
      "(16.073985382332467, 0.98936)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 22ms | Tot: 2s157ms | Loss: 0.7624 | Acc: 85.260% (8526/10000)\n",
      "\n",
      "===> epoch: 64/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 76ms | Tot: 38s64ms | Loss: 0.0253 | Acc: 99.152% (49576/50000)\n",
      "(12.641725922207115, 0.99152)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 22ms | Tot: 2s161ms | Loss: 0.8195 | Acc: 85.260% (8526/10000)\n",
      "\n",
      "===> epoch: 65/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 77ms | Tot: 38s62ms | Loss: 0.0281 | Acc: 99.052% (49526/50000)\n",
      "(14.053874109842582, 0.99052)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 22ms | Tot: 2s163ms | Loss: 0.8269 | Acc: 84.770% (8477/10000)\n",
      "\n",
      "===> epoch: 66/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 77ms | Tot: 38s193ms | Loss: 0.0257 | Acc: 99.130% (49565/50000)\n",
      "(12.843333839613479, 0.9913)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 22ms | Tot: 2s162ms | Loss: 0.7900 | Acc: 85.380% (8538/10000)\n",
      "\n",
      "===> epoch: 67/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 76ms | Tot: 38s82ms | Loss: 0.0337 | Acc: 98.844% (49422/50000)\n",
      "(16.868589358055033, 0.98844)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 24ms | Tot: 2s168ms | Loss: 0.8131 | Acc: 85.220% (8522/10000)\n",
      "\n",
      "===> epoch: 68/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 77ms | Tot: 38s139ms | Loss: 0.0315 | Acc: 98.994% (49497/50000)\n",
      "(15.744536442682147, 0.98994)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 21ms | Tot: 2s162ms | Loss: 0.8169 | Acc: 84.720% (8472/10000)\n",
      "\n",
      "===> epoch: 69/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 77ms | Tot: 38s43ms | Loss: 0.0294 | Acc: 99.030% (49515/50000)\n",
      "(14.703772465058137, 0.9903)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 22ms | Tot: 2s171ms | Loss: 0.8093 | Acc: 84.800% (8480/10000)\n",
      "\n",
      "===> epoch: 70/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 75ms | Tot: 38s63ms | Loss: 0.0334 | Acc: 98.832% (49416/50000) [============================================>...................................]  Step: 76ms | Tot: 21s210ms | Loss: 0.0261 | Acc: 99.082% (27644/27900)\n",
      "(16.685536003729794, 0.98832)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 22ms | Tot: 2s157ms | Loss: 0.7735 | Acc: 85.650% (8565/10000).........................................................................]  Step: 25ms | Tot: 95ms | Loss: 0.7254 | Acc: 85.600% (428/500)\n",
      "\n",
      "===> epoch: 71/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 76ms | Tot: 38s218ms | Loss: 0.0301 | Acc: 98.972% (49486/50000)\n",
      "(15.057985955267213, 0.98972)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 21ms | Tot: 2s161ms | Loss: 0.8091 | Acc: 85.000% (8500/10000)\n",
      "\n",
      "===> epoch: 72/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 76ms | Tot: 38s81ms | Loss: 0.0290 | Acc: 99.074% (49537/50000)\n",
      "(14.478173495503142, 0.99074)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 21ms | Tot: 2s166ms | Loss: 0.8459 | Acc: 85.150% (8515/10000)\n",
      "\n",
      "===> epoch: 73/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 77ms | Tot: 38s68ms | Loss: 0.0257 | Acc: 99.160% (49580/50000)\n",
      "(12.851208238571417, 0.9916)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 21ms | Tot: 2s165ms | Loss: 0.8105 | Acc: 85.390% (8539/10000)\n",
      "\n",
      "===> epoch: 74/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 77ms | Tot: 38s89ms | Loss: 0.0308 | Acc: 98.976% (49488/50000)\n",
      "(15.414753522956744, 0.98976)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 22ms | Tot: 2s171ms | Loss: 0.8240 | Acc: 84.880% (8488/10000)\n",
      "\n",
      "===> epoch: 75/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 75ms | Tot: 38s197ms | Loss: 0.0116 | Acc: 99.594% (49797/50000)\n",
      "(5.806329430110054, 0.99594)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 21ms | Tot: 2s164ms | Loss: 0.8598 | Acc: 85.930% (8593/10000)\n",
      "\n",
      "===> epoch: 76/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 76ms | Tot: 38s88ms | Loss: 0.0068 | Acc: 99.792% (49896/50000)\n",
      "(3.3892153744382085, 0.99792)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 21ms | Tot: 2s171ms | Loss: 0.8757 | Acc: 86.260% (8626/10000)\n",
      "\n",
      "===> epoch: 77/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 75ms | Tot: 38s114ms | Loss: 0.0092 | Acc: 99.684% (49842/50000)\n",
      "(4.593110451300163, 0.99684)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 21ms | Tot: 2s165ms | Loss: 0.9153 | Acc: 86.230% (8623/10000)\n",
      "\n",
      "===> epoch: 78/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 76ms | Tot: 38s95ms | Loss: 0.0083 | Acc: 99.708% (49854/50000)\n",
      "(4.142677878042377, 0.99708)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 22ms | Tot: 2s170ms | Loss: 0.9491 | Acc: 85.860% (8586/10000)\n",
      "\n",
      "===> epoch: 79/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 76ms | Tot: 38s108ms | Loss: 0.0083 | Acc: 99.724% (49862/50000)\n",
      "(4.152065894675616, 0.99724)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 21ms | Tot: 2s170ms | Loss: 0.9419 | Acc: 86.150% (8615/10000)\n",
      "\n",
      "===> epoch: 80/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 77ms | Tot: 38s205ms | Loss: 0.0082 | Acc: 99.694% (49847/50000)\n",
      "(4.106415513193497, 0.99694)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 22ms | Tot: 2s171ms | Loss: 0.9970 | Acc: 85.410% (8541/10000)\n",
      "\n",
      "===> epoch: 81/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 79ms | Tot: 38s69ms | Loss: 0.0073 | Acc: 99.756% (49878/50000) [============================>...................................................]  Step: 76ms | Tot: 13s362ms | Loss: 0.0096 | Acc: 99.705% (17548/17600)\n",
      "(3.6319783935468877, 0.99756)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 22ms | Tot: 2s170ms | Loss: 0.9772 | Acc: 86.520% (8652/10000)\n",
      "\n",
      "===> epoch: 82/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 76ms | Tot: 38s139ms | Loss: 0.0073 | Acc: 99.780% (49890/50000)\n",
      "(3.672775323706446, 0.9978)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 22ms | Tot: 2s179ms | Loss: 1.0068 | Acc: 85.760% (8576/10000)\n",
      "\n",
      "===> epoch: 83/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 76ms | Tot: 38s147ms | Loss: 0.0088 | Acc: 99.700% (49850/50000)\n",
      "(4.387976160909602, 0.997)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 22ms | Tot: 2s167ms | Loss: 0.9631 | Acc: 85.640% (8564/10000)\n",
      "\n",
      "===> epoch: 84/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 76ms | Tot: 38s198ms | Loss: 0.0090 | Acc: 99.664% (49832/50000)\n",
      "(4.496659027856367, 0.99664)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 21ms | Tot: 2s159ms | Loss: 0.9189 | Acc: 86.140% (8614/10000)\n",
      "\n",
      "===> epoch: 85/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 75ms | Tot: 38s93ms | Loss: 0.0076 | Acc: 99.746% (49873/50000)\n",
      "(3.8005194488632696, 0.99746)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 22ms | Tot: 2s176ms | Loss: 0.9587 | Acc: 85.700% (8570/10000)\n",
      "\n",
      "===> epoch: 86/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 76ms | Tot: 38s106ms | Loss: 0.0078 | Acc: 99.782% (49891/50000)\n",
      "(3.8931577856565127, 0.99782)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 22ms | Tot: 2s173ms | Loss: 0.9006 | Acc: 86.280% (8628/10000)\n",
      "\n",
      "===> epoch: 87/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 75ms | Tot: 38s122ms | Loss: 0.0083 | Acc: 99.734% (49867/50000)\n",
      "(4.13849227000901, 0.99734)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 22ms | Tot: 2s177ms | Loss: 0.9716 | Acc: 85.780% (8578/10000)\n",
      "\n",
      "===> epoch: 88/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 76ms | Tot: 38s79ms | Loss: 0.0060 | Acc: 99.804% (49902/50000)\n",
      "(3.0169368927163305, 0.99804)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 22ms | Tot: 2s169ms | Loss: 1.0328 | Acc: 85.420% (8542/10000)\n",
      "\n",
      "===> epoch: 89/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 76ms | Tot: 38s203ms | Loss: 0.0083 | Acc: 99.718% (49859/50000)\n",
      "(4.171579126446886, 0.99718)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 23ms | Tot: 2s168ms | Loss: 0.9626 | Acc: 85.640% (8564/10000)\n",
      "\n",
      "===> epoch: 90/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 77ms | Tot: 38s112ms | Loss: 0.0083 | Acc: 99.752% (49876/50000)\n",
      "(4.163451566706499, 0.99752)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 22ms | Tot: 2s169ms | Loss: 0.9324 | Acc: 85.800% (8580/10000)\n",
      "\n",
      "===> epoch: 91/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 76ms | Tot: 38s75ms | Loss: 0.0076 | Acc: 99.756% (49878/50000)\n",
      "(3.8027843395284435, 0.99756)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 22ms | Tot: 2s169ms | Loss: 0.9159 | Acc: 86.070% (8607/10000)\n",
      "\n",
      "===> epoch: 92/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 76ms | Tot: 38s120ms | Loss: 0.0051 | Acc: 99.834% (49917/50000)\n",
      "(2.5563020756308106, 0.99834)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 21ms | Tot: 2s157ms | Loss: 1.0036 | Acc: 86.060% (8606/10000)\n",
      "\n",
      "===> epoch: 93/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 77ms | Tot: 38s207ms | Loss: 0.0069 | Acc: 99.764% (49882/50000)\n",
      "(3.471870074796243, 0.99764)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 21ms | Tot: 2s174ms | Loss: 1.0407 | Acc: 85.610% (8561/10000)\n",
      "\n",
      "===> epoch: 94/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 76ms | Tot: 38s129ms | Loss: 0.0100 | Acc: 99.662% (49831/50000)\n",
      "(5.018605375200423, 0.99662)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 22ms | Tot: 2s165ms | Loss: 0.9636 | Acc: 86.170% (8617/10000)\n",
      "\n",
      "===> epoch: 95/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 76ms | Tot: 38s85ms | Loss: 0.0065 | Acc: 99.782% (49891/50000)\n",
      "(3.2725044009093835, 0.99782)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 22ms | Tot: 2s170ms | Loss: 0.9671 | Acc: 86.340% (8634/10000)\n",
      "\n",
      "===> epoch: 96/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 76ms | Tot: 38s75ms | Loss: 0.0037 | Acc: 99.876% (49938/50000)\n",
      "(1.8446591101628655, 0.99876)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 22ms | Tot: 2s175ms | Loss: 1.0494 | Acc: 85.980% (8598/10000)\n",
      "\n",
      "===> epoch: 97/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 76ms | Tot: 38s99ms | Loss: 0.0072 | Acc: 99.780% (49890/50000)\n",
      "(3.5943748339195736, 0.9978)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 22ms | Tot: 2s210ms | Loss: 1.0350 | Acc: 85.720% (8572/10000)\n",
      "\n",
      "===> epoch: 98/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 77ms | Tot: 38s179ms | Loss: 0.0086 | Acc: 99.728% (49864/50000)\n",
      "(4.323082947626972, 0.99728)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 22ms | Tot: 2s166ms | Loss: 1.0145 | Acc: 85.470% (8547/10000)\n",
      "\n",
      "===> epoch: 99/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 76ms | Tot: 38s78ms | Loss: 0.0086 | Acc: 99.708% (49854/50000)\n",
      "(4.276800291816471, 0.99708)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 22ms | Tot: 2s165ms | Loss: 0.9262 | Acc: 85.800% (8580/10000)\n",
      "\n",
      "===> epoch: 100/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 76ms | Tot: 38s131ms | Loss: 0.0054 | Acc: 99.832% (49916/50000)\n",
      "(2.7102762544018333, 0.99832)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 22ms | Tot: 2s170ms | Loss: 1.0044 | Acc: 85.970% (8597/10000)\n",
      "\n",
      "===> epoch: 101/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 76ms | Tot: 38s100ms | Loss: 0.0079 | Acc: 99.714% (49857/50000)\n",
      "(3.9668668052872817, 0.99714)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 22ms | Tot: 2s167ms | Loss: 0.9967 | Acc: 85.850% (8585/10000)\n",
      "\n",
      "===> epoch: 102/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 76ms | Tot: 38s221ms | Loss: 0.0166 | Acc: 99.624% (49812/50000)\n",
      "(8.289463642679038, 0.99624)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 23ms | Tot: 2s166ms | Loss: 0.9623 | Acc: 84.690% (8469/10000)\n",
      "\n",
      "===> epoch: 103/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 78ms | Tot: 38s110ms | Loss: 0.0146 | Acc: 99.556% (49778/50000)\n",
      "(7.321894093227456, 0.99556)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 22ms | Tot: 2s166ms | Loss: 0.9183 | Acc: 86.100% (8610/10000)\n",
      "\n",
      "===> epoch: 104/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 76ms | Tot: 38s123ms | Loss: 0.0047 | Acc: 99.854% (49927/50000)\n",
      "(2.3745265934921918, 0.99854)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 21ms | Tot: 2s171ms | Loss: 0.9974 | Acc: 85.880% (8588/10000)\n",
      "\n",
      "===> epoch: 105/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 76ms | Tot: 38s128ms | Loss: 0.0039 | Acc: 99.874% (49937/50000)\n",
      "(1.9699599694367862, 0.99874)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 22ms | Tot: 2s174ms | Loss: 1.0341 | Acc: 85.880% (8588/10000)\n",
      "\n",
      "===> epoch: 106/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 78ms | Tot: 38s98ms | Loss: 0.0032 | Acc: 99.912% (49956/50000)\n",
      "(1.6032136501585228, 0.99912)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 22ms | Tot: 2s228ms | Loss: 1.0972 | Acc: 86.170% (8617/10000)\n",
      "\n",
      "===> epoch: 107/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 77ms | Tot: 38s218ms | Loss: 0.0065 | Acc: 99.802% (49901/50000)\n",
      "(3.238588502233142, 0.99802)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 22ms | Tot: 2s165ms | Loss: 1.0200 | Acc: 86.240% (8624/10000)\n",
      "\n",
      "===> epoch: 108/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 77ms | Tot: 38s84ms | Loss: 0.0051 | Acc: 99.842% (49921/50000)\n",
      "(2.5610555332641525, 0.99842)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 21ms | Tot: 2s171ms | Loss: 1.0250 | Acc: 86.230% (8623/10000)\n",
      "\n",
      "===> epoch: 109/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 77ms | Tot: 38s80ms | Loss: 0.0057 | Acc: 99.812% (49906/50000)\n",
      "(2.8316366308936267, 0.99812)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 22ms | Tot: 2s176ms | Loss: 1.0662 | Acc: 86.290% (8629/10000)\n",
      "\n",
      "===> epoch: 110/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 77ms | Tot: 38s121ms | Loss: 0.0081 | Acc: 99.736% (49868/50000)\n",
      "(4.066574992903043, 0.99736)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 22ms | Tot: 2s175ms | Loss: 1.0187 | Acc: 85.850% (8585/10000)\n",
      "\n",
      "===> epoch: 111/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 76ms | Tot: 38s186ms | Loss: 0.0074 | Acc: 99.746% (49873/50000)\n",
      "(3.695302420768712, 0.99746)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 21ms | Tot: 2s178ms | Loss: 0.9917 | Acc: 86.020% (8602/10000)\n",
      "\n",
      "===> epoch: 112/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 76ms | Tot: 38s149ms | Loss: 0.0072 | Acc: 99.778% (49889/50000)\n",
      "(3.581296385573296, 0.99778)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 22ms | Tot: 2s169ms | Loss: 0.9523 | Acc: 86.360% (8636/10000)\n",
      "\n",
      "===> epoch: 113/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 76ms | Tot: 38s126ms | Loss: 0.0049 | Acc: 99.830% (49915/50000)\n",
      "(2.4473333752339386, 0.9983)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 21ms | Tot: 2s166ms | Loss: 1.0521 | Acc: 86.140% (8614/10000)\n",
      "\n",
      "===> epoch: 114/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 77ms | Tot: 38s115ms | Loss: 0.0070 | Acc: 99.748% (49874/50000)\n",
      "(3.5050759266814566, 0.99748)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 22ms | Tot: 2s170ms | Loss: 0.9794 | Acc: 85.940% (8594/10000)\n",
      "\n",
      "===> epoch: 115/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 78ms | Tot: 38s184ms | Loss: 0.0056 | Acc: 99.816% (49908/50000)\n",
      "(2.781410270741617, 0.99816)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 23ms | Tot: 2s208ms | Loss: 0.9701 | Acc: 86.370% (8637/10000)\n",
      "\n",
      "===> epoch: 116/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 76ms | Tot: 38s185ms | Loss: 0.0060 | Acc: 99.824% (49912/50000)\n",
      "(2.9785991523567645, 0.99824)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 22ms | Tot: 2s178ms | Loss: 1.0022 | Acc: 85.940% (8594/10000)\n",
      "\n",
      "===> epoch: 117/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 77ms | Tot: 38s105ms | Loss: 0.0060 | Acc: 99.816% (49908/50000)\n",
      "(2.986459510610075, 0.99816)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 22ms | Tot: 2s178ms | Loss: 1.0455 | Acc: 85.780% (8578/10000)\n",
      "\n",
      "===> epoch: 118/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 75ms | Tot: 38s144ms | Loss: 0.0085 | Acc: 99.706% (49853/50000)\n",
      "(4.225810818665195, 0.99706)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 21ms | Tot: 2s180ms | Loss: 1.0264 | Acc: 85.510% (8551/10000)\n",
      "\n",
      "===> epoch: 119/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 76ms | Tot: 38s124ms | Loss: 0.0084 | Acc: 99.740% (49870/50000)\n",
      "(4.202581472616657, 0.9974)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 21ms | Tot: 2s182ms | Loss: 0.9732 | Acc: 86.010% (8601/10000)\n",
      "\n",
      "===> epoch: 120/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 76ms | Tot: 2h48m | Loss: 0.0114 | Acc: 99.824% (49912/50000)0) [===============================================================================>]  Step: 75ms | Tot: 2h48m | Loss: 0.0114 | Acc: 99.824% (49812/49900)\n",
      "(5.691402438299519, 0.99824)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 21ms | Tot: 2s153ms | Loss: 1.0380 | Acc: 86.260% (8626/10000)\n",
      "\n",
      "===> epoch: 121/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 76ms | Tot: 37s680ms | Loss: 0.0066 | Acc: 99.778% (49889/50000)[============================================>...................................]  Step: 75ms | Tot: 21s26ms | Loss: 0.0049 | Acc: 99.839% (27955/28000)\n",
      "(3.301029803916208, 0.99778)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 21ms | Tot: 2s168ms | Loss: 0.9941 | Acc: 86.050% (8605/10000)\n",
      "\n",
      "===> epoch: 122/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 76ms | Tot: 37s612ms | Loss: 0.0064 | Acc: 99.774% (49887/50000)\n",
      "(3.1960258265025914, 0.99774)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 23ms | Tot: 2s153ms | Loss: 0.9844 | Acc: 85.870% (8587/10000)\n",
      "\n",
      "===> epoch: 123/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 77ms | Tot: 37s674ms | Loss: 0.0041 | Acc: 99.880% (49940/50000)=====>.......................................................................]  Step: 75ms | Tot: 4s158ms | Loss: 0.0033 | Acc: 99.911% (5595/5600)\n",
      "(2.043757482755609, 0.9988)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 22ms | Tot: 2s157ms | Loss: 1.0720 | Acc: 85.840% (8584/10000)\n",
      "\n",
      "===> epoch: 124/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 76ms | Tot: 37s763ms | Loss: 0.0065 | Acc: 99.790% (49895/50000)[=========================================>......................................]  Step: 75ms | Tot: 19s506ms | Loss: 0.0061 | Acc: 99.815% (25852/25900)\n",
      "(3.2697160726474976, 0.9979)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 21ms | Tot: 2s167ms | Loss: 1.0134 | Acc: 86.120% (8612/10000)\n",
      "\n",
      "===> epoch: 125/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 77ms | Tot: 37s896ms | Loss: 0.0092 | Acc: 99.686% (49843/50000)[=============================================================>..................]  Step: 75ms | Tot: 29s334ms | Loss: 0.0090 | Acc: 99.693% (38581/38700)\n",
      "(4.593060308498025, 0.99686)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 22ms | Tot: 2s165ms | Loss: 1.0076 | Acc: 85.720% (8572/10000)\n",
      "\n",
      "===> epoch: 126/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 76ms | Tot: 37s843ms | Loss: 0.0081 | Acc: 99.730% (49865/50000)\n",
      "(4.069365444225696, 0.9973)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 22ms | Tot: 2s170ms | Loss: 0.9774 | Acc: 85.660% (8566/10000)\n",
      "\n",
      "===> epoch: 127/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 75ms | Tot: 37s860ms | Loss: 0.0045 | Acc: 99.856% (49928/50000)[==================================>.............................................]  Step: 76ms | Tot: 16s161ms | Loss: 0.0036 | Acc: 99.893% (21377/21400)\n",
      "(2.272686013184284, 0.99856)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 22ms | Tot: 2s173ms | Loss: 1.0090 | Acc: 85.690% (8569/10000)\n",
      "\n",
      "===> epoch: 128/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 76ms | Tot: 37s904ms | Loss: 0.0066 | Acc: 99.790% (49895/50000)\n",
      "(3.317081143653013, 0.9979)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 22ms | Tot: 2s176ms | Loss: 0.9814 | Acc: 85.340% (8534/10000)\n",
      "\n",
      "===> epoch: 129/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 76ms | Tot: 37s986ms | Loss: 0.0078 | Acc: 99.730% (49865/50000)\n",
      "(3.9005203414781136, 0.9973)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 22ms | Tot: 2s167ms | Loss: 0.9615 | Acc: 85.870% (8587/10000)\n",
      "\n",
      "===> epoch: 130/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 76ms | Tot: 37s854ms | Loss: 0.0046 | Acc: 99.856% (49928/50000)\n",
      "(2.323941926480984, 0.99856)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 22ms | Tot: 2s183ms | Loss: 0.9812 | Acc: 86.290% (8629/10000)\n",
      "\n",
      "===> epoch: 131/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 88ms | Tot: 38s167ms | Loss: 0.0049 | Acc: 99.830% (49915/50000)\n",
      "(2.4337531067230884, 0.9983)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 22ms | Tot: 2s248ms | Loss: 1.0383 | Acc: 85.960% (8596/10000)\n",
      "\n",
      "===> epoch: 132/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 75ms | Tot: 38s86ms | Loss: 0.0057 | Acc: 99.828% (49914/50000)\n",
      "(2.8703648750488355, 0.99828)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 22ms | Tot: 2s175ms | Loss: 1.0395 | Acc: 85.520% (8552/10000)\n",
      "\n",
      "===> epoch: 133/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 75ms | Tot: 37s947ms | Loss: 0.0070 | Acc: 99.766% (49883/50000)\n",
      "(3.4897575379141017, 0.99766)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 22ms | Tot: 2s175ms | Loss: 1.0234 | Acc: 86.020% (8602/10000)\n",
      "\n",
      "===> epoch: 134/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 76ms | Tot: 38s79ms | Loss: 0.0074 | Acc: 99.784% (49892/50000)\n",
      "(3.6960115228484938, 0.99784)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 22ms | Tot: 2s183ms | Loss: 0.9635 | Acc: 86.250% (8625/10000)\n",
      "\n",
      "===> epoch: 135/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 75ms | Tot: 38s6ms | Loss: 0.0039 | Acc: 99.886% (49943/50000))\n",
      "(1.9707810493400757, 0.99886)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 22ms | Tot: 2s181ms | Loss: 1.0551 | Acc: 85.870% (8587/10000)\n",
      "\n",
      "===> epoch: 136/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 77ms | Tot: 38s691ms | Loss: 0.0052 | Acc: 99.860% (49930/50000)\n",
      "(2.583928075942822, 0.9986)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 22ms | Tot: 2s196ms | Loss: 0.9816 | Acc: 86.190% (8619/10000)\n",
      "\n",
      "===> epoch: 137/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 78ms | Tot: 38s457ms | Loss: 0.0066 | Acc: 99.798% (49899/50000)\n",
      "(3.3095558732366044, 0.99798)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 22ms | Tot: 2s203ms | Loss: 0.9819 | Acc: 86.010% (8601/10000)\n",
      "\n",
      "===> epoch: 138/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 76ms | Tot: 38s608ms | Loss: 0.0078 | Acc: 99.752% (49876/50000)\n",
      "(3.885516642809307, 0.99752)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 22ms | Tot: 2s208ms | Loss: 0.9764 | Acc: 85.960% (8596/10000)\n",
      "\n",
      "===> epoch: 139/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 75ms | Tot: 38s481ms | Loss: 0.0057 | Acc: 99.822% (49911/50000)\n",
      "(2.8263797433592117, 0.99822)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 22ms | Tot: 2s205ms | Loss: 0.9967 | Acc: 86.160% (8616/10000)\n",
      "\n",
      "===> epoch: 140/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 77ms | Tot: 38s447ms | Loss: 0.0061 | Acc: 99.800% (49900/50000)\n",
      "(3.0354308308706095, 0.998)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 23ms | Tot: 2s224ms | Loss: 1.0389 | Acc: 86.000% (8600/10000)\n",
      "\n",
      "===> epoch: 141/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 76ms | Tot: 38s78ms | Loss: 0.0060 | Acc: 99.788% (49894/50000)\n",
      "(2.97888346173022, 0.99788)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 22ms | Tot: 2s160ms | Loss: 1.0141 | Acc: 85.460% (8546/10000)\n",
      "\n",
      "===> epoch: 142/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 81ms | Tot: 37s954ms | Loss: 0.0061 | Acc: 99.814% (49907/50000)\n",
      "(3.034530280288891, 0.99814)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 21ms | Tot: 2s271ms | Loss: 1.0385 | Acc: 85.930% (8593/10000)\n",
      "\n",
      "===> epoch: 143/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 77ms | Tot: 37s964ms | Loss: 0.0067 | Acc: 99.782% (49891/50000)\n",
      "(3.3612461873744905, 0.99782)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 21ms | Tot: 2s154ms | Loss: 0.9821 | Acc: 85.660% (8566/10000)\n",
      "\n",
      "===> epoch: 144/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 75ms | Tot: 37s992ms | Loss: 0.0065 | Acc: 99.800% (49900/50000)[==============================================================>.................]  Step: 76ms | Tot: 29s726ms | Loss: 0.0063 | Acc: 99.801% (39022/39100)\n",
      "(3.2557291321554658, 0.998)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 21ms | Tot: 2s166ms | Loss: 0.9645 | Acc: 85.690% (8569/10000)\n",
      "\n",
      "===> epoch: 145/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 76ms | Tot: 37s815ms | Loss: 0.0047 | Acc: 99.856% (49928/50000)[=============================================================================>..]  Step: 76ms | Tot: 36s673ms | Loss: 0.0047 | Acc: 99.856% (48430/48500)\n",
      "(2.337454745778814, 0.99856)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 22ms | Tot: 2s156ms | Loss: 1.0475 | Acc: 85.920% (8592/10000)\n",
      "\n",
      "===> epoch: 146/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 75ms | Tot: 37s864ms | Loss: 0.0048 | Acc: 99.848% (49924/50000)[==================================================>.............................]  Step: 76ms | Tot: 23s841ms | Loss: 0.0041 | Acc: 99.867% (31458/31500)\n",
      "(2.389510951248667, 0.99848)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 21ms | Tot: 2s156ms | Loss: 1.0171 | Acc: 86.120% (8612/10000)\n",
      "\n",
      "===> epoch: 147/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 76ms | Tot: 37s979ms | Loss: 0.0082 | Acc: 99.750% (49875/50000)\n",
      "(4.117089707095147, 0.9975)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 23ms | Tot: 2s150ms | Loss: 0.9937 | Acc: 85.840% (8584/10000)\n",
      "\n",
      "===> epoch: 148/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 76ms | Tot: 37s829ms | Loss: 0.0097 | Acc: 99.790% (49895/50000)[=======================================================>........................]  Step: 75ms | Tot: 26s81ms | Loss: 0.0113 | Acc: 99.765% (34419/34500)\n",
      "(4.8628042841573915, 0.9979)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 21ms | Tot: 2s153ms | Loss: 0.9847 | Acc: 85.840% (8584/10000)\n",
      "\n",
      "===> epoch: 149/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 75ms | Tot: 37s847ms | Loss: 0.0051 | Acc: 99.862% (49931/50000)\n",
      "(2.53029317565597, 0.99862)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 21ms | Tot: 2s142ms | Loss: 0.9813 | Acc: 85.930% (8593/10000)\n",
      "\n",
      "===> epoch: 150/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 75ms | Tot: 37s864ms | Loss: 0.0025 | Acc: 99.916% (49958/50000)\n",
      "(1.2640811621313333, 0.99916)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 21ms | Tot: 2s155ms | Loss: 1.0147 | Acc: 86.490% (8649/10000)\n",
      "\n",
      "===> epoch: 151/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 76ms | Tot: 37s850ms | Loss: 0.0014 | Acc: 99.954% (49977/50000)\n",
      "(0.6899548270030209, 0.99954)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 21ms | Tot: 2s164ms | Loss: 1.0416 | Acc: 86.610% (8661/10000)\n",
      "\n",
      "===> epoch: 152/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 78ms | Tot: 37s992ms | Loss: 0.0010 | Acc: 99.962% (49981/50000)\n",
      "(0.4992030184489522, 0.99962)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 21ms | Tot: 2s153ms | Loss: 1.0949 | Acc: 86.440% (8644/10000)\n",
      "\n",
      "===> epoch: 153/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 76ms | Tot: 37s905ms | Loss: 0.0015 | Acc: 99.948% (49974/50000)\n",
      "(0.7595588548357455, 0.99948)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 22ms | Tot: 2s157ms | Loss: 1.1186 | Acc: 86.330% (8633/10000)\n",
      "\n",
      "===> epoch: 154/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 76ms | Tot: 37s849ms | Loss: 0.0012 | Acc: 99.964% (49982/50000)\n",
      "(0.606185550286682, 0.99964)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 21ms | Tot: 2s155ms | Loss: 1.1311 | Acc: 86.730% (8673/10000)\n",
      "\n",
      "===> epoch: 155/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 76ms | Tot: 37s877ms | Loss: 0.0041 | Acc: 99.894% (49947/50000)\n",
      "(2.049495361600293, 0.99894)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 22ms | Tot: 2s161ms | Loss: 1.1257 | Acc: 86.260% (8626/10000)\n",
      "\n",
      "===> epoch: 156/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 76ms | Tot: 37s998ms | Loss: 0.0020 | Acc: 99.954% (49977/50000)\n",
      "(0.9914594565605057, 0.99954)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 21ms | Tot: 2s159ms | Loss: 1.1190 | Acc: 86.520% (8652/10000)\n",
      "\n",
      "===> epoch: 157/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 75ms | Tot: 37s852ms | Loss: 0.0013 | Acc: 99.964% (49982/50000)\n",
      "(0.6358545487812535, 0.99964)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 22ms | Tot: 2s164ms | Loss: 1.1392 | Acc: 86.400% (8640/10000)\n",
      "\n",
      "===> epoch: 158/200\n",
      "train:\n",
      " 500/500 [================================================================================>]  Step: 75ms | Tot: 37s900ms | Loss: 0.0016 | Acc: 99.942% (49971/50000)\n",
      "(0.8077607536238247, 0.99942)\n",
      "test:\n",
      " 100/100 [================================================================================>]  Step: 22ms | Tot: 2s170ms | Loss: 1.1425 | Acc: 86.210% (8621/10000)\n",
      "\n",
      "===> epoch: 159/200\n",
      "train:\n",
      " 455/500 [========================================================================>.......]  Step: 76ms | Tot: 35s124ms | Loss: 0.0009 | Acc: 99.971% (45487/45500))\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[1;32m~\\OneDrive\\01 Frankfurt School\\Semester 3\\Deep Learning\\TripleNetDL\\cifar10triplenet\\triplenetb.py:154\u001b[0m\n\u001b[0;32m    150\u001b[0m                 \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msave()\n\u001b[0;32m    153\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m__name__\u001b[39m \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39m__main__\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m--> 154\u001b[0m     main()\n",
      "File \u001b[1;32m~\\OneDrive\\01 Frankfurt School\\Semester 3\\Deep Learning\\TripleNetDL\\cifar10triplenet\\triplenetb.py:31\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     28\u001b[0m args \u001b[39m=\u001b[39m parser\u001b[39m.\u001b[39mparse_args()\n\u001b[0;32m     30\u001b[0m solver \u001b[39m=\u001b[39m Solver(args)\n\u001b[1;32m---> 31\u001b[0m solver\u001b[39m.\u001b[39;49mrun()\n",
      "File \u001b[1;32m~\\OneDrive\\01 Frankfurt School\\Semester 3\\Deep Learning\\TripleNetDL\\cifar10triplenet\\triplenetb.py:144\u001b[0m, in \u001b[0;36mSolver.run\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    142\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mscheduler\u001b[39m.\u001b[39mstep(epoch)\n\u001b[0;32m    143\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m===> epoch: \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m/200\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m epoch)\n\u001b[1;32m--> 144\u001b[0m train_result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain()\n\u001b[0;32m    145\u001b[0m \u001b[39mprint\u001b[39m(train_result)\n\u001b[0;32m    146\u001b[0m test_result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtest()\n",
      "File \u001b[1;32m~\\OneDrive\\01 Frankfurt School\\Semester 3\\Deep Learning\\TripleNetDL\\cifar10triplenet\\triplenetb.py:85\u001b[0m, in \u001b[0;36mSolver.train\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     83\u001b[0m data, target \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39mto(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice), target\u001b[39m.\u001b[39mto(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice)\n\u001b[0;32m     84\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m---> 85\u001b[0m output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel(data)\n\u001b[0;32m     86\u001b[0m loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcriterion(output, target)\n\u001b[0;32m     87\u001b[0m loss\u001b[39m.\u001b[39mbackward()\n",
      "File \u001b[1;32mc:\\Users\\alexa\\mambaforge\\envs\\triplenet\\lib\\site-packages\\torch\\nn\\modules\\module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1106\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1107\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1108\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1109\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1110\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1111\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\OneDrive\\01 Frankfurt School\\Semester 3\\Deep Learning\\TripleNetDL\\cifar10triplenet\\models\\TripleNet_B.py:215\u001b[0m, in \u001b[0;36mTripleNet.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    213\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[0;32m    214\u001b[0m     \u001b[39mfor\u001b[39;00m layer \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbase:\n\u001b[1;32m--> 215\u001b[0m       x \u001b[39m=\u001b[39m layer(x)\n\u001b[0;32m    216\u001b[0m     \u001b[39mreturn\u001b[39;00m x\n",
      "File \u001b[1;32mc:\\Users\\alexa\\mambaforge\\envs\\triplenet\\lib\\site-packages\\torch\\nn\\modules\\module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1106\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1107\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1108\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1109\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1110\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1111\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\OneDrive\\01 Frankfurt School\\Semester 3\\Deep Learning\\TripleNetDL\\cifar10triplenet\\models\\TripleNet_B.py:116\u001b[0m, in \u001b[0;36mHarDBlock.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    114\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    115\u001b[0m         x \u001b[39m=\u001b[39m tin[\u001b[39m0\u001b[39m]\n\u001b[1;32m--> 116\u001b[0m     out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlayers[layer](x)\n\u001b[0;32m    117\u001b[0m     layers_\u001b[39m.\u001b[39mappend(out)\n\u001b[0;32m    119\u001b[0m t \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(layers_)\n",
      "File \u001b[1;32mc:\\Users\\alexa\\mambaforge\\envs\\triplenet\\lib\\site-packages\\torch\\nn\\modules\\module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1106\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1107\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1108\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1109\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1110\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1111\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\OneDrive\\01 Frankfurt School\\Semester 3\\Deep Learning\\TripleNetDL\\cifar10triplenet\\models\\TripleNet_B.py:62\u001b[0m, in \u001b[0;36mConvLayer.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[1;32m---> 62\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mforward(x)\n",
      "File \u001b[1;32mc:\\Users\\alexa\\mambaforge\\envs\\triplenet\\lib\\site-packages\\torch\\nn\\modules\\container.py:141\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    139\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[0;32m    140\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[1;32m--> 141\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[0;32m    142\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\alexa\\mambaforge\\envs\\triplenet\\lib\\site-packages\\torch\\nn\\modules\\module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1106\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1107\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1108\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1109\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1110\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1111\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\alexa\\mambaforge\\envs\\triplenet\\lib\\site-packages\\torch\\nn\\modules\\conv.py:447\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    446\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m--> 447\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_conv_forward(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "File \u001b[1;32mc:\\Users\\alexa\\mambaforge\\envs\\triplenet\\lib\\site-packages\\torch\\nn\\modules\\conv.py:443\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    439\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mzeros\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m    440\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39mconv2d(F\u001b[39m.\u001b[39mpad(\u001b[39minput\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode),\n\u001b[0;32m    441\u001b[0m                     weight, bias, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstride,\n\u001b[0;32m    442\u001b[0m                     _pair(\u001b[39m0\u001b[39m), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdilation, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgroups)\n\u001b[1;32m--> 443\u001b[0m \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mconv2d(\u001b[39minput\u001b[39;49m, weight, bias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstride,\n\u001b[0;32m    444\u001b[0m                 \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdilation, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgroups)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%run cifar10triplenet\\triplenetb.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "triplenet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
