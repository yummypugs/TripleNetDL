{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\alexa\\mambaforge\\envs\\triplenet\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:131: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n",
      "c:\\Users\\alexa\\mambaforge\\envs\\triplenet\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===> epoch: 1/200\n",
      "train:\n",
      " 782/782 [================================================================================>]  Step: 595ms | Tot: 50s137ms | Loss: 1.4429 | Acc: 46.664% (23332/50000)==============================>................................................]  Step: 64ms | Tot: 19s590ms | Loss: 1.7020 | Acc: 36.050% (7060/19584)\n",
      "(1128.3507467508316, 0.46664)\n",
      "test:\n",
      " 157/157 [================================================================================>]  Step: 14ms | Tot: 2s642ms | Loss: 1.1963 | Acc: 57.730% (5773/10000)\n",
      "\n",
      "===> epoch: 2/200\n",
      "train:\n",
      " 782/782 [================================================================================>]  Step: 71ms | Tot: 48s501ms | Loss: 1.0052 | Acc: 64.246% (32123/50000)[=======================================>........................................]  Step: 64ms | Tot: 23s688ms | Loss: 1.0561 | Acc: 62.185% (15203/24448)\n",
      "(786.1018263101578, 0.64246)\n",
      "test:\n",
      " 157/157 [================================================================================>]  Step: 13ms | Tot: 2s645ms | Loss: 1.1587 | Acc: 60.470% (6047/10000)\n",
      "\n",
      "===> epoch: 3/200\n",
      "train:\n",
      " 782/782 [================================================================================>]  Step: 72ms | Tot: 48s459ms | Loss: 0.8399 | Acc: 70.754% (35377/50000)====>........................................................................]  Step: 63ms | Tot: 4s808ms | Loss: 0.9038 | Acc: 68.329% (3411/4992)\n",
      "(656.8287543058395, 0.70754)\n",
      "test:\n",
      " 157/157 [================================================================================>]  Step: 13ms | Tot: 2s655ms | Loss: 1.1652 | Acc: 63.120% (6312/10000)\n",
      "\n",
      "===> epoch: 4/200\n",
      "train:\n",
      " 782/782 [================================================================================>]  Step: 62ms | Tot: 48s663ms | Loss: 0.7352 | Acc: 74.704% (37352/50000)[========================>.......................................................]  Step: 62ms | Tot: 14s921ms | Loss: 0.7572 | Acc: 73.749% (11375/15424)\n",
      "(574.9230932891369, 0.74704)\n",
      "test:\n",
      " 157/157 [================================================================================>]  Step: 13ms | Tot: 2s645ms | Loss: 0.8048 | Acc: 72.870% (7287/10000)\n",
      "\n",
      "===> epoch: 5/200\n",
      "train:\n",
      " 782/782 [================================================================================>]  Step: 66ms | Tot: 48s453ms | Loss: 0.6569 | Acc: 77.694% (38847/50000)[=============================>..................................................]  Step: 63ms | Tot: 17s871ms | Loss: 0.6647 | Acc: 77.465% (14328/18496)\n",
      "(513.7176113128662, 0.77694)\n",
      "test:\n",
      " 157/157 [================================================================================>]  Step: 14ms | Tot: 2s661ms | Loss: 0.7149 | Acc: 76.040% (7604/10000)\n",
      "\n",
      "===> epoch: 6/200\n",
      "train:\n",
      " 782/782 [================================================================================>]  Step: 60ms | Tot: 48s508ms | Loss: 0.5906 | Acc: 80.152% (40076/50000)\n",
      "(461.8253035247326, 0.80152)\n",
      "test:\n",
      " 157/157 [================================================================================>]  Step: 13ms | Tot: 2s650ms | Loss: 0.7147 | Acc: 76.490% (7649/10000)\n",
      "\n",
      "===> epoch: 7/200\n",
      "train:\n",
      " 782/782 [================================================================================>]  Step: 69ms | Tot: 48s366ms | Loss: 0.5405 | Acc: 81.796% (40898/50000)\n",
      "(422.68680214881897, 0.81796)\n",
      "test:\n",
      " 157/157 [================================================================================>]  Step: 14ms | Tot: 2s657ms | Loss: 0.7656 | Acc: 75.330% (7533/10000)\n",
      "\n",
      "===> epoch: 8/200\n",
      "train:\n",
      " 782/782 [================================================================================>]  Step: 60ms | Tot: 48s582ms | Loss: 0.4942 | Acc: 83.358% (41679/50000)\n",
      "(386.4897148311138, 0.83358)\n",
      "test:\n",
      " 157/157 [================================================================================>]  Step: 13ms | Tot: 2s656ms | Loss: 0.6201 | Acc: 79.620% (7962/10000)\n",
      "\n",
      "===> epoch: 9/200\n",
      "train:\n",
      " 782/782 [================================================================================>]  Step: 65ms | Tot: 48s523ms | Loss: 0.4539 | Acc: 84.696% (42348/50000)[===================================>............................................]  Step: 64ms | Tot: 21s227ms | Loss: 0.4493 | Acc: 84.862% (18629/21952) [===========================================================>....................]  Step: 62ms | Tot: 36s79ms | Loss: 0.4476 | Acc: 84.960% (31646/37248)\n",
      "(354.95328433811665, 0.84696)\n",
      "test:\n",
      " 157/157 [================================================================================>]  Step: 14ms | Tot: 2s656ms | Loss: 0.7439 | Acc: 76.180% (7618/10000)\n",
      "\n",
      "===> epoch: 10/200\n",
      "train:\n",
      " 782/782 [================================================================================>]  Step: 67ms | Tot: 48s621ms | Loss: 0.4152 | Acc: 86.074% (43037/50000)\n",
      "(324.6568901091814, 0.86074)\n",
      "test:\n",
      " 157/157 [================================================================================>]  Step: 14ms | Tot: 2s656ms | Loss: 0.5648 | Acc: 80.930% (8093/10000)\n",
      "\n",
      "===> epoch: 11/200\n",
      "train:\n",
      " 782/782 [================================================================================>]  Step: 64ms | Tot: 48s716ms | Loss: 0.3785 | Acc: 87.258% (43629/50000)\n",
      "(296.02081206440926, 0.87258)\n",
      "test:\n",
      " 157/157 [================================================================================>]  Step: 13ms | Tot: 2s661ms | Loss: 0.6025 | Acc: 80.820% (8082/10000)\n",
      "\n",
      "===> epoch: 12/200\n",
      "train:\n",
      " 782/782 [================================================================================>]  Step: 67ms | Tot: 48s752ms | Loss: 0.3509 | Acc: 88.284% (44142/50000)\n",
      "(274.38302537053823, 0.88284)\n",
      "test:\n",
      " 157/157 [================================================================================>]  Step: 13ms | Tot: 2s635ms | Loss: 0.6064 | Acc: 80.210% (8021/10000)\n",
      "\n",
      "===> epoch: 13/200\n",
      "train:\n",
      " 782/782 [================================================================================>]  Step: 69ms | Tot: 48s492ms | Loss: 0.3197 | Acc: 89.242% (44621/50000)\n",
      "(250.0274726599455, 0.89242)\n",
      "test:\n",
      " 157/157 [================================================================================>]  Step: 14ms | Tot: 2s765ms | Loss: 0.5382 | Acc: 82.990% (8299/10000)\n",
      "\n",
      "===> epoch: 14/200\n",
      "train:\n",
      " 782/782 [================================================================================>]  Step: 64ms | Tot: 49s345ms | Loss: 0.2892 | Acc: 90.412% (45206/50000)=============>................................................................]  Step: 70ms | Tot: 9s492ms | Loss: 0.2565 | Acc: 91.539% (8612/9408)\n",
      "(226.18776035308838, 0.90412)\n",
      "test:\n",
      " 157/157 [================================================================================>]  Step: 13ms | Tot: 2s613ms | Loss: 0.5752 | Acc: 82.140% (8214/10000)\n",
      "\n",
      "===> epoch: 15/200\n",
      "train:\n",
      " 782/782 [================================================================================>]  Step: 61ms | Tot: 48s360ms | Loss: 0.2693 | Acc: 90.966% (45483/50000)\n",
      "(210.55973037332296, 0.90966)\n",
      "test:\n",
      " 157/157 [================================================================================>]  Step: 13ms | Tot: 2s640ms | Loss: 0.5660 | Acc: 82.590% (8259/10000)\n",
      "\n",
      "===> epoch: 16/200\n",
      "train:\n",
      " 782/782 [================================================================================>]  Step: 71ms | Tot: 48s240ms | Loss: 0.2447 | Acc: 91.844% (45922/50000)\n",
      "(191.3742359764874, 0.91844)\n",
      "test:\n",
      " 157/157 [================================================================================>]  Step: 14ms | Tot: 2s606ms | Loss: 0.5993 | Acc: 82.480% (8248/10000)\n",
      "\n",
      "===> epoch: 17/200\n",
      "train:\n",
      " 782/782 [================================================================================>]  Step: 67ms | Tot: 48s224ms | Loss: 0.2224 | Acc: 92.518% (46259/50000)[====================>...........................................................]  Step: 62ms | Tot: 12s179ms | Loss: 0.2184 | Acc: 92.732% (11751/12672)\n",
      "(173.89839014038444, 0.92518)\n",
      "test:\n",
      " 157/157 [================================================================================>]  Step: 13ms | Tot: 2s632ms | Loss: 0.5579 | Acc: 83.510% (8351/10000)\n",
      "\n",
      "===> epoch: 18/200\n",
      "train:\n",
      " 782/782 [================================================================================>]  Step: 65ms | Tot: 48s415ms | Loss: 0.2040 | Acc: 93.186% (46593/50000)\n",
      "(159.5644303150475, 0.93186)\n",
      "test:\n",
      " 157/157 [================================================================================>]  Step: 13ms | Tot: 2s621ms | Loss: 0.5687 | Acc: 83.870% (8387/10000)\n",
      "\n",
      "===> epoch: 19/200\n",
      "train:\n",
      " 782/782 [================================================================================>]  Step: 61ms | Tot: 48s246ms | Loss: 0.1901 | Acc: 93.732% (46866/50000)\n",
      "(148.66925679706037, 0.93732)\n",
      "test:\n",
      " 157/157 [================================================================================>]  Step: 13ms | Tot: 2s624ms | Loss: 0.5712 | Acc: 83.360% (8336/10000)\n",
      "\n",
      "===> epoch: 20/200\n",
      "train:\n",
      " 782/782 [================================================================================>]  Step: 68ms | Tot: 48s276ms | Loss: 0.1790 | Acc: 94.024% (47012/50000)\n",
      "(139.9700033403933, 0.94024)\n",
      "test:\n",
      " 157/157 [================================================================================>]  Step: 14ms | Tot: 2s629ms | Loss: 0.5996 | Acc: 83.710% (8371/10000)\n",
      "\n",
      "===> epoch: 21/200\n",
      "train:\n",
      " 782/782 [================================================================================>]  Step: 66ms | Tot: 48s251ms | Loss: 0.1604 | Acc: 94.728% (47364/50000)\n",
      "(125.39408522285521, 0.94728)\n",
      "test:\n",
      " 157/157 [================================================================================>]  Step: 13ms | Tot: 2s617ms | Loss: 0.6495 | Acc: 83.320% (8332/10000)\n",
      "\n",
      "===> epoch: 22/200\n",
      "train:\n",
      " 782/782 [================================================================================>]  Step: 63ms | Tot: 48s404ms | Loss: 0.1493 | Acc: 95.042% (47521/50000)\n",
      "(116.75365614704788, 0.95042)\n",
      "test:\n",
      " 157/157 [================================================================================>]  Step: 13ms | Tot: 2s626ms | Loss: 0.6214 | Acc: 83.720% (8372/10000)\n",
      "\n",
      "===> epoch: 23/200\n",
      "train:\n",
      " 782/782 [================================================================================>]  Step: 73ms | Tot: 48s276ms | Loss: 0.1399 | Acc: 95.286% (47643/50000)[==========================================================>.....................]  Step: 62ms | Tot: 35s353ms | Loss: 0.1387 | Acc: 95.293% (34946/36672) [====================================================================>...........]  Step: 62ms | Tot: 41s282ms | Loss: 0.1402 | Acc: 95.256% (40785/42816)\n",
      "(109.43541521951556, 0.95286)\n",
      "test:\n",
      " 157/157 [================================================================================>]  Step: 13ms | Tot: 2s622ms | Loss: 0.6073 | Acc: 83.200% (8320/10000)\n",
      "\n",
      "===> epoch: 24/200\n",
      "train:\n",
      " 782/782 [================================================================================>]  Step: 70ms | Tot: 48s311ms | Loss: 0.1270 | Acc: 95.762% (47881/50000)\n",
      "(99.28001212142408, 0.95762)\n",
      "test:\n",
      " 157/157 [================================================================================>]  Step: 13ms | Tot: 2s614ms | Loss: 0.7165 | Acc: 82.200% (8220/10000)\n",
      "\n",
      "===> epoch: 25/200\n",
      "train:\n",
      " 782/782 [================================================================================>]  Step: 62ms | Tot: 48s394ms | Loss: 0.1243 | Acc: 95.754% (47877/50000)\n",
      "(97.21981461858377, 0.95754)\n",
      "test:\n",
      " 157/157 [================================================================================>]  Step: 13ms | Tot: 2s635ms | Loss: 0.6098 | Acc: 83.880% (8388/10000)=========================================>.....................................]  Step: 17ms | Tot: 1s386ms | Loss: 0.6224 | Acc: 83.528% (4437/5312)\n",
      "\n",
      "===> epoch: 26/200\n",
      "train:\n",
      " 782/782 [================================================================================>]  Step: 64ms | Tot: 48s333ms | Loss: 0.1158 | Acc: 96.036% (48018/50000)\n",
      "(90.58530983608216, 0.96036)\n",
      "test:\n",
      " 157/157 [================================================================================>]  Step: 14ms | Tot: 2s641ms | Loss: 0.6703 | Acc: 83.210% (8321/10000)\n",
      "\n",
      "===> epoch: 27/200\n",
      "train:\n",
      " 782/782 [================================================================================>]  Step: 59ms | Tot: 48s281ms | Loss: 0.1095 | Acc: 96.296% (48148/50000)\n",
      "(85.65048204502091, 0.96296)\n",
      "test:\n",
      " 157/157 [================================================================================>]  Step: 14ms | Tot: 2s621ms | Loss: 0.6600 | Acc: 83.670% (8367/10000)\n",
      "\n",
      "===> epoch: 28/200\n",
      "train:\n",
      " 782/782 [================================================================================>]  Step: 70ms | Tot: 48s315ms | Loss: 0.1005 | Acc: 96.586% (48293/50000)\n",
      "(78.61157272942364, 0.96586)\n",
      "test:\n",
      " 157/157 [================================================================================>]  Step: 13ms | Tot: 2s642ms | Loss: 0.6769 | Acc: 83.670% (8367/10000)\n",
      "\n",
      "===> epoch: 29/200\n",
      "train:\n",
      " 782/782 [================================================================================>]  Step: 63ms | Tot: 48s389ms | Loss: 0.0976 | Acc: 96.764% (48382/50000)[===========================================>....................................]  Step: 62ms | Tot: 26s89ms | Loss: 0.0934 | Acc: 96.934% (26118/26944)\n",
      "(76.28460587747395, 0.96764)\n",
      "test:\n",
      " 157/157 [================================================================================>]  Step: 14ms | Tot: 2s624ms | Loss: 0.6733 | Acc: 84.390% (8439/10000)\n",
      "\n",
      "===> epoch: 30/200\n",
      "train:\n",
      " 782/782 [================================================================================>]  Step: 68ms | Tot: 48s404ms | Loss: 0.0916 | Acc: 96.898% (48449/50000)\n",
      "(71.61554918205366, 0.96898)\n",
      "test:\n",
      " 157/157 [================================================================================>]  Step: 13ms | Tot: 2s625ms | Loss: 0.7256 | Acc: 83.740% (8374/10000)\n",
      "\n",
      "===> epoch: 31/200\n",
      "train:\n",
      " 782/782 [================================================================================>]  Step: 61ms | Tot: 48s306ms | Loss: 0.0887 | Acc: 97.018% (48509/50000)\n",
      "(69.32931758696213, 0.97018)\n",
      "test:\n",
      " 157/157 [================================================================================>]  Step: 13ms | Tot: 2s634ms | Loss: 0.6777 | Acc: 84.020% (8402/10000)\n",
      "\n",
      "===> epoch: 32/200\n",
      "train:\n",
      " 782/782 [================================================================================>]  Step: 63ms | Tot: 48s415ms | Loss: 0.0828 | Acc: 97.268% (48634/50000)[======================================================>.........................]  Step: 62ms | Tot: 32s927ms | Loss: 0.0780 | Acc: 97.382% (33219/34112)\n",
      "(64.72401477908716, 0.97268)\n",
      "test:\n",
      " 157/157 [================================================================================>]  Step: 14ms | Tot: 2s662ms | Loss: 0.6394 | Acc: 84.390% (8439/10000)\n",
      "\n",
      "===> epoch: 33/200\n",
      "train:\n",
      " 782/782 [================================================================================>]  Step: 61ms | Tot: 48s331ms | Loss: 0.0777 | Acc: 97.414% (48707/50000)[===========================================================================>....]  Step: 62ms | Tot: 45s420ms | Loss: 0.0768 | Acc: 97.428% (45830/47040)\n",
      "(60.79739984241314, 0.97414)\n",
      "test:\n",
      " 157/157 [================================================================================>]  Step: 13ms | Tot: 2s614ms | Loss: 0.6395 | Acc: 84.350% (8435/10000)\n",
      "\n",
      "===> epoch: 34/200\n",
      "train:\n",
      " 782/782 [================================================================================>]  Step: 70ms | Tot: 48s375ms | Loss: 0.0788 | Acc: 97.446% (48723/50000)\n",
      "(61.63419754151255, 0.97446)\n",
      "test:\n",
      " 157/157 [================================================================================>]  Step: 14ms | Tot: 2s625ms | Loss: 0.6731 | Acc: 84.310% (8431/10000)\n",
      "\n",
      "===> epoch: 35/200\n",
      "train:\n",
      " 782/782 [================================================================================>]  Step: 60ms | Tot: 48s330ms | Loss: 0.0741 | Acc: 97.520% (48760/50000)\n",
      "(57.91262802295387, 0.9752)\n",
      "test:\n",
      " 157/157 [================================================================================>]  Step: 14ms | Tot: 2s635ms | Loss: 0.7432 | Acc: 82.840% (8284/10000)\n",
      "\n",
      "===> epoch: 36/200\n",
      "train:\n",
      " 782/782 [================================================================================>]  Step: 77ms | Tot: 48s484ms | Loss: 0.0734 | Acc: 97.566% (48783/50000)==>..........................................................................]  Step: 62ms | Tot: 3s123ms | Loss: 0.0634 | Acc: 98.039% (3200/3264)\n",
      "(57.421620960813016, 0.97566)\n",
      "test:\n",
      " 157/157 [================================================================================>]  Step: 13ms | Tot: 2s635ms | Loss: 0.6626 | Acc: 85.110% (8511/10000)\n",
      "\n",
      "===> epoch: 37/200\n",
      "train:\n",
      " 782/782 [================================================================================>]  Step: 70ms | Tot: 48s373ms | Loss: 0.0697 | Acc: 97.660% (48830/50000)[===================>............................................................]  Step: 62ms | Tot: 12s39ms | Loss: 0.0659 | Acc: 97.829% (12209/12480)\n",
      "(54.50257282750681, 0.9766)\n",
      "test:\n",
      " 157/157 [================================================================================>]  Step: 13ms | Tot: 2s638ms | Loss: 0.7223 | Acc: 84.390% (8439/10000)\n",
      "\n",
      "===> epoch: 38/200\n",
      "train:\n",
      " 782/782 [================================================================================>]  Step: 62ms | Tot: 48s310ms | Loss: 0.0720 | Acc: 97.692% (48846/50000)\n",
      "(56.29391413019039, 0.97692)\n",
      "test:\n",
      " 157/157 [================================================================================>]  Step: 13ms | Tot: 2s643ms | Loss: 0.7038 | Acc: 84.420% (8442/10000)\n",
      "\n",
      "===> epoch: 39/200\n",
      "train:\n",
      " 782/782 [================================================================================>]  Step: 61ms | Tot: 48s337ms | Loss: 0.0670 | Acc: 97.720% (48860/50000)\n",
      "(52.37195860617794, 0.9772)\n",
      "test:\n",
      " 157/157 [================================================================================>]  Step: 13ms | Tot: 2s714ms | Loss: 0.7111 | Acc: 84.350% (8435/10000)\n",
      "\n",
      "===> epoch: 40/200\n",
      "train:\n",
      " 782/782 [================================================================================>]  Step: 73ms | Tot: 48s382ms | Loss: 0.0642 | Acc: 97.908% (48954/50000)\n",
      "(50.229563668021, 0.97908)\n",
      "test:\n",
      " 157/157 [================================================================================>]  Step: 13ms | Tot: 2s640ms | Loss: 0.7157 | Acc: 84.380% (8438/10000)\n",
      "\n",
      "===> epoch: 41/200\n",
      "train:\n",
      " 782/782 [================================================================================>]  Step: 58ms | Tot: 48s371ms | Loss: 0.0610 | Acc: 98.048% (49024/50000)[===================================================================>............]  Step: 63ms | Tot: 40s758ms | Loss: 0.0608 | Acc: 98.037% (41348/42176)\n",
      "(47.72426893073134, 0.98048)\n",
      "test:\n",
      " 157/157 [================================================================================>]  Step: 13ms | Tot: 2s637ms | Loss: 0.7354 | Acc: 84.460% (8446/10000)\n",
      "\n",
      "===> epoch: 42/200\n",
      "train:\n",
      " 782/782 [================================================================================>]  Step: 66ms | Tot: 48s334ms | Loss: 0.0611 | Acc: 98.040% (49020/50000)\n",
      "(47.76465099549387, 0.9804)\n",
      "test:\n",
      " 157/157 [================================================================================>]  Step: 13ms | Tot: 2s629ms | Loss: 0.7488 | Acc: 83.990% (8399/10000)\n",
      "\n",
      "===> epoch: 43/200\n",
      "train:\n",
      " 782/782 [================================================================================>]  Step: 67ms | Tot: 48s457ms | Loss: 0.0595 | Acc: 97.974% (48987/50000)[=================================================>..............................]  Step: 63ms | Tot: 29s684ms | Loss: 0.0597 | Acc: 97.948% (30027/30656)\n",
      "(46.53320847824216, 0.97974)\n",
      "test:\n",
      " 157/157 [================================================================================>]  Step: 14ms | Tot: 2s640ms | Loss: 0.7487 | Acc: 84.190% (8419/10000)\n",
      "\n",
      "===> epoch: 44/200\n",
      "train:\n",
      " 782/782 [================================================================================>]  Step: 66ms | Tot: 48s327ms | Loss: 0.0513 | Acc: 98.298% (49149/50000)\n",
      "(40.13608960597776, 0.98298)\n",
      "test:\n",
      " 157/157 [================================================================================>]  Step: 14ms | Tot: 2s661ms | Loss: 0.7366 | Acc: 84.210% (8421/10000)\n",
      "\n",
      "===> epoch: 45/200\n",
      "train:\n",
      " 782/782 [================================================================================>]  Step: 58ms | Tot: 48s369ms | Loss: 0.0590 | Acc: 98.066% (49033/50000)\n",
      "(46.13452806358691, 0.98066)\n",
      "test:\n",
      " 157/157 [================================================================================>]  Step: 13ms | Tot: 2s638ms | Loss: 0.7524 | Acc: 83.600% (8360/10000)\n",
      "\n",
      "===> epoch: 46/200\n",
      "train:\n",
      " 782/782 [================================================================================>]  Step: 59ms | Tot: 48s354ms | Loss: 0.0577 | Acc: 98.042% (49021/50000)\n",
      "(45.141345051000826, 0.98042)\n",
      "test:\n",
      " 157/157 [================================================================================>]  Step: 13ms | Tot: 2s628ms | Loss: 0.7381 | Acc: 84.310% (8431/10000)\n",
      "\n",
      "===> epoch: 47/200\n",
      "train:\n",
      " 782/782 [================================================================================>]  Step: 66ms | Tot: 48s486ms | Loss: 0.0530 | Acc: 98.256% (49128/50000)\n",
      "(41.419128854351584, 0.98256)\n",
      "test:\n",
      " 157/157 [================================================================================>]  Step: 13ms | Tot: 2s644ms | Loss: 0.7486 | Acc: 83.970% (8397/10000)\n",
      "\n",
      "===> epoch: 48/200\n",
      "train:\n",
      " 782/782 [================================================================================>]  Step: 69ms | Tot: 48s338ms | Loss: 0.0462 | Acc: 98.416% (49208/50000)\n",
      "(36.11510965938214, 0.98416)\n",
      "test:\n",
      " 157/157 [================================================================================>]  Step: 13ms | Tot: 2s642ms | Loss: 0.7825 | Acc: 83.870% (8387/10000)\n",
      "\n",
      "===> epoch: 49/200\n",
      "train:\n",
      " 782/782 [================================================================================>]  Step: 70ms | Tot: 48s381ms | Loss: 0.0447 | Acc: 98.470% (49235/50000)\n",
      "(34.97118543158285, 0.9847)\n",
      "test:\n",
      " 157/157 [================================================================================>]  Step: 14ms | Tot: 2s638ms | Loss: 0.7869 | Acc: 84.430% (8443/10000)\n",
      "\n",
      "===> epoch: 50/200\n",
      "train:\n",
      " 782/782 [================================================================================>]  Step: 63ms | Tot: 48s544ms | Loss: 0.0474 | Acc: 98.396% (49198/50000)\n",
      "(37.07095463667065, 0.98396)\n",
      "test:\n",
      " 157/157 [================================================================================>]  Step: 13ms | Tot: 2s634ms | Loss: 0.7916 | Acc: 83.920% (8392/10000)\n",
      "\n",
      "===> epoch: 51/200\n",
      "train:\n",
      " 782/782 [================================================================================>]  Step: 62ms | Tot: 48s362ms | Loss: 0.0505 | Acc: 98.330% (49165/50000)\n",
      "(39.49846934515517, 0.9833)\n",
      "test:\n",
      " 157/157 [================================================================================>]  Step: 13ms | Tot: 2s643ms | Loss: 0.7500 | Acc: 84.010% (8401/10000)\n",
      "\n",
      "===> epoch: 52/200\n",
      "train:\n",
      " 782/782 [================================================================================>]  Step: 57ms | Tot: 48s369ms | Loss: 0.0438 | Acc: 98.560% (49280/50000)\n",
      "(34.214032933232374, 0.9856)\n",
      "test:\n",
      " 157/157 [================================================================================>]  Step: 13ms | Tot: 2s643ms | Loss: 0.7396 | Acc: 84.420% (8442/10000)\n",
      "\n",
      "===> epoch: 53/200\n",
      "train:\n",
      " 782/782 [================================================================================>]  Step: 66ms | Tot: 48s370ms | Loss: 0.0428 | Acc: 98.606% (49303/50000)[=============================================>..................................]  Step: 62ms | Tot: 27s509ms | Loss: 0.0393 | Acc: 98.764% (28128/28480)\n",
      "(33.46518665761687, 0.98606)\n",
      "test:\n",
      " 157/157 [================================================================================>]  Step: 13ms | Tot: 2s640ms | Loss: 0.7905 | Acc: 84.230% (8423/10000)\n",
      "\n",
      "===> epoch: 54/200\n",
      "train:\n",
      " 782/782 [================================================================================>]  Step: 60ms | Tot: 48s578ms | Loss: 0.0428 | Acc: 98.558% (49279/50000)\n",
      "(33.44918440206675, 0.98558)\n",
      "test:\n",
      " 157/157 [================================================================================>]  Step: 13ms | Tot: 2s643ms | Loss: 0.8021 | Acc: 84.590% (8459/10000)\n",
      "\n",
      "===> epoch: 55/200\n",
      "train:\n",
      " 782/782 [================================================================================>]  Step: 62ms | Tot: 48s372ms | Loss: 0.0455 | Acc: 98.514% (49257/50000).............................................................................]  Step: 63ms | Tot: 1s434ms | Loss: 0.0458 | Acc: 98.177% (1508/1536)\n",
      "(35.597500264062546, 0.98514)\n",
      "test:\n",
      " 157/157 [================================================================================>]  Step: 14ms | Tot: 2s629ms | Loss: 0.7917 | Acc: 84.240% (8424/10000)\n",
      "\n",
      "===> epoch: 56/200\n",
      "train:\n",
      " 782/782 [================================================================================>]  Step: 61ms | Tot: 48s391ms | Loss: 0.0451 | Acc: 98.562% (49281/50000)\n",
      "(35.23119874228723, 0.98562)\n",
      "test:\n",
      " 157/157 [================================================================================>]  Step: 13ms | Tot: 2s637ms | Loss: 0.7532 | Acc: 84.330% (8433/10000)\n",
      "\n",
      "===> epoch: 57/200\n",
      "train:\n",
      " 782/782 [================================================================================>]  Step: 61ms | Tot: 48s485ms | Loss: 0.0396 | Acc: 98.730% (49365/50000)\n",
      "(31.00524632068118, 0.9873)\n",
      "test:\n",
      " 157/157 [================================================================================>]  Step: 14ms | Tot: 2s631ms | Loss: 0.7919 | Acc: 84.570% (8457/10000)\n",
      "\n",
      "===> epoch: 58/200\n",
      "train:\n",
      " 782/782 [================================================================================>]  Step: 64ms | Tot: 48s398ms | Loss: 0.0421 | Acc: 98.652% (49326/50000)[======================================>.........................................]  Step: 63ms | Tot: 23s171ms | Loss: 0.0394 | Acc: 98.713% (23691/24000)\n",
      "(32.89608669758309, 0.98652)\n",
      "test:\n",
      " 157/157 [================================================================================>]  Step: 13ms | Tot: 2s632ms | Loss: 0.7690 | Acc: 84.920% (8492/10000)\n",
      "\n",
      "===> epoch: 59/200\n",
      "train:\n",
      " 782/782 [================================================================================>]  Step: 68ms | Tot: 49s243ms | Loss: 0.0410 | Acc: 98.660% (49330/50000)\n",
      "(32.06227692398534, 0.9866)\n",
      "test:\n",
      " 157/157 [================================================================================>]  Step: 13ms | Tot: 2s687ms | Loss: 0.8057 | Acc: 84.000% (8400/10000)\n",
      "\n",
      "===> epoch: 60/200\n",
      "train:\n",
      " 782/782 [================================================================================>]  Step: 70ms | Tot: 49s922ms | Loss: 0.0390 | Acc: 98.690% (49345/50000)[===================>............................................................]  Step: 64ms | Tot: 11s691ms | Loss: 0.0364 | Acc: 98.757% (11756/11904) [===================================>............................................]  Step: 66ms | Tot: 21s932ms | Loss: 0.0367 | Acc: 98.758% (21869/22144) [===============================================>................................]  Step: 65ms | Tot: 29s753ms | Loss: 0.0360 | Acc: 98.782% (29524/29888)\n",
      "(30.511767806543503, 0.9869)\n",
      "test:\n",
      " 157/157 [================================================================================>]  Step: 15ms | Tot: 2s741ms | Loss: 0.7473 | Acc: 84.500% (8450/10000)\n",
      "\n",
      "===> epoch: 61/200\n",
      "train:\n",
      " 782/782 [================================================================================>]  Step: 66ms | Tot: 50s673ms | Loss: 0.0376 | Acc: 98.726% (49363/50000)[================================================================>...............]  Step: 68ms | Tot: 40s551ms | Loss: 0.0367 | Acc: 98.749% (40005/40512)\n",
      "(29.420646186714293, 0.98726)\n",
      "test:\n",
      " 157/157 [================================================================================>]  Step: 14ms | Tot: 2s721ms | Loss: 0.7305 | Acc: 84.870% (8487/10000)\n",
      "\n",
      "===> epoch: 62/200\n",
      "train:\n",
      " 782/782 [================================================================================>]  Step: 67ms | Tot: 49s676ms | Loss: 0.0377 | Acc: 98.738% (49369/50000)\n",
      "(29.519933205418056, 0.98738)\n",
      "test:\n",
      " 157/157 [================================================================================>]  Step: 16ms | Tot: 2s864ms | Loss: 0.7695 | Acc: 83.770% (8377/10000)\n",
      "\n",
      "===> epoch: 63/200\n",
      "train:\n",
      " 782/782 [================================================================================>]  Step: 77ms | Tot: 51s791ms | Loss: 0.0397 | Acc: 98.714% (49357/50000)======>......................................................................]  Step: 66ms | Tot: 6s176ms | Loss: 0.0394 | Acc: 98.620% (5933/6016)\n",
      "(31.052374341874383, 0.98714)\n",
      "test:\n",
      " 157/157 [================================================================================>]  Step: 15ms | Tot: 2s897ms | Loss: 0.7880 | Acc: 83.890% (8389/10000)\n",
      "\n",
      "===> epoch: 64/200\n",
      "train:\n",
      " 782/782 [================================================================================>]  Step: 67ms | Tot: 51s40ms | Loss: 0.0344 | Acc: 98.790% (49395/50000) [========================================>.......................................]  Step: 63ms | Tot: 25s759ms | Loss: 0.0342 | Acc: 98.770% (25285/25600)\n",
      "(26.92840909928782, 0.9879)\n",
      "test:\n",
      " 157/157 [================================================================================>]  Step: 15ms | Tot: 2s840ms | Loss: 0.7852 | Acc: 84.480% (8448/10000)\n",
      "\n",
      "===> epoch: 65/200\n",
      "train:\n",
      " 782/782 [================================================================================>]  Step: 69ms | Tot: 52s844ms | Loss: 0.0362 | Acc: 98.872% (49436/50000)[========================================>.......................................]  Step: 70ms | Tot: 27s168ms | Loss: 0.0329 | Acc: 98.984% (25340/25600) [=================================================================>..............]  Step: 67ms | Tot: 43s723ms | Loss: 0.0342 | Acc: 98.915% (40832/41280)\n",
      "(28.340016061454662, 0.98872)\n",
      "test:\n",
      " 157/157 [================================================================================>]  Step: 14ms | Tot: 2s779ms | Loss: 0.7800 | Acc: 84.400% (8440/10000)\n",
      "\n",
      "===> epoch: 66/200\n",
      "train:\n",
      " 782/782 [================================================================================>]  Step: 68ms | Tot: 51s216ms | Loss: 0.0346 | Acc: 98.852% (49426/50000)[================>...............................................................]  Step: 64ms | Tot: 10s766ms | Loss: 0.0320 | Acc: 98.835% (10437/10560) [======================================>.........................................]  Step: 64ms | Tot: 24s691ms | Loss: 0.0336 | Acc: 98.868% (24108/24384) [=============================================================>..................]  Step: 64ms | Tot: 39s223ms | Loss: 0.0327 | Acc: 98.896% (38166/38592) [================================================================>...............]  Step: 65ms | Tot: 41s166ms | Loss: 0.0331 | Acc: 98.887% (39998/40448)\n",
      "(27.031632867176086, 0.98852)\n",
      "test:\n",
      " 157/157 [================================================================================>]  Step: 14ms | Tot: 2s864ms | Loss: 0.7908 | Acc: 84.360% (8436/10000)\n",
      "\n",
      "===> epoch: 67/200\n",
      "train:\n",
      " 782/782 [================================================================================>]  Step: 72ms | Tot: 53s40ms | Loss: 0.0327 | Acc: 98.952% (49476/50000))[======================>.........................................................]  Step: 68ms | Tot: 14s571ms | Loss: 0.0358 | Acc: 98.774% (13781/13952) [=====================================>..........................................]  Step: 64ms | Tot: 24s326ms | Loss: 0.0346 | Acc: 98.867% (23032/23296)\n",
      "(25.545600394631037, 0.98952)\n",
      "test:\n",
      " 157/157 [================================================================================>]  Step: 14ms | Tot: 2s804ms | Loss: 0.7674 | Acc: 84.900% (8490/10000)\n",
      "\n",
      "===> epoch: 68/200\n",
      "train:\n",
      " 782/782 [================================================================================>]  Step: 81ms | Tot: 52s623ms | Loss: 0.0340 | Acc: 98.908% (49454/50000)[==================================>.............................................]  Step: 67ms | Tot: 22s613ms | Loss: 0.0318 | Acc: 98.969% (21599/21824) [===========================================================>....................]  Step: 67ms | Tot: 38s783ms | Loss: 0.0330 | Acc: 98.943% (36601/36992)\n",
      "(26.55899727254291, 0.98908)\n",
      "test:\n",
      " 157/157 [================================================================================>]  Step: 15ms | Tot: 3s15ms | Loss: 0.8043 | Acc: 84.630% (8463/10000)\n",
      "\n",
      "===> epoch: 69/200\n",
      "train:\n",
      " 782/782 [================================================================================>]  Step: 67ms | Tot: 53s61ms | Loss: 0.0345 | Acc: 98.922% (49461/50000) [================================================================>...............]  Step: 69ms | Tot: 42s815ms | Loss: 0.0325 | Acc: 98.993% (40104/40512)\n",
      "(26.94365350645967, 0.98922)\n",
      "test:\n",
      " 157/157 [================================================================================>]  Step: 15ms | Tot: 3s51ms | Loss: 0.7236 | Acc: 84.700% (8470/10000)\n",
      "\n",
      "===> epoch: 70/200\n",
      "train:\n",
      " 782/782 [================================================================================>]  Step: 71ms | Tot: 53s154ms | Loss: 0.0325 | Acc: 98.942% (49471/50000)=>...........................................................................]  Step: 66ms | Tot: 3s4ms | Loss: 0.0300 | Acc: 99.062% (2853/2880) [======>.........................................................................]  Step: 67ms | Tot: 4s298ms | Loss: 0.0295 | Acc: 98.975% (4054/4096) [==========================>.....................................................]  Step: 72ms | Tot: 17s474ms | Loss: 0.0270 | Acc: 99.109% (16238/16384) [======================================================>.........................]  Step: 67ms | Tot: 36s235ms | Loss: 0.0303 | Acc: 99.013% (33522/33856) [=============================================================================>..]  Step: 69ms | Tot: 51s417ms | Loss: 0.0322 | Acc: 98.958% (47943/48448)\n",
      "(25.427484147250652, 0.98942)\n",
      "test:\n",
      " 157/157 [================================================================================>]  Step: 14ms | Tot: 2s959ms | Loss: 0.7923 | Acc: 84.090% (8409/10000)\n",
      "\n",
      "===> epoch: 71/200\n",
      "train:\n",
      " 782/782 [================================================================================>]  Step: 71ms | Tot: 1m3s | Loss: 0.0340 | Acc: 98.908% (49454/50000)0)))=====>.......................................................................]  Step: 68ms | Tot: 5s590ms | Loss: 0.0272 | Acc: 99.066% (5199/5248) [============>...................................................................]  Step: 69ms | Tot: 8s437ms | Loss: 0.0254 | Acc: 99.131% (7867/7936)\n",
      "(26.60020919048111, 0.98908)\n",
      "test:\n",
      " 157/157 [================================================================================>]  Step: 15ms | Tot: 3s325ms | Loss: 0.8148 | Acc: 84.080% (8408/10000)\n",
      "\n",
      "===> epoch: 72/200\n",
      "train:\n",
      " 782/782 [================================================================================>]  Step: 75ms | Tot: 54s571ms | Loss: 0.0324 | Acc: 98.938% (49469/50000)[=========================================================>......................]  Step: 65ms | Tot: 39s759ms | Loss: 0.0328 | Acc: 98.900% (35509/35904) [==========================================================>.....................]  Step: 68ms | Tot: 40s419ms | Loss: 0.0328 | Acc: 98.894% (36140/36544)\n",
      "(25.34918994299369, 0.98938)\n",
      "test:\n",
      " 157/157 [================================================================================>]  Step: 15ms | Tot: 2s923ms | Loss: 0.7369 | Acc: 85.070% (8507/10000)\n",
      "\n",
      "===> epoch: 73/200\n",
      "train:\n",
      " 782/782 [================================================================================>]  Step: 72ms | Tot: 52s907ms | Loss: 0.0335 | Acc: 98.902% (49451/50000)>............................................................................]  Step: 65ms | Tot: 1s933ms | Loss: 0.0191 | Acc: 99.219% (1905/1920) [===============================================================>................]  Step: 69ms | Tot: 42s268ms | Loss: 0.0322 | Acc: 98.968% (39587/40000) [=========================================================================>......]  Step: 70ms | Tot: 48s899ms | Loss: 0.0326 | Acc: 98.935% (45716/46208) [=============================================================================>..]  Step: 67ms | Tot: 51s311ms | Loss: 0.0330 | Acc: 98.920% (47988/48512)\n",
      "(26.188740261772182, 0.98902)\n",
      "test:\n",
      " 157/157 [================================================================================>]  Step: 15ms | Tot: 2s951ms | Loss: 0.7890 | Acc: 84.550% (8455/10000)\n",
      "\n",
      "===> epoch: 74/200\n",
      "train:\n",
      " 782/782 [================================================================================>]  Step: 70ms | Tot: 53s433ms | Loss: 0.0307 | Acc: 99.010% (49505/50000)[===================================================================>............]  Step: 66ms | Tot: 45s112ms | Loss: 0.0318 | Acc: 98.991% (41687/42112) [=====================================================================>..........]  Step: 64ms | Tot: 46s237ms | Loss: 0.0316 | Acc: 98.984% (42761/43200)\n",
      "(24.04174430097919, 0.9901)\n",
      "test:\n",
      " 157/157 [================================================================================>]  Step: 14ms | Tot: 2s990ms | Loss: 0.7968 | Acc: 84.820% (8482/10000)\n",
      "\n",
      "===> epoch: 75/200\n",
      "train:\n",
      " 782/782 [================================================================================>]  Step: 68ms | Tot: 52s372ms | Loss: 0.0132 | Acc: 99.572% (49786/50000)[=================>..............................................................]  Step: 68ms | Tot: 11s114ms | Loss: 0.0169 | Acc: 99.429% (10627/10688)\n",
      "(10.314884004823398, 0.99572)\n",
      "test:\n",
      " 157/157 [================================================================================>]  Step: 13ms | Tot: 2s737ms | Loss: 0.8460 | Acc: 85.510% (8551/10000)\n",
      "\n",
      "===> epoch: 76/200\n",
      "train:\n",
      " 782/782 [================================================================================>]  Step: 70ms | Tot: 51s35ms | Loss: 0.0087 | Acc: 99.692% (49846/50000) [===================>............................................................]  Step: 69ms | Tot: 12s386ms | Loss: 0.0091 | Acc: 99.720% (12126/12160) [====================================================>...........................]  Step: 63ms | Tot: 33s255ms | Loss: 0.0088 | Acc: 99.694% (32604/32704) [=======================================================>........................]  Step: 64ms | Tot: 35s7ms | Loss: 0.0088 | Acc: 99.692% (34326/34432) [=========================================================>......................]  Step: 66ms | Tot: 36s762ms | Loss: 0.0087 | Acc: 99.696% (36050/36160)\n",
      "(6.817971015880175, 0.99692)\n",
      "test:\n",
      " 157/157 [================================================================================>]  Step: 15ms | Tot: 2s883ms | Loss: 0.9040 | Acc: 85.470% (8547/10000)\n",
      "\n",
      "===> epoch: 77/200\n",
      "train:\n",
      " 782/782 [================================================================================>]  Step: 72ms | Tot: 51s884ms | Loss: 0.0080 | Acc: 99.756% (49878/50000)==>..........................................................................]  Step: 66ms | Tot: 3s485ms | Loss: 0.0120 | Acc: 99.716% (3510/3520) [==========================================>.....................................]  Step: 66ms | Tot: 27s78ms | Loss: 0.0076 | Acc: 99.741% (26236/26304) [================================================================>...............]  Step: 64ms | Tot: 41s564ms | Loss: 0.0079 | Acc: 99.747% (40218/40320)\n",
      "(6.274418026623607, 0.99756)\n",
      "test:\n",
      " 157/157 [================================================================================>]  Step: 13ms | Tot: 2s883ms | Loss: 0.9230 | Acc: 85.560% (8556/10000)\n",
      "\n",
      "===> epoch: 78/200\n",
      "train:\n",
      " 782/782 [================================================================================>]  Step: 72ms | Tot: 51s856ms | Loss: 0.0108 | Acc: 99.650% (49825/50000)============>.................................................................]  Step: 69ms | Tot: 9s173ms | Loss: 0.0086 | Acc: 99.710% (8934/8960)\n",
      "(8.446619560423642, 0.9965)\n",
      "test:\n",
      " 157/157 [================================================================================>]  Step: 14ms | Tot: 2s887ms | Loss: 0.9489 | Acc: 84.950% (8495/10000)\n",
      "\n",
      "===> epoch: 79/200\n",
      "train:\n",
      " 782/782 [================================================================================>]  Step: 62ms | Tot: 50s425ms | Loss: 0.0121 | Acc: 99.602% (49801/50000)==>..........................................................................]  Step: 69ms | Tot: 3s662ms | Loss: 0.0082 | Acc: 99.749% (3575/3584) [======================================================================>.........]  Step: 65ms | Tot: 44s483ms | Loss: 0.0119 | Acc: 99.623% (43866/44032)\n",
      "(9.489918842100451, 0.99602)\n",
      "test:\n",
      " 157/157 [================================================================================>]  Step: 14ms | Tot: 2s712ms | Loss: 0.9190 | Acc: 85.440% (8544/10000)\n",
      "\n",
      "===> epoch: 80/200\n",
      "train:\n",
      " 782/782 [================================================================================>]  Step: 68ms | Tot: 49s359ms | Loss: 0.0078 | Acc: 99.720% (49860/50000)[==================>.............................................................]  Step: 65ms | Tot: 11s284ms | Loss: 0.0079 | Acc: 99.710% (11359/11392)\n",
      "(6.0836246402031975, 0.9972)\n",
      "test:\n",
      " 157/157 [================================================================================>]  Step: 14ms | Tot: 2s714ms | Loss: 0.9583 | Acc: 85.480% (8548/10000)\n",
      "\n",
      "===> epoch: 81/200\n",
      "train:\n",
      " 782/782 [================================================================================>]  Step: 72ms | Tot: 49s414ms | Loss: 0.0075 | Acc: 99.736% (49868/50000)[========================================>.......................................]  Step: 63ms | Tot: 25s162ms | Loss: 0.0070 | Acc: 99.753% (25409/25472)\n",
      "(5.867716702683538, 0.99736)\n",
      "test:\n",
      " 157/157 [================================================================================>]  Step: 13ms | Tot: 2s703ms | Loss: 0.9717 | Acc: 85.310% (8531/10000)\n",
      "\n",
      "===> epoch: 82/200\n",
      "train:\n",
      " 782/782 [================================================================================>]  Step: 59ms | Tot: 49s281ms | Loss: 0.0075 | Acc: 99.754% (49877/50000)[==========================================>.....................................]  Step: 63ms | Tot: 26s197ms | Loss: 0.0061 | Acc: 99.816% (26575/26624)\n",
      "(5.845724029310986, 0.99754)\n",
      "test:\n",
      " 157/157 [================================================================================>]  Step: 13ms | Tot: 2s704ms | Loss: 0.9540 | Acc: 85.460% (8546/10000)\n",
      "\n",
      "===> epoch: 83/200\n",
      "train:\n",
      " 782/782 [================================================================================>]  Step: 68ms | Tot: 49s422ms | Loss: 0.0098 | Acc: 99.670% (49835/50000)[=========================================================>......................]  Step: 63ms | Tot: 35s332ms | Loss: 0.0102 | Acc: 99.651% (35651/35776)\n",
      "(7.628241263013479, 0.9967)\n",
      "test:\n",
      " 157/157 [================================================================================>]  Step: 13ms | Tot: 2s707ms | Loss: 0.9732 | Acc: 85.680% (8568/10000)\n",
      "\n",
      "===> epoch: 84/200\n",
      "train:\n",
      " 782/782 [================================================================================>]  Step: 64ms | Tot: 49s803ms | Loss: 0.0140 | Acc: 99.612% (49806/50000)\n",
      "(10.922996698714996, 0.99612)\n",
      "test:\n",
      " 157/157 [================================================================================>]  Step: 14ms | Tot: 2s702ms | Loss: 0.9429 | Acc: 85.150% (8515/10000)\n",
      "\n",
      "===> epoch: 85/200\n",
      "train:\n",
      " 782/782 [================================================================================>]  Step: 68ms | Tot: 49s571ms | Loss: 0.0067 | Acc: 99.806% (49903/50000)============>.................................................................]  Step: 63ms | Tot: 8s706ms | Loss: 0.0061 | Acc: 99.820% (8880/8896)\n",
      "(5.219178109360655, 0.99806)\n",
      "test:\n",
      " 157/157 [================================================================================>]  Step: 14ms | Tot: 2s701ms | Loss: 1.0024 | Acc: 85.480% (8548/10000)\n",
      "\n",
      "===> epoch: 86/200\n",
      "train:\n",
      " 782/782 [================================================================================>]  Step: 65ms | Tot: 49s148ms | Loss: 0.0057 | Acc: 99.832% (49916/50000)[==============================================================================>.]  Step: 63ms | Tot: 48s15ms | Loss: 0.0057 | Acc: 99.834% (48815/48896)\n",
      "(4.456128816173077, 0.99832)\n",
      "test:\n",
      " 157/157 [================================================================================>]  Step: 13ms | Tot: 2s740ms | Loss: 1.0039 | Acc: 85.660% (8566/10000)\n",
      "\n",
      "===> epoch: 87/200\n",
      "train:\n",
      " 782/782 [================================================================================>]  Step: 63ms | Tot: 49s284ms | Loss: 0.0077 | Acc: 99.750% (49875/50000)[===================================================>............................]  Step: 63ms | Tot: 31s792ms | Loss: 0.0068 | Acc: 99.771% (32182/32256) [====================================================>...........................]  Step: 63ms | Tot: 32s610ms | Loss: 0.0070 | Acc: 99.767% (33011/33088)\n",
      "(5.992891827729636, 0.9975)\n",
      "test:\n",
      " 157/157 [================================================================================>]  Step: 13ms | Tot: 2s698ms | Loss: 1.0291 | Acc: 85.080% (8508/10000)\n",
      "\n",
      "===> epoch: 88/200\n",
      "train:\n",
      " 782/782 [================================================================================>]  Step: 62ms | Tot: 49s174ms | Loss: 0.0093 | Acc: 99.696% (49848/50000)[=======================================>........................................]  Step: 65ms | Tot: 24s303ms | Loss: 0.0113 | Acc: 99.629% (24676/24768)\n",
      "(7.3087790502358985, 0.99696)\n",
      "test:\n",
      " 157/157 [================================================================================>]  Step: 13ms | Tot: 2s703ms | Loss: 0.9553 | Acc: 85.220% (8522/10000)\n",
      "\n",
      "===> epoch: 89/200\n",
      "train:\n",
      " 782/782 [================================================================================>]  Step: 65ms | Tot: 49s160ms | Loss: 0.0076 | Acc: 99.748% (49874/50000)[===================================================================>............]  Step: 64ms | Tot: 41s239ms | Loss: 0.0080 | Acc: 99.733% (41872/41984)\n",
      "(5.958226787422973, 0.99748)\n",
      "test:\n",
      " 157/157 [================================================================================>]  Step: 14ms | Tot: 2s708ms | Loss: 0.8985 | Acc: 85.660% (8566/10000)\n",
      "\n",
      "===> epoch: 90/200\n",
      "train:\n",
      " 782/782 [================================================================================>]  Step: 74ms | Tot: 49s290ms | Loss: 0.0066 | Acc: 99.802% (49901/50000)\n",
      "(5.132100194872692, 0.99802)\n",
      "test:\n",
      " 157/157 [================================================================================>]  Step: 13ms | Tot: 2s768ms | Loss: 0.9944 | Acc: 85.180% (8518/10000)\n",
      "\n",
      "===> epoch: 91/200\n",
      "train:\n",
      " 782/782 [================================================================================>]  Step: 65ms | Tot: 48s681ms | Loss: 0.0089 | Acc: 99.706% (49853/50000)\n",
      "(6.987909830879289, 0.99706)\n",
      "test:\n",
      " 157/157 [================================================================================>]  Step: 14ms | Tot: 2s652ms | Loss: 0.9486 | Acc: 85.510% (8551/10000)\n",
      "\n",
      "===> epoch: 92/200\n",
      "train:\n",
      " 782/782 [================================================================================>]  Step: 63ms | Tot: 48s612ms | Loss: 0.0077 | Acc: 99.758% (49879/50000)[=======================================>........................................]  Step: 63ms | Tot: 23s927ms | Loss: 0.0065 | Acc: 99.817% (24595/24640)\n",
      "(6.030412770161092, 0.99758)\n",
      "test:\n",
      " 157/157 [================================================================================>]  Step: 14ms | Tot: 2s667ms | Loss: 0.9420 | Acc: 85.820% (8582/10000)\n",
      "\n",
      "===> epoch: 93/200\n",
      "train:\n",
      " 782/782 [================================================================================>]  Step: 65ms | Tot: 48s602ms | Loss: 0.0065 | Acc: 99.768% (49884/50000)\n",
      "(5.098301279014322, 0.99768)\n",
      "test:\n",
      " 157/157 [================================================================================>]  Step: 13ms | Tot: 2s695ms | Loss: 1.0009 | Acc: 85.220% (8522/10000)\n",
      "\n",
      "===> epoch: 94/200\n",
      "train:\n",
      " 782/782 [================================================================================>]  Step: 67ms | Tot: 48s611ms | Loss: 0.0091 | Acc: 99.706% (49853/50000)\n",
      "(7.124143568843465, 0.99706)\n",
      "test:\n",
      " 157/157 [================================================================================>]  Step: 13ms | Tot: 2s643ms | Loss: 0.9577 | Acc: 85.190% (8519/10000)\n",
      "\n",
      "===> epoch: 95/200\n",
      "train:\n",
      " 782/782 [================================================================================>]  Step: 62ms | Tot: 48s629ms | Loss: 0.0078 | Acc: 99.744% (49872/50000)==========>...................................................................]  Step: 62ms | Tot: 7s419ms | Loss: 0.0102 | Acc: 99.688% (7656/7680)\n",
      "(6.090826170415312, 0.99744)\n",
      "test:\n",
      " 157/157 [================================================================================>]  Step: 14ms | Tot: 2s667ms | Loss: 0.9488 | Acc: 85.660% (8566/10000)\n",
      "\n",
      "===> epoch: 96/200\n",
      "train:\n",
      " 782/782 [================================================================================>]  Step: 72ms | Tot: 48s617ms | Loss: 0.0079 | Acc: 99.754% (49877/50000)[==================================================>.............................]  Step: 65ms | Tot: 30s614ms | Loss: 0.0069 | Acc: 99.800% (31489/31552)\n",
      "(6.166895795715163, 0.99754)\n",
      "test:\n",
      " 157/157 [================================================================================>]  Step: 14ms | Tot: 2s659ms | Loss: 0.9641 | Acc: 85.290% (8529/10000)\n",
      "\n",
      "===> epoch: 97/200\n",
      "train:\n",
      " 782/782 [================================================================================>]  Step: 63ms | Tot: 48s743ms | Loss: 0.0075 | Acc: 99.758% (49879/50000)\n",
      "(5.903413962858394, 0.99758)\n",
      "test:\n",
      " 157/157 [================================================================================>]  Step: 13ms | Tot: 2s650ms | Loss: 1.0228 | Acc: 85.250% (8525/10000)\n",
      "\n",
      "===> epoch: 98/200\n",
      "train:\n",
      " 782/782 [================================================================================>]  Step: 60ms | Tot: 48s699ms | Loss: 0.0077 | Acc: 99.740% (49870/50000)\n",
      "(6.010223703831798, 0.9974)\n",
      "test:\n",
      " 157/157 [================================================================================>]  Step: 15ms | Tot: 2s663ms | Loss: 0.9612 | Acc: 85.490% (8549/10000)\n",
      "\n",
      "===> epoch: 99/200\n",
      "train:\n",
      " 782/782 [================================================================================>]  Step: 60ms | Tot: 48s599ms | Loss: 0.0085 | Acc: 99.704% (49852/50000)\n",
      "(6.674949535638007, 0.99704)\n",
      "test:\n",
      " 157/157 [================================================================================>]  Step: 14ms | Tot: 2s653ms | Loss: 1.0008 | Acc: 85.580% (8558/10000)\n",
      "\n",
      "===> epoch: 100/200\n",
      "train:\n",
      " 782/782 [================================================================================>]  Step: 75ms | Tot: 1m991ms | Loss: 0.0088 | Acc: 99.708% (49854/50000))======>.......................................................................]  Step: 70ms | Tot: 4s972ms | Loss: 0.0049 | Acc: 99.842% (5048/5056)\n",
      "(6.883053873740209, 0.99708)\n",
      "test:\n",
      " 157/157 [================================================================================>]  Step: 15ms | Tot: 3s152ms | Loss: 0.9998 | Acc: 85.330% (8533/10000)\n",
      "\n",
      "===> epoch: 101/200\n",
      "train:\n",
      " 782/782 [================================================================================>]  Step: 66ms | Tot: 1m5s | Loss: 0.0071 | Acc: 99.794% (49897/50000)2)) [====================================================================>...........]  Step: 95ms | Tot: 56s527ms | Loss: 0.0066 | Acc: 99.809% (42862/42944)\n",
      "(5.514910942945789, 0.99794)\n",
      "test:\n",
      " 157/157 [================================================================================>]  Step: 18ms | Tot: 3s431ms | Loss: 0.9877 | Acc: 85.330% (8533/10000)\n",
      "\n",
      "===> epoch: 102/200\n",
      "train:\n",
      " 782/782 [================================================================================>]  Step: 62ms | Tot: 1m5s | Loss: 0.0078 | Acc: 99.736% (49868/50000)2))\n",
      "(6.093495823963167, 0.99736)\n",
      "test:\n",
      " 157/157 [================================================================================>]  Step: 15ms | Tot: 2s998ms | Loss: 1.0364 | Acc: 85.450% (8545/10000)\n",
      "\n",
      "===> epoch: 103/200\n",
      "train:\n",
      " 782/782 [================================================================================>]  Step: 64ms | Tot: 1m4s | Loss: 0.0072 | Acc: 99.758% (49879/50000)4)) [==================================>.............................................]  Step: 75ms | Tot: 28s898ms | Loss: 0.0089 | Acc: 99.703% (21823/21888)\n",
      "(5.644763731067087, 0.99758)\n",
      "test:\n",
      " 157/157 [================================================================================>]  Step: 18ms | Tot: 3s360ms | Loss: 0.9993 | Acc: 85.530% (8553/10000)\n",
      "\n",
      "===> epoch: 104/200\n",
      "train:\n",
      " 782/782 [================================================================================>]  Step: 61ms | Tot: 1m3s | Loss: 0.0086 | Acc: 99.698% (49849/50000)2))\n",
      "(6.714448960909522, 0.99698)\n",
      "test:\n",
      " 157/157 [================================================================================>]  Step: 15ms | Tot: 3s83ms | Loss: 0.9703 | Acc: 85.570% (8557/10000)\n",
      "\n",
      "===> epoch: 105/200\n",
      "train:\n",
      " 782/782 [================================================================================>]  Step: 74ms | Tot: 1m3s | Loss: 0.0066 | Acc: 99.778% (49889/50000)4)) [==================================================>.............................]  Step: 88ms | Tot: 40s379ms | Loss: 0.0065 | Acc: 99.785% (31548/31616) [====================================================>...........................]  Step: 89ms | Tot: 41s706ms | Loss: 0.0064 | Acc: 99.785% (32506/32576) [==========================================================>.....................]  Step: 74ms | Tot: 46s540ms | Loss: 0.0066 | Acc: 99.778% (36463/36544) [==========================================================>.....................]  Step: 72ms | Tot: 46s827ms | Loss: 0.0066 | Acc: 99.774% (36717/36800) [============================================================================>...]  Step: 73ms | Tot: 1m347ms | Loss: 0.0064 | Acc: 99.781% (47448/47552)\n",
      "(5.171055262075242, 0.99778)\n",
      "test:\n",
      " 157/157 [================================================================================>]  Step: 15ms | Tot: 3s65ms | Loss: 1.0201 | Acc: 85.590% (8559/10000)\n",
      "\n",
      "===> epoch: 106/200\n",
      "train:\n",
      " 782/782 [================================================================================>]  Step: 66ms | Tot: 49s712ms | Loss: 0.0082 | Acc: 99.740% (49870/50000)\n",
      "(6.4162441128828505, 0.9974)\n",
      "test:\n",
      " 157/157 [================================================================================>]  Step: 14ms | Tot: 2s704ms | Loss: 1.0217 | Acc: 85.160% (8516/10000)\n",
      "\n",
      "===> epoch: 107/200\n",
      "train:\n",
      " 782/782 [================================================================================>]  Step: 63ms | Tot: 49s59ms | Loss: 0.0080 | Acc: 99.770% (49885/50000)\n",
      "(6.256814805619797, 0.9977)\n",
      "test:\n",
      " 157/157 [================================================================================>]  Step: 14ms | Tot: 2s695ms | Loss: 0.9544 | Acc: 85.470% (8547/10000)\n",
      "\n",
      "===> epoch: 108/200\n",
      "train:\n",
      " 782/782 [================================================================================>]  Step: 66ms | Tot: 49s47ms | Loss: 0.0069 | Acc: 99.778% (49889/50000)\n",
      "(5.426803629501592, 0.99778)\n",
      "test:\n",
      " 157/157 [================================================================================>]  Step: 13ms | Tot: 2s696ms | Loss: 0.9864 | Acc: 85.320% (8532/10000)\n",
      "\n",
      "===> epoch: 109/200\n",
      "train:\n",
      " 782/782 [================================================================================>]  Step: 62ms | Tot: 49s116ms | Loss: 0.0060 | Acc: 99.808% (49904/50000)\n",
      "(4.700575127193588, 0.99808)\n",
      "test:\n",
      " 157/157 [================================================================================>]  Step: 14ms | Tot: 2s697ms | Loss: 1.0470 | Acc: 85.430% (8543/10000)\n",
      "\n",
      "===> epoch: 110/200\n",
      "train:\n",
      " 782/782 [================================================================================>]  Step: 61ms | Tot: 49s40ms | Loss: 0.0081 | Acc: 99.750% (49875/50000).........................................................................]  Step: 71ms | Tot: 141ms | Loss: 0.0021 | Acc: 100.000% (192/192)\n",
      "(6.30554879608917, 0.9975)\n",
      "test:\n",
      " 157/157 [================================================================================>]  Step: 15ms | Tot: 2s703ms | Loss: 1.0906 | Acc: 85.130% (8513/10000)\n",
      "\n",
      "===> epoch: 111/200\n",
      "train:\n",
      " 782/782 [================================================================================>]  Step: 65ms | Tot: 49s129ms | Loss: 0.0085 | Acc: 99.720% (49860/50000)\n",
      "(6.660401555299359, 0.9972)\n",
      "test:\n",
      " 157/157 [================================================================================>]  Step: 13ms | Tot: 2s696ms | Loss: 1.0013 | Acc: 85.560% (8556/10000)\n",
      "\n",
      "===> epoch: 112/200\n",
      "train:\n",
      " 782/782 [================================================================================>]  Step: 62ms | Tot: 49s25ms | Loss: 0.0071 | Acc: 99.766% (49883/50000)\n",
      "(5.515018132144178, 0.99766)\n",
      "test:\n",
      " 157/157 [================================================================================>]  Step: 14ms | Tot: 2s739ms | Loss: 1.0572 | Acc: 85.300% (8530/10000)\n",
      "\n",
      "===> epoch: 113/200\n",
      "train:\n",
      " 782/782 [================================================================================>]  Step: 62ms | Tot: 49s54ms | Loss: 0.0068 | Acc: 99.792% (49896/50000)============>..................................................................]  Step: 63ms | Tot: 8s136ms | Loss: 0.0045 | Acc: 99.891% (8247/8256)\n",
      "(5.33092116318312, 0.99792)\n",
      "test:\n",
      " 157/157 [================================================================================>]  Step: 14ms | Tot: 2s689ms | Loss: 1.0207 | Acc: 84.960% (8496/10000)\n",
      "\n",
      "===> epoch: 114/200\n",
      "train:\n",
      " 782/782 [================================================================================>]  Step: 72ms | Tot: 48s986ms | Loss: 0.0084 | Acc: 99.764% (49882/50000)[==================================================>.............................]  Step: 63ms | Tot: 30s676ms | Loss: 0.0047 | Acc: 99.853% (31314/31360)\n",
      "(6.5571950233807, 0.99764)\n",
      "test:\n",
      " 157/157 [================================================================================>]  Step: 13ms | Tot: 2s695ms | Loss: 1.0260 | Acc: 84.380% (8438/10000)\n",
      "\n",
      "===> epoch: 115/200\n",
      "train:\n",
      " 782/782 [================================================================================>]  Step: 76ms | Tot: 48s941ms | Loss: 0.0073 | Acc: 99.766% (49883/50000)[=============================================================>..................]  Step: 63ms | Tot: 37s716ms | Loss: 0.0084 | Acc: 99.733% (38489/38592)\n",
      "(5.747606920722319, 0.99766)\n",
      "test:\n",
      " 157/157 [================================================================================>]  Step: 13ms | Tot: 2s687ms | Loss: 1.0515 | Acc: 85.350% (8535/10000)\n",
      "\n",
      "===> epoch: 116/200\n",
      "train:\n",
      " 782/782 [================================================================================>]  Step: 66ms | Tot: 49s57ms | Loss: 0.0055 | Acc: 99.828% (49914/50000) [===========================>....................................................]  Step: 63ms | Tot: 16s493ms | Loss: 0.0040 | Acc: 99.888% (16877/16896) [==============================================>.................................]  Step: 64ms | Tot: 28s480ms | Loss: 0.0046 | Acc: 99.866% (29017/29056)\n",
      "(4.279534911812334, 0.99828)\n",
      "test:\n",
      " 157/157 [================================================================================>]  Step: 14ms | Tot: 2s695ms | Loss: 1.0663 | Acc: 85.240% (8524/10000)\n",
      "\n",
      "===> epoch: 117/200\n",
      "train:\n",
      " 782/782 [================================================================================>]  Step: 67ms | Tot: 48s988ms | Loss: 0.0080 | Acc: 99.726% (49863/50000)\n",
      "(6.290237558830995, 0.99726)\n",
      "test:\n",
      " 157/157 [================================================================================>]  Step: 13ms | Tot: 2s704ms | Loss: 0.9696 | Acc: 85.700% (8570/10000)\n",
      "\n",
      "===> epoch: 118/200\n",
      "train:\n",
      " 782/782 [================================================================================>]  Step: 66ms | Tot: 48s534ms | Loss: 0.0063 | Acc: 99.798% (49899/50000)\n",
      "(4.890109636253328, 0.99798)\n",
      "test:\n",
      " 157/157 [================================================================================>]  Step: 13ms | Tot: 2s648ms | Loss: 0.9776 | Acc: 85.570% (8557/10000)\n",
      "\n",
      "===> epoch: 119/200\n",
      "train:\n",
      " 782/782 [================================================================================>]  Step: 62ms | Tot: 48s467ms | Loss: 0.0082 | Acc: 99.738% (49869/50000)\n",
      "(6.41562317574062, 0.99738)\n",
      "test:\n",
      " 157/157 [================================================================================>]  Step: 16ms | Tot: 2s678ms | Loss: 1.0054 | Acc: 85.800% (8580/10000)\n",
      "\n",
      "===> epoch: 120/200\n",
      "train:\n",
      " 782/782 [================================================================================>]  Step: 71ms | Tot: 48s579ms | Loss: 0.0087 | Acc: 99.708% (49854/50000)\n",
      "(6.778983144085942, 0.99708)\n",
      "test:\n",
      " 157/157 [================================================================================>]  Step: 13ms | Tot: 2s648ms | Loss: 0.9919 | Acc: 85.360% (8536/10000)\n",
      "\n",
      "===> epoch: 121/200\n",
      "train:\n",
      " 782/782 [================================================================================>]  Step: 64ms | Tot: 48s486ms | Loss: 0.0061 | Acc: 99.806% (49903/50000)\n",
      "(4.75671139754013, 0.99806)\n",
      "test:\n",
      " 157/157 [================================================================================>]  Step: 13ms | Tot: 2s654ms | Loss: 1.0022 | Acc: 85.630% (8563/10000)\n",
      "\n",
      "===> epoch: 122/200\n",
      "train:\n",
      " 782/782 [================================================================================>]  Step: 67ms | Tot: 48s520ms | Loss: 0.0067 | Acc: 99.770% (49885/50000)\n",
      "(5.271898298954511, 0.9977)\n",
      "test:\n",
      " 157/157 [================================================================================>]  Step: 13ms | Tot: 2s646ms | Loss: 1.0310 | Acc: 85.490% (8549/10000)\n",
      "\n",
      "===> epoch: 123/200\n",
      "train:\n",
      " 782/782 [================================================================================>]  Step: 67ms | Tot: 48s637ms | Loss: 0.0072 | Acc: 99.788% (49894/50000)[===================================================>............................]  Step: 63ms | Tot: 31s530ms | Loss: 0.0070 | Acc: 99.778% (32376/32448) [=====================================================>..........................]  Step: 63ms | Tot: 32s288ms | Loss: 0.0068 | Acc: 99.783% (33144/33216)\n",
      "(5.622200352599975, 0.99788)\n",
      "test:\n",
      " 157/157 [================================================================================>]  Step: 14ms | Tot: 2s661ms | Loss: 0.9647 | Acc: 85.540% (8554/10000)\n",
      "\n",
      "===> epoch: 124/200\n",
      "train:\n",
      " 782/782 [================================================================================>]  Step: 65ms | Tot: 48s509ms | Loss: 0.0059 | Acc: 99.828% (49914/50000)[=======================>........................................................]  Step: 63ms | Tot: 14s49ms | Loss: 0.0059 | Acc: 99.807% (14500/14528)\n",
      "(4.588675239659096, 0.99828)\n",
      "test:\n",
      " 157/157 [================================================================================>]  Step: 13ms | Tot: 2s634ms | Loss: 1.0216 | Acc: 85.580% (8558/10000)\n",
      "\n",
      "===> epoch: 125/200\n",
      "train:\n",
      " 782/782 [================================================================================>]  Step: 63ms | Tot: 48s503ms | Loss: 0.0073 | Acc: 99.778% (49889/50000)=========>....................................................................]  Step: 63ms | Tot: 7s47ms | Loss: 0.0087 | Acc: 99.671% (7272/7296)\n",
      "(5.71205216041335, 0.99778)\n",
      "test:\n",
      " 157/157 [================================================================================>]  Step: 13ms | Tot: 2s676ms | Loss: 1.0413 | Acc: 85.370% (8537/10000)\n",
      "\n",
      "===> epoch: 126/200\n",
      "train:\n",
      " 782/782 [================================================================================>]  Step: 61ms | Tot: 48s468ms | Loss: 0.0115 | Acc: 99.772% (49886/50000)\n",
      "(8.99368391572898, 0.99772)\n",
      "test:\n",
      " 157/157 [================================================================================>]  Step: 13ms | Tot: 2s656ms | Loss: 1.0583 | Acc: 85.310% (8531/10000)\n",
      "\n",
      "===> epoch: 127/200\n",
      "train:\n",
      " 782/782 [================================================================================>]  Step: 67ms | Tot: 48s642ms | Loss: 0.0129 | Acc: 99.634% (49817/50000)[=====================>..........................................................]  Step: 62ms | Tot: 12s936ms | Loss: 0.0251 | Acc: 99.336% (13160/13248) [=================================>..............................................]  Step: 63ms | Tot: 20s577ms | Loss: 0.0211 | Acc: 99.437% (21001/21120)\n",
      "(10.103402764701968, 0.99634)\n",
      "test:\n",
      " 157/157 [================================================================================>]  Step: 13ms | Tot: 2s643ms | Loss: 0.9280 | Acc: 86.270% (8627/10000)\n",
      "\n",
      "===> epoch: 128/200\n",
      "train:\n",
      " 782/782 [================================================================================>]  Step: 69ms | Tot: 48s499ms | Loss: 0.0056 | Acc: 99.874% (49937/50000)\n",
      "(4.343687795655569, 0.99874)\n",
      "test:\n",
      " 157/157 [================================================================================>]  Step: 13ms | Tot: 2s656ms | Loss: 0.9910 | Acc: 85.780% (8578/10000)\n",
      "\n",
      "===> epoch: 129/200\n",
      "train:\n",
      " 782/782 [================================================================================>]  Step: 60ms | Tot: 48s498ms | Loss: 0.0040 | Acc: 99.880% (49940/50000)\n",
      "(3.151652211613964, 0.9988)\n",
      "test:\n",
      " 157/157 [================================================================================>]  Step: 14ms | Tot: 2s654ms | Loss: 1.0794 | Acc: 85.940% (8594/10000)\n",
      "\n",
      "===> epoch: 130/200\n",
      "train:\n",
      " 782/782 [================================================================================>]  Step: 64ms | Tot: 48s641ms | Loss: 0.0079 | Acc: 99.752% (49876/50000)\n",
      "(6.165732989779826, 0.99752)\n",
      "test:\n",
      " 157/157 [================================================================================>]  Step: 13ms | Tot: 2s667ms | Loss: 0.9483 | Acc: 85.600% (8560/10000)\n",
      "\n",
      "===> epoch: 131/200\n",
      "train:\n",
      " 782/782 [================================================================================>]  Step: 64ms | Tot: 48s481ms | Loss: 0.0073 | Acc: 99.758% (49879/50000)\n",
      "(5.738181877897659, 0.99758)\n",
      "test:\n",
      " 157/157 [================================================================================>]  Step: 14ms | Tot: 2s663ms | Loss: 0.9966 | Acc: 85.530% (8553/10000)\n",
      "\n",
      "===> epoch: 132/200\n",
      "train:\n",
      " 782/782 [================================================================================>]  Step: 72ms | Tot: 48s498ms | Loss: 0.0069 | Acc: 99.798% (49899/50000)[========================================>.......................................]  Step: 62ms | Tot: 24s650ms | Loss: 0.0073 | Acc: 99.792% (25419/25472) [================================================>...............................]  Step: 63ms | Tot: 29s622ms | Loss: 0.0069 | Acc: 99.794% (30529/30592)\n",
      "(5.384610716022507, 0.99798)\n",
      "test:\n",
      " 157/157 [================================================================================>]  Step: 13ms | Tot: 2s664ms | Loss: 0.9976 | Acc: 85.620% (8562/10000)\n",
      "\n",
      "===> epoch: 133/200\n",
      "train:\n",
      " 782/782 [================================================================================>]  Step: 63ms | Tot: 48s476ms | Loss: 0.0065 | Acc: 99.766% (49883/50000)\n",
      "(5.064185236165031, 0.99766)\n",
      "test:\n",
      " 157/157 [================================================================================>]  Step: 13ms | Tot: 2s646ms | Loss: 1.0756 | Acc: 85.400% (8540/10000)\n",
      "\n",
      "===> epoch: 134/200\n",
      "train:\n",
      " 782/782 [================================================================================>]  Step: 68ms | Tot: 48s648ms | Loss: 0.0110 | Acc: 99.646% (49823/50000)\n",
      "(8.615215955232998, 0.99646)\n",
      "test:\n",
      " 157/157 [================================================================================>]  Step: 13ms | Tot: 2s642ms | Loss: 0.9836 | Acc: 85.670% (8567/10000)\n",
      "\n",
      "===> epoch: 135/200\n",
      "train:\n",
      " 782/782 [================================================================================>]  Step: 71ms | Tot: 48s545ms | Loss: 0.0052 | Acc: 99.836% (49918/50000)\n",
      "(4.030560357893592, 0.99836)\n",
      "test:\n",
      " 157/157 [================================================================================>]  Step: 13ms | Tot: 2s648ms | Loss: 1.0008 | Acc: 85.820% (8582/10000)\n",
      "\n",
      "===> epoch: 136/200\n",
      "train:\n",
      " 782/782 [================================================================================>]  Step: 67ms | Tot: 48s484ms | Loss: 0.0050 | Acc: 99.856% (49928/50000)\n",
      "(3.9247304846721818, 0.99856)\n",
      "test:\n",
      " 157/157 [================================================================================>]  Step: 16ms | Tot: 2s664ms | Loss: 1.0852 | Acc: 85.060% (8506/10000)\n",
      "\n",
      "===> epoch: 137/200\n",
      "train:\n",
      " 782/782 [================================================================================>]  Step: 58ms | Tot: 48s718ms | Loss: 0.0075 | Acc: 99.744% (49872/50000)[=====================>..........................................................]  Step: 62ms | Tot: 12s837ms | Loss: 0.0080 | Acc: 99.698% (13208/13248)\n",
      "(5.850704466407478, 0.99744)\n",
      "test:\n",
      " 157/157 [================================================================================>]  Step: 13ms | Tot: 2s663ms | Loss: 1.0260 | Acc: 85.670% (8567/10000)\n",
      "\n",
      "===> epoch: 138/200\n",
      "train:\n",
      " 782/782 [================================================================================>]  Step: 59ms | Tot: 48s612ms | Loss: 0.0059 | Acc: 99.814% (49907/50000)\n",
      "(4.629660252537178, 0.99814)\n",
      "test:\n",
      " 157/157 [================================================================================>]  Step: 14ms | Tot: 2s662ms | Loss: 1.0088 | Acc: 85.600% (8560/10000)\n",
      "\n",
      "===> epoch: 139/200\n",
      "train:\n",
      " 782/782 [================================================================================>]  Step: 70ms | Tot: 48s517ms | Loss: 0.0057 | Acc: 99.812% (49906/50000)[====================================================================>...........]  Step: 62ms | Tot: 41s494ms | Loss: 0.0055 | Acc: 99.822% (42740/42816)\n",
      "(4.441807620813961, 0.99812)\n",
      "test:\n",
      " 157/157 [================================================================================>]  Step: 14ms | Tot: 2s667ms | Loss: 1.0739 | Acc: 85.280% (8528/10000)\n",
      "\n",
      "===> epoch: 140/200\n",
      "train:\n",
      " 782/782 [================================================================================>]  Step: 64ms | Tot: 48s569ms | Loss: 0.0072 | Acc: 99.782% (49891/50000)........................................................................]  Step: 69ms | Tot: 137ms | Loss: 0.0023 | Acc: 100.000% (192/192)\n",
      "(5.658990199064647, 0.99782)\n",
      "test:\n",
      " 157/157 [================================================================================>]  Step: 13ms | Tot: 2s661ms | Loss: 1.0971 | Acc: 85.240% (8524/10000)\n",
      "\n",
      "===> epoch: 141/200\n",
      "train:\n",
      " 782/782 [================================================================================>]  Step: 67ms | Tot: 48s625ms | Loss: 0.0062 | Acc: 99.784% (49892/50000)\n",
      "(4.863876112724483, 0.99784)\n",
      "test:\n",
      " 157/157 [================================================================================>]  Step: 13ms | Tot: 2s644ms | Loss: 1.0411 | Acc: 85.600% (8560/10000)\n",
      "\n",
      "===> epoch: 142/200\n",
      "train:\n",
      " 782/782 [================================================================================>]  Step: 63ms | Tot: 48s519ms | Loss: 0.0079 | Acc: 99.774% (49887/50000)\n",
      "(6.140801021663719, 0.99774)\n",
      "test:\n",
      " 157/157 [================================================================================>]  Step: 14ms | Tot: 2s658ms | Loss: 1.0071 | Acc: 85.750% (8575/10000)\n",
      "\n",
      "===> epoch: 143/200\n",
      "train:\n",
      " 782/782 [================================================================================>]  Step: 61ms | Tot: 48s492ms | Loss: 0.0058 | Acc: 99.816% (49908/50000)\n",
      "(4.565608685926236, 0.99816)\n",
      "test:\n",
      " 157/157 [================================================================================>]  Step: 14ms | Tot: 2s660ms | Loss: 1.0703 | Acc: 85.380% (8538/10000)\n",
      "\n",
      "===> epoch: 144/200\n",
      "train:\n",
      " 782/782 [================================================================================>]  Step: 63ms | Tot: 48s572ms | Loss: 0.0052 | Acc: 99.820% (49910/50000)\n",
      "(4.0656525635711205, 0.9982)\n",
      "test:\n",
      " 157/157 [================================================================================>]  Step: 13ms | Tot: 2s664ms | Loss: 1.1247 | Acc: 85.660% (8566/10000)\n",
      "\n",
      "===> epoch: 145/200\n",
      "train:\n",
      " 782/782 [================================================================================>]  Step: 68ms | Tot: 48s515ms | Loss: 0.0094 | Acc: 99.710% (49855/50000)[===========================================================================>....]  Step: 62ms | Tot: 45s779ms | Loss: 0.0096 | Acc: 99.701% (47091/47232)\n",
      "(7.333848116177251, 0.9971)\n",
      "test:\n",
      " 157/157 [================================================================================>]  Step: 14ms | Tot: 2s653ms | Loss: 1.0068 | Acc: 85.310% (8531/10000)\n",
      "\n",
      "===> epoch: 146/200\n",
      "train:\n",
      " 782/782 [================================================================================>]  Step: 59ms | Tot: 48s520ms | Loss: 0.0047 | Acc: 99.830% (49915/50000)[=================>..............................................................]  Step: 62ms | Tot: 10s726ms | Loss: 0.0040 | Acc: 99.846% (11055/11072) [======================================================>.........................]  Step: 62ms | Tot: 33s249ms | Loss: 0.0047 | Acc: 99.848% (34252/34304)\n",
      "(3.6878114477199233, 0.9983)\n",
      "test:\n",
      " 157/157 [================================================================================>]  Step: 15ms | Tot: 2s657ms | Loss: 1.1280 | Acc: 85.560% (8556/10000)\n",
      "\n",
      "===> epoch: 147/200\n",
      "train:\n",
      " 782/782 [================================================================================>]  Step: 61ms | Tot: 48s528ms | Loss: 0.0072 | Acc: 99.770% (49885/50000)\n",
      "(5.668003588434203, 0.9977)\n",
      "test:\n",
      " 157/157 [================================================================================>]  Step: 13ms | Tot: 2s660ms | Loss: 1.0767 | Acc: 85.790% (8579/10000)\n",
      "\n",
      "===> epoch: 148/200\n",
      "train:\n",
      " 782/782 [================================================================================>]  Step: 66ms | Tot: 48s543ms | Loss: 0.0086 | Acc: 99.780% (49890/50000)\n",
      "(6.715036614960809, 0.9978)\n",
      "test:\n",
      " 157/157 [================================================================================>]  Step: 13ms | Tot: 2s650ms | Loss: 0.9712 | Acc: 85.760% (8576/10000)\n",
      "\n",
      "===> epoch: 149/200\n",
      "train:\n",
      " 782/782 [================================================================================>]  Step: 70ms | Tot: 48s508ms | Loss: 0.0072 | Acc: 99.760% (49880/50000)\n",
      "(5.626938775862072, 0.9976)\n",
      "test:\n",
      " 157/157 [================================================================================>]  Step: 14ms | Tot: 2s669ms | Loss: 1.0113 | Acc: 85.420% (8542/10000)\n",
      "\n",
      "===> epoch: 150/200\n",
      "train:\n",
      " 782/782 [================================================================================>]  Step: 61ms | Tot: 48s499ms | Loss: 0.0034 | Acc: 99.896% (49948/50000)\n",
      "(2.626903243293782, 0.99896)\n",
      "test:\n",
      " 157/157 [================================================================================>]  Step: 13ms | Tot: 2s653ms | Loss: 1.0191 | Acc: 86.040% (8604/10000)\n",
      "\n",
      "===> epoch: 151/200\n",
      "train:\n",
      " 782/782 [================================================================================>]  Step: 64ms | Tot: 48s636ms | Loss: 0.0020 | Acc: 99.946% (49973/50000)\n",
      "(1.5584182725297069, 0.99946)\n",
      "test:\n",
      " 157/157 [================================================================================>]  Step: 13ms | Tot: 2s659ms | Loss: 1.0293 | Acc: 86.190% (8619/10000)\n",
      "\n",
      "===> epoch: 152/200\n",
      "train:\n",
      " 782/782 [================================================================================>]  Step: 64ms | Tot: 48s491ms | Loss: 0.0009 | Acc: 99.986% (49993/50000)\n",
      "(0.7058433353633689, 0.99986)\n",
      "test:\n",
      " 157/157 [================================================================================>]  Step: 13ms | Tot: 2s657ms | Loss: 1.0976 | Acc: 86.190% (8619/10000)\n",
      "\n",
      "===> epoch: 153/200\n",
      "train:\n",
      " 782/782 [================================================================================>]  Step: 60ms | Tot: 48s527ms | Loss: 0.0010 | Acc: 99.978% (49989/50000)\n",
      "(0.7581813084356668, 0.99978)\n",
      "test:\n",
      " 157/157 [================================================================================>]  Step: 15ms | Tot: 2s663ms | Loss: 1.1347 | Acc: 86.280% (8628/10000)\n",
      "\n",
      "===> epoch: 154/200\n",
      "train:\n",
      " 782/782 [================================================================================>]  Step: 63ms | Tot: 48s524ms | Loss: 0.0015 | Acc: 99.958% (49979/50000)\n",
      "(1.1772448985674089, 0.99958)\n",
      "test:\n",
      " 157/157 [================================================================================>]  Step: 13ms | Tot: 2s658ms | Loss: 1.1576 | Acc: 85.870% (8587/10000)\n",
      "\n",
      "===> epoch: 155/200\n",
      "train:\n",
      " 782/782 [================================================================================>]  Step: 63ms | Tot: 48s597ms | Loss: 0.0024 | Acc: 99.916% (49958/50000)\n",
      "(1.851800361304683, 0.99916)\n",
      "test:\n",
      " 157/157 [================================================================================>]  Step: 13ms | Tot: 2s670ms | Loss: 1.2165 | Acc: 85.740% (8574/10000)\n",
      "\n",
      "===> epoch: 156/200\n",
      "train:\n",
      " 782/782 [================================================================================>]  Step: 65ms | Tot: 48s535ms | Loss: 0.0022 | Acc: 99.932% (49966/50000)\n",
      "(1.7317928805307474, 0.99932)\n",
      "test:\n",
      " 157/157 [================================================================================>]  Step: 14ms | Tot: 2s648ms | Loss: 1.1417 | Acc: 85.910% (8591/10000)\n",
      "\n",
      "===> epoch: 157/200\n",
      "train:\n",
      " 782/782 [================================================================================>]  Step: 59ms | Tot: 48s474ms | Loss: 0.0014 | Acc: 99.964% (49982/50000)\n",
      "(1.09096028664203, 0.99964)\n",
      "test:\n",
      " 157/157 [================================================================================>]  Step: 14ms | Tot: 2s672ms | Loss: 1.2186 | Acc: 85.980% (8598/10000)\n",
      "\n",
      "===> epoch: 158/200\n",
      "train:\n",
      " 782/782 [================================================================================>]  Step: 66ms | Tot: 48s582ms | Loss: 0.0028 | Acc: 99.926% (49963/50000)[======================>.........................................................]  Step: 63ms | Tot: 13s793ms | Loss: 0.0025 | Acc: 99.916% (14260/14272)\n",
      "(2.1735600154866574, 0.99926)\n",
      "test:\n",
      " 157/157 [================================================================================>]  Step: 14ms | Tot: 2s680ms | Loss: 1.1596 | Acc: 86.160% (8616/10000)\n",
      "\n",
      "===> epoch: 159/200\n",
      "train:\n",
      " 782/782 [================================================================================>]  Step: 65ms | Tot: 48s541ms | Loss: 0.0024 | Acc: 99.928% (49964/50000)\n",
      "(1.8598139225898365, 0.99928)\n",
      "test:\n",
      " 157/157 [================================================================================>]  Step: 13ms | Tot: 2s660ms | Loss: 1.1951 | Acc: 86.060% (8606/10000)\n",
      "\n",
      "===> epoch: 160/200\n",
      "train:\n",
      " 782/782 [================================================================================>]  Step: 65ms | Tot: 48s487ms | Loss: 0.0011 | Acc: 99.970% (49985/50000)\n",
      "(0.8561124255352297, 0.9997)\n",
      "test:\n",
      " 157/157 [================================================================================>]  Step: 13ms | Tot: 2s669ms | Loss: 1.1989 | Acc: 86.100% (8610/10000)\n",
      "\n",
      "===> epoch: 161/200\n",
      "train:\n",
      " 782/782 [================================================================================>]  Step: 64ms | Tot: 48s512ms | Loss: 0.0008 | Acc: 99.976% (49988/50000)[==========================>.....................................................]  Step: 62ms | Tot: 16s79ms | Loss: 0.0015 | Acc: 99.946% (16631/16640)\n",
      "(0.6105845052477719, 0.99976)\n",
      "test:\n",
      " 157/157 [================================================================================>]  Step: 13ms | Tot: 2s671ms | Loss: 1.2841 | Acc: 86.260% (8626/10000)\n",
      "\n",
      "===> epoch: 162/200\n",
      "train:\n",
      " 782/782 [================================================================================>]  Step: 61ms | Tot: 48s647ms | Loss: 0.0017 | Acc: 99.936% (49968/50000)\n",
      "(1.3280512722579658, 0.99936)\n",
      "test:\n",
      " 157/157 [================================================================================>]  Step: 13ms | Tot: 2s658ms | Loss: 1.2450 | Acc: 86.270% (8627/10000)\n",
      "\n",
      "===> epoch: 163/200\n",
      "train:\n",
      " 782/782 [================================================================================>]  Step: 57ms | Tot: 48s540ms | Loss: 0.0027 | Acc: 99.900% (49950/50000)[============================================>...................................]  Step: 63ms | Tot: 27s223ms | Loss: 0.0031 | Acc: 99.897% (28067/28096)\n",
      "(2.1036771997534345, 0.999)\n",
      "test:\n",
      " 157/157 [================================================================================>]  Step: 16ms | Tot: 2s658ms | Loss: 1.2065 | Acc: 86.010% (8601/10000)\n",
      "\n",
      "===> epoch: 164/200\n",
      "train:\n",
      " 782/782 [================================================================================>]  Step: 65ms | Tot: 48s474ms | Loss: 0.0018 | Acc: 99.942% (49971/50000)\n",
      "(1.3924404642518766, 0.99942)\n",
      "test:\n",
      " 157/157 [================================================================================>]  Step: 13ms | Tot: 2s662ms | Loss: 1.2375 | Acc: 86.080% (8608/10000)\n",
      "\n",
      "===> epoch: 165/200\n",
      "train:\n",
      " 782/782 [================================================================================>]  Step: 67ms | Tot: 48s557ms | Loss: 0.0013 | Acc: 99.958% (49979/50000)\n",
      "(0.9981321253711712, 0.99958)\n",
      "test:\n",
      " 157/157 [================================================================================>]  Step: 13ms | Tot: 2s716ms | Loss: 1.2287 | Acc: 86.170% (8617/10000)\n",
      "\n",
      "===> epoch: 166/200\n",
      "train:\n",
      " 782/782 [================================================================================>]  Step: 74ms | Tot: 48s705ms | Loss: 0.0018 | Acc: 99.954% (49977/50000)\n",
      "(1.4006792190433828, 0.99954)\n",
      "test:\n",
      " 157/157 [================================================================================>]  Step: 14ms | Tot: 2s660ms | Loss: 1.2902 | Acc: 86.060% (8606/10000)\n",
      "\n",
      "===> epoch: 167/200\n",
      "train:\n",
      " 782/782 [================================================================================>]  Step: 67ms | Tot: 48s520ms | Loss: 0.0032 | Acc: 99.908% (49954/50000)[===============================================================>................]  Step: 62ms | Tot: 38s395ms | Loss: 0.0029 | Acc: 99.914% (39582/39616)\n",
      "(2.5325974105787736, 0.99908)\n",
      "test:\n",
      " 157/157 [================================================================================>]  Step: 14ms | Tot: 2s662ms | Loss: 1.1991 | Acc: 85.820% (8582/10000)\n",
      "\n",
      "===> epoch: 168/200\n",
      "train:\n",
      " 782/782 [================================================================================>]  Step: 59ms | Tot: 48s506ms | Loss: 0.0017 | Acc: 99.948% (49974/50000)\n",
      "(1.334628845217111, 0.99948)\n",
      "test:\n",
      " 157/157 [================================================================================>]  Step: 13ms | Tot: 2s667ms | Loss: 1.2530 | Acc: 86.060% (8606/10000)\n",
      "\n",
      "===> epoch: 169/200\n",
      "train:\n",
      " 782/782 [================================================================================>]  Step: 63ms | Tot: 48s618ms | Loss: 0.0017 | Acc: 99.942% (49971/50000)\n",
      "(1.3557781055382918, 0.99942)\n",
      "test:\n",
      " 157/157 [================================================================================>]  Step: 15ms | Tot: 2s664ms | Loss: 1.1913 | Acc: 86.140% (8614/10000)\n",
      "\n",
      "===> epoch: 170/200\n",
      "train:\n",
      " 782/782 [================================================================================>]  Step: 64ms | Tot: 48s508ms | Loss: 0.0017 | Acc: 99.944% (49972/50000).........................................................................]  Step: 62ms | Tot: 522ms | Loss: 0.0001 | Acc: 100.000% (576/576) [========================>.......................................................]  Step: 63ms | Tot: 14s666ms | Loss: 0.0016 | Acc: 99.947% (15160/15168)\n",
      "(1.33690147383237, 0.99944)\n",
      "test:\n",
      " 157/157 [================================================================================>]  Step: 13ms | Tot: 2s663ms | Loss: 1.2081 | Acc: 85.810% (8581/10000)\n",
      "\n",
      "===> epoch: 171/200\n",
      "train:\n",
      " 782/782 [================================================================================>]  Step: 67ms | Tot: 48s500ms | Loss: 0.0009 | Acc: 99.972% (49986/50000)\n",
      "(0.6865243367022629, 0.99972)\n",
      "test:\n",
      " 157/157 [================================================================================>]  Step: 14ms | Tot: 2s657ms | Loss: 1.2123 | Acc: 85.880% (8588/10000)\n",
      "\n",
      "===> epoch: 172/200\n",
      "train:\n",
      " 782/782 [================================================================================>]  Step: 66ms | Tot: 48s495ms | Loss: 0.0013 | Acc: 99.956% (49978/50000)\n",
      "(1.0136593496118422, 0.99956)\n",
      "test:\n",
      " 157/157 [================================================================================>]  Step: 14ms | Tot: 2s697ms | Loss: 1.2246 | Acc: 85.840% (8584/10000)\n",
      "\n",
      "===> epoch: 173/200\n",
      "train:\n",
      " 782/782 [================================================================================>]  Step: 63ms | Tot: 49s375ms | Loss: 0.0029 | Acc: 99.908% (49954/50000)[======================================>.........................................]  Step: 63ms | Tot: 23s165ms | Loss: 0.0032 | Acc: 99.912% (23787/23808)\n",
      "(2.2858781394452876, 0.99908)\n",
      "test:\n",
      " 157/157 [================================================================================>]  Step: 16ms | Tot: 2s787ms | Loss: 1.2015 | Acc: 85.890% (8589/10000)\n",
      "\n",
      "===> epoch: 174/200\n",
      "train:\n",
      " 782/782 [================================================================================>]  Step: 66ms | Tot: 49s687ms | Loss: 0.0015 | Acc: 99.948% (49974/50000)[==============================>.................................................]  Step: 64ms | Tot: 18s953ms | Loss: 0.0014 | Acc: 99.958% (19128/19136) [======================================>.........................................]  Step: 63ms | Tot: 24s28ms | Loss: 0.0016 | Acc: 99.946% (24243/24256)\n",
      "(1.1800937313444422, 0.99948)\n",
      "test:\n",
      " 157/157 [================================================================================>]  Step: 14ms | Tot: 2s715ms | Loss: 1.2277 | Acc: 85.860% (8586/10000)\n",
      "\n",
      "===> epoch: 175/200\n",
      "train:\n",
      " 782/782 [================================================================================>]  Step: 78ms | Tot: 49s266ms | Loss: 0.0021 | Acc: 99.926% (49963/50000)[======================>.........................................................]  Step: 63ms | Tot: 13s531ms | Loss: 0.0017 | Acc: 99.957% (13818/13824) [============================================================================>...]  Step: 63ms | Tot: 47s107ms | Loss: 0.0020 | Acc: 99.927% (47837/47872)\n",
      "(1.6313862753846706, 0.99926)\n",
      "test:\n",
      " 157/157 [================================================================================>]  Step: 14ms | Tot: 2s719ms | Loss: 1.2151 | Acc: 86.000% (8600/10000)\n",
      "\n",
      "===> epoch: 176/200\n",
      "train:\n",
      " 782/782 [================================================================================>]  Step: 58ms | Tot: 49s228ms | Loss: 0.0014 | Acc: 99.960% (49980/50000)\n",
      "(1.0574725411179884, 0.9996)\n",
      "test:\n",
      " 157/157 [================================================================================>]  Step: 13ms | Tot: 2s712ms | Loss: 1.2182 | Acc: 86.110% (8611/10000)\n",
      "\n",
      "===> epoch: 177/200\n",
      "train:\n",
      " 782/782 [================================================================================>]  Step: 63ms | Tot: 49s131ms | Loss: 0.0008 | Acc: 99.976% (49988/50000)\n",
      "(0.6536962476452501, 0.99976)\n",
      "test:\n",
      " 157/157 [================================================================================>]  Step: 14ms | Tot: 2s722ms | Loss: 1.2714 | Acc: 86.200% (8620/10000)\n",
      "\n",
      "===> epoch: 178/200\n",
      "train:\n",
      " 782/782 [================================================================================>]  Step: 69ms | Tot: 49s161ms | Loss: 0.0013 | Acc: 99.960% (49980/50000)\n",
      "(0.9985163741093572, 0.9996)\n",
      "test:\n",
      " 157/157 [================================================================================>]  Step: 14ms | Tot: 2s724ms | Loss: 1.2927 | Acc: 85.810% (8581/10000)\n",
      "\n",
      "===> epoch: 179/200\n",
      "train:\n",
      " 782/782 [================================================================================>]  Step: 72ms | Tot: 49s151ms | Loss: 0.0019 | Acc: 99.932% (49966/50000)=>...........................................................................]  Step: 62ms | Tot: 2s465ms | Loss: 0.0010 | Acc: 99.961% (2559/2560) [==============================================================>.................]  Step: 64ms | Tot: 38s496ms | Loss: 0.0013 | Acc: 99.946% (39211/39232) [==============================================================>.................]  Step: 63ms | Tot: 38s559ms | Loss: 0.0013 | Acc: 99.947% (39275/39296)\n",
      "(1.5080953898427936, 0.99932)\n",
      "test:\n",
      " 157/157 [================================================================================>]  Step: 13ms | Tot: 2s799ms | Loss: 1.2681 | Acc: 86.090% (8609/10000)\n",
      "\n",
      "===> epoch: 180/200\n",
      "train:\n",
      " 782/782 [================================================================================>]  Step: 66ms | Tot: 49s246ms | Loss: 0.0021 | Acc: 99.940% (49970/50000)[======================================>.........................................]  Step: 63ms | Tot: 23s419ms | Loss: 0.0019 | Acc: 99.941% (23794/23808) [===============================================================>................]  Step: 62ms | Tot: 38s902ms | Loss: 0.0021 | Acc: 99.937% (39527/39552)\n",
      "(1.62031392200862, 0.9994)\n",
      "test:\n",
      " 157/157 [================================================================================>]  Step: 13ms | Tot: 2s722ms | Loss: 1.2309 | Acc: 85.910% (8591/10000)\n",
      "\n",
      "===> epoch: 181/200\n",
      "train:\n",
      " 782/782 [================================================================================>]  Step: 66ms | Tot: 49s145ms | Loss: 0.0008 | Acc: 99.968% (49984/50000)[=============================================================================>..]  Step: 63ms | Tot: 47s825ms | Loss: 0.0009 | Acc: 99.967% (48688/48704)\n",
      "(0.6530663420726057, 0.99968)\n",
      "test:\n",
      " 157/157 [================================================================================>]  Step: 13ms | Tot: 2s717ms | Loss: 1.2742 | Acc: 85.920% (8592/10000)\n",
      "\n",
      "===> epoch: 182/200\n",
      "train:\n",
      " 782/782 [================================================================================>]  Step: 67ms | Tot: 49s107ms | Loss: 0.0013 | Acc: 99.950% (49975/50000)\n",
      "(1.0393611896691368, 0.9995)\n",
      "test:\n",
      " 157/157 [================================================================================>]  Step: 14ms | Tot: 2s700ms | Loss: 1.2706 | Acc: 85.800% (8580/10000)\n",
      "\n",
      "===> epoch: 183/200\n",
      "train:\n",
      " 782/782 [================================================================================>]  Step: 59ms | Tot: 49s250ms | Loss: 0.0014 | Acc: 99.956% (49978/50000)\n",
      "(1.1050934319476085, 0.99956)\n",
      "test:\n",
      " 157/157 [================================================================================>]  Step: 14ms | Tot: 2s715ms | Loss: 1.3547 | Acc: 86.060% (8606/10000)\n",
      "\n",
      "===> epoch: 184/200\n",
      "train:\n",
      " 782/782 [================================================================================>]  Step: 68ms | Tot: 49s170ms | Loss: 0.0018 | Acc: 99.942% (49971/50000)==========>...................................................................]  Step: 64ms | Tot: 7s791ms | Loss: 0.0036 | Acc: 99.912% (7929/7936)\n",
      "(1.4108163305165533, 0.99942)\n",
      "test:\n",
      " 157/157 [================================================================================>]  Step: 14ms | Tot: 2s707ms | Loss: 1.2847 | Acc: 85.850% (8585/10000)\n",
      "\n",
      "===> epoch: 185/200\n",
      "train:\n",
      " 782/782 [================================================================================>]  Step: 64ms | Tot: 49s113ms | Loss: 0.0012 | Acc: 99.954% (49977/50000)====>.........................................................................]  Step: 63ms | Tot: 4s178ms | Loss: 0.0005 | Acc: 99.977% (4287/4288)\n",
      "(0.9089752574660253, 0.99954)\n",
      "test:\n",
      " 157/157 [================================================================================>]  Step: 13ms | Tot: 2s723ms | Loss: 1.3517 | Acc: 85.540% (8554/10000)\n",
      "\n",
      "===> epoch: 186/200\n",
      "train:\n",
      " 782/782 [================================================================================>]  Step: 65ms | Tot: 49s101ms | Loss: 0.0028 | Acc: 99.920% (49960/50000)[==============================>.................................................]  Step: 64ms | Tot: 18s999ms | Loss: 0.0016 | Acc: 99.943% (19381/19392)\n",
      "(2.1663246961271483, 0.9992)\n",
      "test:\n",
      " 157/157 [================================================================================>]  Step: 15ms | Tot: 2s772ms | Loss: 1.2706 | Acc: 85.790% (8579/10000)\n",
      "\n",
      "===> epoch: 187/200\n",
      "train:\n",
      " 782/782 [================================================================================>]  Step: 62ms | Tot: 49s118ms | Loss: 0.0020 | Acc: 99.940% (49970/50000)\n",
      "(1.5607060212755783, 0.9994)\n",
      "test:\n",
      " 157/157 [================================================================================>]  Step: 13ms | Tot: 2s698ms | Loss: 1.2792 | Acc: 85.560% (8556/10000)\n",
      "\n",
      "===> epoch: 188/200\n",
      "train:\n",
      " 782/782 [================================================================================>]  Step: 62ms | Tot: 48s606ms | Loss: 0.0021 | Acc: 99.928% (49964/50000)[==============================================================>.................]  Step: 63ms | Tot: 37s906ms | Loss: 0.0022 | Acc: 99.921% (39009/39040)\n",
      "(1.6466169319759985, 0.99928)\n",
      "test:\n",
      " 157/157 [================================================================================>]  Step: 13ms | Tot: 2s680ms | Loss: 1.3240 | Acc: 85.470% (8547/10000)\n",
      "\n",
      "===> epoch: 189/200\n",
      "train:\n",
      " 782/782 [================================================================================>]  Step: 57ms | Tot: 48s629ms | Loss: 0.0008 | Acc: 99.976% (49988/50000)[=======================================>........................................]  Step: 63ms | Tot: 24s20ms | Loss: 0.0009 | Acc: 99.980% (24763/24768)\n",
      "(0.6039759195328998, 0.99976)\n",
      "test:\n",
      " 157/157 [================================================================================>]  Step: 14ms | Tot: 2s685ms | Loss: 1.3140 | Acc: 85.680% (8568/10000)\n",
      "\n",
      "===> epoch: 190/200\n",
      "train:\n",
      " 782/782 [================================================================================>]  Step: 64ms | Tot: 49s652ms | Loss: 0.0005 | Acc: 99.986% (49993/50000)\n",
      "(0.3906453491793016, 0.99986)\n",
      "test:\n",
      " 157/157 [================================================================================>]  Step: 14ms | Tot: 2s739ms | Loss: 1.3549 | Acc: 85.850% (8585/10000)\n",
      "\n",
      "===> epoch: 191/200\n",
      "train:\n",
      " 782/782 [================================================================================>]  Step: 68ms | Tot: 49s138ms | Loss: 0.0021 | Acc: 99.940% (49970/50000)\n",
      "(1.6354571167170775, 0.9994)\n",
      "test:\n",
      " 157/157 [================================================================================>]  Step: 13ms | Tot: 2s718ms | Loss: 1.2999 | Acc: 85.790% (8579/10000)\n",
      "\n",
      "===> epoch: 192/200\n",
      "train:\n",
      " 782/782 [================================================================================>]  Step: 70ms | Tot: 49s179ms | Loss: 0.0015 | Acc: 99.942% (49971/50000)=======>......................................................................]  Step: 64ms | Tot: 5s615ms | Loss: 0.0014 | Acc: 99.948% (5757/5760) [=============================================================================>..]  Step: 63ms | Tot: 47s911ms | Loss: 0.0015 | Acc: 99.941% (48739/48768)\n",
      "(1.1685228103664826, 0.99942)\n",
      "test:\n",
      " 157/157 [================================================================================>]  Step: 13ms | Tot: 2s727ms | Loss: 1.2814 | Acc: 86.010% (8601/10000)\n",
      "\n",
      "===> epoch: 193/200\n",
      "train:\n",
      " 782/782 [================================================================================>]  Step: 64ms | Tot: 49s182ms | Loss: 0.0012 | Acc: 99.962% (49981/50000)\n",
      "(0.9337998834356895, 0.99962)\n",
      "test:\n",
      " 157/157 [================================================================================>]  Step: 14ms | Tot: 2s771ms | Loss: 1.2987 | Acc: 85.970% (8597/10000)\n",
      "\n",
      "===> epoch: 194/200\n",
      "train:\n",
      " 782/782 [================================================================================>]  Step: 62ms | Tot: 49s221ms | Loss: 0.0021 | Acc: 99.926% (49963/50000)\n",
      "(1.6453930739591556, 0.99926)\n",
      "test:\n",
      " 157/157 [================================================================================>]  Step: 14ms | Tot: 2s720ms | Loss: 1.2969 | Acc: 85.850% (8585/10000)\n",
      "\n",
      "===> epoch: 195/200\n",
      "train:\n",
      " 782/782 [================================================================================>]  Step: 67ms | Tot: 49s248ms | Loss: 0.0017 | Acc: 99.946% (49973/50000)\n",
      "(1.341672550515554, 0.99946)\n",
      "test:\n",
      " 157/157 [================================================================================>]  Step: 13ms | Tot: 2s720ms | Loss: 1.2915 | Acc: 85.980% (8598/10000)\n",
      "\n",
      "===> epoch: 196/200\n",
      "train:\n",
      " 782/782 [================================================================================>]  Step: 65ms | Tot: 49s147ms | Loss: 0.0020 | Acc: 99.942% (49971/50000)\n",
      "(1.537556039950914, 0.99942)\n",
      "test:\n",
      " 157/157 [================================================================================>]  Step: 13ms | Tot: 2s705ms | Loss: 1.2344 | Acc: 86.030% (8603/10000)\n",
      "\n",
      "===> epoch: 197/200\n",
      "train:\n",
      " 782/782 [================================================================================>]  Step: 62ms | Tot: 49s157ms | Loss: 0.0014 | Acc: 99.966% (49983/50000)========>.....................................................................]  Step: 64ms | Tot: 6s353ms | Loss: 0.0019 | Acc: 99.939% (6524/6528)\n",
      "(1.1147863233291133, 0.99966)\n",
      "test:\n",
      " 157/157 [================================================================================>]  Step: 14ms | Tot: 2s712ms | Loss: 1.2786 | Acc: 85.940% (8594/10000)\n",
      "\n",
      "===> epoch: 198/200\n",
      "train:\n",
      " 782/782 [================================================================================>]  Step: 63ms | Tot: 49s114ms | Loss: 0.0021 | Acc: 99.928% (49964/50000)[=============================================>..................................]  Step: 62ms | Tot: 27s926ms | Loss: 0.0027 | Acc: 99.912% (28455/28480)\n",
      "(1.6081312906868277, 0.99928)\n",
      "test:\n",
      " 157/157 [================================================================================>]  Step: 13ms | Tot: 2s708ms | Loss: 1.2266 | Acc: 85.690% (8569/10000)\n",
      "\n",
      "===> epoch: 199/200\n",
      "train:\n",
      " 782/782 [================================================================================>]  Step: 63ms | Tot: 49s85ms | Loss: 0.0019 | Acc: 99.942% (49971/50000) [===============================>................................................]  Step: 64ms | Tot: 19s555ms | Loss: 0.0017 | Acc: 99.945% (19957/19968) [====================================================>...........................]  Step: 65ms | Tot: 32s64ms | Loss: 0.0019 | Acc: 99.942% (32685/32704)\n",
      "(1.4874086558571662, 0.99942)\n",
      "test:\n",
      " 157/157 [================================================================================>]  Step: 14ms | Tot: 2s716ms | Loss: 1.2694 | Acc: 85.600% (8560/10000)\n",
      "\n",
      "===> epoch: 200/200\n",
      "train:\n",
      " 782/782 [================================================================================>]  Step: 65ms | Tot: 49s165ms | Loss: 0.0014 | Acc: 99.960% (49980/50000)[============================================================================>...]  Step: 65ms | Tot: 46s794ms | Loss: 0.0014 | Acc: 99.960% (47661/47680)\n",
      "(1.0610610586327525, 0.9996)\n",
      "test:\n",
      " 157/157 [================================================================================>]  Step: 13ms | Tot: 2s775ms | Loss: 1.2087 | Acc: 85.960% (8596/10000)\n",
      "===> BEST ACC. PERFORMANCE: 86.280%\n",
      "Checkpoint saved to model.pth\n"
     ]
    }
   ],
   "source": [
    "%run cifar10triplenet\\main_batchsize_64.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "The model has 8965434 trainable parameters.\n",
      "\n",
      "===> epoch: 1/200\n",
      "train:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\alexa\\mambaforge\\envs\\triplenet\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:131: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n",
      "c:\\Users\\alexa\\mambaforge\\envs\\triplenet\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 79/782 [========>.......................................................................]  Step: 62ms | Tot: 4s867ms | Loss: 2.0789 | Acc: 21.519% (1088/5056)\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[1;32m~\\OneDrive\\01 Frankfurt School\\Semester 3\\Deep Learning\\TripleNetDL\\cifar10triplenet\\main_batchsize_64.py:154\u001b[0m\n\u001b[0;32m    150\u001b[0m                 \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msave()\n\u001b[0;32m    153\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m__name__\u001b[39m \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39m__main__\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m--> 154\u001b[0m     main()\n",
      "File \u001b[1;32m~\\OneDrive\\01 Frankfurt School\\Semester 3\\Deep Learning\\TripleNetDL\\cifar10triplenet\\main_batchsize_64.py:31\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     28\u001b[0m args \u001b[39m=\u001b[39m parser\u001b[39m.\u001b[39mparse_args()\n\u001b[0;32m     30\u001b[0m solver \u001b[39m=\u001b[39m Solver(args)\n\u001b[1;32m---> 31\u001b[0m solver\u001b[39m.\u001b[39;49mrun()\n",
      "File \u001b[1;32m~\\OneDrive\\01 Frankfurt School\\Semester 3\\Deep Learning\\TripleNetDL\\cifar10triplenet\\main_batchsize_64.py:144\u001b[0m, in \u001b[0;36mSolver.run\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    142\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mscheduler\u001b[39m.\u001b[39mstep(epoch)\n\u001b[0;32m    143\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m===> epoch: \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m/200\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m epoch)\n\u001b[1;32m--> 144\u001b[0m train_result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain()\n\u001b[0;32m    145\u001b[0m \u001b[39mprint\u001b[39m(train_result)\n\u001b[0;32m    146\u001b[0m test_result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtest()\n",
      "File \u001b[1;32m~\\OneDrive\\01 Frankfurt School\\Semester 3\\Deep Learning\\TripleNetDL\\cifar10triplenet\\main_batchsize_64.py:87\u001b[0m, in \u001b[0;36mSolver.train\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     85\u001b[0m output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel(data)\n\u001b[0;32m     86\u001b[0m loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcriterion(output, target)\n\u001b[1;32m---> 87\u001b[0m loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[0;32m     88\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptimizer\u001b[39m.\u001b[39mstep()\n\u001b[0;32m     89\u001b[0m iter_loss \u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39mitem()\n",
      "File \u001b[1;32mc:\\Users\\alexa\\mambaforge\\envs\\triplenet\\lib\\site-packages\\torch\\_tensor.py:363\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    354\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[0;32m    355\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    356\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[0;32m    357\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    361\u001b[0m         create_graph\u001b[39m=\u001b[39mcreate_graph,\n\u001b[0;32m    362\u001b[0m         inputs\u001b[39m=\u001b[39minputs)\n\u001b[1;32m--> 363\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs)\n",
      "File \u001b[1;32mc:\\Users\\alexa\\mambaforge\\envs\\triplenet\\lib\\site-packages\\torch\\autograd\\__init__.py:173\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    168\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[0;32m    170\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[0;32m    171\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    172\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 173\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    174\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[0;32m    175\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%run cifar10triplenet\\main_batchsize_64.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "triplenet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
